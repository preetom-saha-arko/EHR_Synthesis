{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\preet\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\preet\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "total samples: 46517\n",
      "feature size: 1358\n",
      "total samples: 46517, features: 1358\n",
      "training data shape: (37000, 1358), testing data shape: (9000, 1358), dataset type: int32\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#################### Seed  #####################\n",
    "torch.manual_seed(1235)\n",
    "np.random.seed(1235)\n",
    "torch.cuda.manual_seed_all(1235)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(1235)\n",
    "################################################\n",
    "\n",
    "################ For KL-prior ######################\n",
    "\n",
    "\n",
    "def knn_distance(point, sample, k):\n",
    "    \"\"\" Euclidean distance from `point` to it's `k`-Nearest\n",
    "    Neighbour in `sample` \"\"\"\n",
    "    norms = torch.linalg.norm(sample-point, axis=1)\n",
    "    return torch.sort(norms)[0][k]\n",
    "\n",
    "\n",
    "def verify_sample_shapes(s1, s2, k):\n",
    "    # Expects [N, D]\n",
    "    assert(len(s1.shape) == len(s2.shape) == 2)\n",
    "    # Check dimensionality of sample is identical\n",
    "    assert(s1.shape[1] == s2.shape[1])\n",
    "\n",
    "\n",
    "def naive_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using brute-force (numpy) k-NN\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    D = np.log(m / (n - 1))\n",
    "    d = float(s1.shape[1])\n",
    "\n",
    "    for p1 in s1:\n",
    "        nu = knn_distance(p1, s2, k-1)  # -1 because 'p1' is not in 's2'\n",
    "        rho = knn_distance(p1, s1, k)\n",
    "        D += (d/n)*torch.log(nu/rho)\n",
    "    return D\n",
    "\n",
    "#################################\n",
    "### Reading Dataset from File ###\n",
    "#################################\n",
    "\n",
    "\n",
    "input_data = np.load(\n",
    "    r'C:\\Users\\preet\\OneDrive\\Documents\\CS578_project\\useful_mimic3\\patient_matrix.npy', allow_pickle=True)\n",
    "\n",
    "total_samples = input_data.shape[0]\n",
    "feature_size = input_data.shape[1]\n",
    "print(\"total samples:\", total_samples)\n",
    "print(\"feature size:\", feature_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#################################\n",
    "### hyperparams ###\n",
    "#################################\n",
    "batchSize = 1000\n",
    "lr = 0.001\n",
    "lr_g = 0.2  # Generator learning rate\n",
    "n_epoch_ae = 300  # number of autoencoder epochs\n",
    "num_gen = 10\n",
    "autoencoder_flag = False\n",
    "autoencoder_inner_dim = 128\n",
    "DEBUG = False\n",
    "\n",
    "################ Preparing Dataset #############\n",
    "\n",
    "\n",
    "#####################\n",
    "### Dataset Model ###\n",
    "#####################\n",
    "\n",
    "\n",
    "class EHRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.sample_size = dataset.shape[0]\n",
    "        self.feature_size = dataset.shape[1]\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"type(self.dataset[idx]):\",type(self.dataset[idx]))\n",
    "        return self.dataset[idx]\n",
    "        # return self.transform(self.dataset[idx])\n",
    "\n",
    "##########################\n",
    "### Dataset Processing ###\n",
    "##########################\n",
    "\n",
    "\n",
    "train_data = input_data[:int(0.8 * total_samples)]\n",
    "# print(train_data[0])\n",
    "# print(type(train_data[0]))\n",
    "train_data_len = len(train_data)//batchSize*batchSize\n",
    "train_data = train_data[:train_data_len]\n",
    "\n",
    "test_data = input_data[int(0.8 * total_samples):]\n",
    "test_data_len = len(test_data)//batchSize*batchSize\n",
    "test_data = test_data[:test_data_len]\n",
    "\n",
    "print('total samples: {}, features: {}'.format(total_samples, feature_size))\n",
    "print('training data shape: {}, testing data shape: {}, dataset type: {}'.format(\n",
    "    train_data.shape, test_data.shape, input_data.dtype))\n",
    "training_dataloader = DataLoader(\n",
    "    EHRDataset(dataset=train_data),\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True\n",
    "    # num_workers=opt.n_cpu\n",
    ")\n",
    "\n",
    "testing_dataloader = DataLoader(\n",
    "    EHRDataset(dataset=test_data),\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True\n",
    "    # num_workers=opt.n_cpu\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "############## NN structures ###################\n",
    "\n",
    "def initialize_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            # m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            # m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):  # BatchNorm weight init\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):  # BatchNorm weight init\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "### Generator Model ###\n",
    "# https://github.com/mohibeyki/SCorGAN/blob/main/medGAN/MIMIC-III/medGAN.ipynb\n",
    "#############################\n",
    "\n",
    "# Output should be 64 * 20\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_gen):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.name = 'generator'\n",
    "        self.latent_dim = latent_dim  # default 128\n",
    "        self.num_gen = num_gen\n",
    "\n",
    "        if autoencoder_flag:\n",
    "            self.genDim = autoencoder_inner_dim\n",
    "        else:\n",
    "            self.genDim = feature_size\n",
    "            \n",
    "        if autoencoder_flag:\n",
    "            self.linear1 = nn.Linear(latent_dim, self.genDim)\n",
    "            self.bn1 = nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01)\n",
    "            self.activation1 = nn.ReLU()\n",
    "            self.linear2 = nn.Linear(latent_dim, self.genDim)\n",
    "            self.bn2 = nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01)\n",
    "            self.activation2 = nn.Tanh()\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(latent_dim, self.genDim//2),\n",
    "                nn.BatchNorm1d(self.genDim//2, eps=0.001, momentum=0.01),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.genDim//2, self.genDim),\n",
    "                nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            \n",
    "\n",
    "        self.gs = []\n",
    "        for i in range(self.num_gen):\n",
    "            g = nn.Sequential(\n",
    "                # input size is z_size\n",
    "                nn.Linear(latent_dim, self.genDim),\n",
    "                nn.BatchNorm1d(self.genDim, eps=0.001, momentum=0.01),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Linear(self.genDim, latent_dim),\n",
    "                nn.BatchNorm1d(latent_dim, eps=0.001, momentum=0.01),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            )\n",
    "            setattr(self, 'G_{}'.format(i), g)\n",
    "            self.gs.append(g)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"x.size():\",x.size())  # [100,128]\n",
    "        sp_size = (len(x) - 1) // len(self.gs) + 1\n",
    "#         print(\"sp_size:\",sp_size)  # 10\n",
    "        y = []\n",
    "        for _x, _g in zip(torch.split(x, sp_size, dim=0), self.gs):\n",
    "            y.append(_g(_x))\n",
    "        y = torch.cat(y, dim=0)\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"y dim:\",y.size())\n",
    "\n",
    "        if autoencoder_flag:\n",
    "            # Layer 1\n",
    "            residual = y\n",
    "            temp = self.activation1(self.bn1(self.linear1(y)))\n",
    "            out1 = temp + residual\n",
    "\n",
    "            # Layer 2\n",
    "            residual = out1\n",
    "            temp = self.activation2(self.bn2(self.linear2(out1)))\n",
    "            out2 = temp + residual\n",
    "            return out2\n",
    "        else:\n",
    "            output = self.model(y)\n",
    "            return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################\n",
    "### Discriminator Model ###\n",
    "# https://github.com/mohibeyki/SCorGAN/blob/main/medGAN/MIMIC-III/medGAN.ipynb\n",
    "###########################\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.name = 'discriminator'\n",
    "\n",
    "        # Discriminator's parameters\n",
    "        self.disDim = 256\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feature_size, self.disDim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.disDim, int(self.disDim / 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.disDim / 2), 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feeding the model\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "#########################\n",
    "### AutoEncoder Model ###\n",
    "#########################\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(feature_size, autoencoder_inner_dim),\n",
    "            nn.Tanh())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(autoencoder_inner_dim, feature_size), nn.Sigmoid())\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "########################\n",
    "### AutoEncoder Loss ###\n",
    "########################\n",
    "\n",
    "class AutoEncoderLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoderLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        epsilon = 1e-12\n",
    "        term = target * torch.log(input + epsilon) + \\\n",
    "                                  (1. - target) * torch.log(1. - input + epsilon)\n",
    "        return torch.mean(-torch.sum(term, 1), 0)\n",
    "\n",
    "\n",
    "################################################\n",
    "current_path = os.getcwd()\n",
    "directory = \"med_ebgan\"\n",
    "result_path = os.path.join(current_path, directory)\n",
    "if not os.path.isdir(result_path):\n",
    "    os.mkdir(result_path)\n",
    "\n",
    "################# EBGAN training ###############\n",
    "\n",
    "############################\n",
    "### Model Initialization ###\n",
    "############################\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "latent_dim = 128\n",
    "autoencoder = Autoencoder()\n",
    "generator = Generator(latent_dim, num_gen)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "Tensor = torch.FloatTensor\n",
    "\n",
    "autoencoder.cuda()\n",
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "\n",
    "generator_params = [{'params': generator.parameters(\n",
    ")}, {'params': autoencoder.decoder.parameters(), 'lr': 1e-4}]\n",
    "\n",
    "initial_lr_d = 0.002\n",
    "optimizer_A = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    discriminator.parameters(), lr=initial_lr_d, betas=(0.5, 0.999))\n",
    "optimizer_G = torch.optim.SGD(generator.parameters(), lr=lr_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1/100 of autoencoder training] [Loss:    7175.44] [errors: 161219]\n",
      "[Epoch   2/100 of autoencoder training] [Loss:    6231.60] [errors: 148178]\n",
      "[Epoch   3/100 of autoencoder training] [Loss:    4903.11] [errors: 143242]\n",
      "[Epoch   4/100 of autoencoder training] [Loss:    3829.39] [errors: 139921]\n",
      "[Epoch   5/100 of autoencoder training] [Loss:    2803.84] [errors: 135776]\n",
      "[Epoch   6/100 of autoencoder training] [Loss:    1824.03] [errors: 130974]\n",
      "[Epoch   7/100 of autoencoder training] [Loss:    1004.38] [errors: 124904]\n",
      "[Epoch   8/100 of autoencoder training] [Loss:     269.32] [errors: 119574]\n",
      "[Epoch   9/100 of autoencoder training] [Loss:    -410.26] [errors: 113852]\n",
      "[Epoch  10/100 of autoencoder training] [Loss:    -962.85] [errors: 109989]\n",
      "[Epoch  11/100 of autoencoder training] [Loss:   -1452.54] [errors: 105307]\n",
      "[Epoch  12/100 of autoencoder training] [Loss:   -1863.63] [errors: 101411]\n",
      "[Epoch  13/100 of autoencoder training] [Loss:   -2217.36] [errors:  98535]\n",
      "[Epoch  14/100 of autoencoder training] [Loss:   -2499.01] [errors:  95472]\n",
      "[Epoch  15/100 of autoencoder training] [Loss:   -2778.80] [errors:  93674]\n",
      "[Epoch  16/100 of autoencoder training] [Loss:   -3038.70] [errors:  91249]\n",
      "[Epoch  17/100 of autoencoder training] [Loss:   -3234.27] [errors:  88869]\n",
      "[Epoch  18/100 of autoencoder training] [Loss:   -3465.92] [errors:  87192]\n",
      "[Epoch  19/100 of autoencoder training] [Loss:   -3677.82] [errors:  85331]\n",
      "[Epoch  20/100 of autoencoder training] [Loss:   -3871.88] [errors:  83597]\n",
      "[Epoch  21/100 of autoencoder training] [Loss:   -4081.65] [errors:  82193]\n",
      "[Epoch  22/100 of autoencoder training] [Loss:   -4236.74] [errors:  79956]\n",
      "[Epoch  23/100 of autoencoder training] [Loss:   -4449.25] [errors:  78557]\n",
      "[Epoch  24/100 of autoencoder training] [Loss:   -4616.79] [errors:  76550]\n",
      "[Epoch  25/100 of autoencoder training] [Loss:   -4757.55] [errors:  75050]\n",
      "[Epoch  26/100 of autoencoder training] [Loss:   -4882.89] [errors:  74149]\n",
      "[Epoch  27/100 of autoencoder training] [Loss:   -5007.63] [errors:  73192]\n",
      "[Epoch  28/100 of autoencoder training] [Loss:   -5105.39] [errors:  72008]\n",
      "[Epoch  29/100 of autoencoder training] [Loss:   -5208.14] [errors:  71568]\n",
      "[Epoch  30/100 of autoencoder training] [Loss:   -5318.50] [errors:  70498]\n",
      "[Epoch  31/100 of autoencoder training] [Loss:   -5404.04] [errors:  69761]\n",
      "[Epoch  32/100 of autoencoder training] [Loss:   -5483.94] [errors:  69019]\n",
      "[Epoch  33/100 of autoencoder training] [Loss:   -5566.85] [errors:  68381]\n",
      "[Epoch  34/100 of autoencoder training] [Loss:   -5620.68] [errors:  67665]\n",
      "[Epoch  35/100 of autoencoder training] [Loss:   -5687.69] [errors:  67179]\n",
      "[Epoch  36/100 of autoencoder training] [Loss:   -5760.60] [errors:  66899]\n",
      "[Epoch  37/100 of autoencoder training] [Loss:   -5802.01] [errors:  66284]\n",
      "[Epoch  38/100 of autoencoder training] [Loss:   -5876.79] [errors:  65944]\n",
      "[Epoch  39/100 of autoencoder training] [Loss:   -5898.22] [errors:  65045]\n",
      "[Epoch  40/100 of autoencoder training] [Loss:   -5973.60] [errors:  65027]\n",
      "[Epoch  41/100 of autoencoder training] [Loss:   -6023.92] [errors:  64778]\n",
      "[Epoch  42/100 of autoencoder training] [Loss:   -6074.79] [errors:  64255]\n",
      "[Epoch  43/100 of autoencoder training] [Loss:   -6125.24] [errors:  64348]\n",
      "[Epoch  44/100 of autoencoder training] [Loss:   -6150.91] [errors:  63663]\n",
      "[Epoch  45/100 of autoencoder training] [Loss:   -6172.40] [errors:  63536]\n",
      "[Epoch  46/100 of autoencoder training] [Loss:   -6211.22] [errors:  63548]\n",
      "[Epoch  47/100 of autoencoder training] [Loss:   -6231.22] [errors:  62837]\n",
      "[Epoch  48/100 of autoencoder training] [Loss:   -6259.97] [errors:  62601]\n",
      "[Epoch  49/100 of autoencoder training] [Loss:   -6310.86] [errors:  62924]\n",
      "[Epoch  50/100 of autoencoder training] [Loss:   -6317.28] [errors:  62155]\n",
      "[Epoch  51/100 of autoencoder training] [Loss:   -6357.77] [errors:  62043]\n",
      "[Epoch  52/100 of autoencoder training] [Loss:   -6379.98] [errors:  61970]\n",
      "[Epoch  53/100 of autoencoder training] [Loss:   -6405.35] [errors:  61715]\n",
      "[Epoch  54/100 of autoencoder training] [Loss:   -6433.78] [errors:  61795]\n",
      "[Epoch  55/100 of autoencoder training] [Loss:   -6424.61] [errors:  61181]\n",
      "[Epoch  56/100 of autoencoder training] [Loss:   -6462.60] [errors:  61395]\n",
      "[Epoch  57/100 of autoencoder training] [Loss:   -6474.92] [errors:  61115]\n",
      "[Epoch  58/100 of autoencoder training] [Loss:   -6484.55] [errors:  60676]\n",
      "[Epoch  59/100 of autoencoder training] [Loss:   -6532.52] [errors:  61467]\n",
      "[Epoch  60/100 of autoencoder training] [Loss:   -6513.00] [errors:  60832]\n",
      "[Epoch  61/100 of autoencoder training] [Loss:   -6531.90] [errors:  60706]\n",
      "[Epoch  62/100 of autoencoder training] [Loss:   -6563.64] [errors:  60936]\n",
      "[Epoch  63/100 of autoencoder training] [Loss:   -6578.70] [errors:  60730]\n",
      "[Epoch  64/100 of autoencoder training] [Loss:   -6568.80] [errors:  60377]\n",
      "[Epoch  65/100 of autoencoder training] [Loss:   -6566.19] [errors:  60230]\n",
      "[Epoch  66/100 of autoencoder training] [Loss:   -6597.30] [errors:  60258]\n",
      "[Epoch  67/100 of autoencoder training] [Loss:   -6610.57] [errors:  60369]\n",
      "[Epoch  68/100 of autoencoder training] [Loss:   -6620.54] [errors:  60024]\n",
      "[Epoch  69/100 of autoencoder training] [Loss:   -6646.31] [errors:  60212]\n",
      "[Epoch  70/100 of autoencoder training] [Loss:   -6658.30] [errors:  60164]\n",
      "[Epoch  71/100 of autoencoder training] [Loss:   -6649.83] [errors:  59804]\n",
      "[Epoch  72/100 of autoencoder training] [Loss:   -6639.15] [errors:  59661]\n",
      "[Epoch  73/100 of autoencoder training] [Loss:   -6656.54] [errors:  59555]\n",
      "[Epoch  74/100 of autoencoder training] [Loss:   -6693.74] [errors:  59688]\n",
      "[Epoch  75/100 of autoencoder training] [Loss:   -6701.98] [errors:  59513]\n",
      "[Epoch  76/100 of autoencoder training] [Loss:   -6716.78] [errors:  59534]\n",
      "[Epoch  77/100 of autoencoder training] [Loss:   -6714.29] [errors:  59305]\n",
      "[Epoch  78/100 of autoencoder training] [Loss:   -6742.42] [errors:  59348]\n",
      "[Epoch  79/100 of autoencoder training] [Loss:   -6754.68] [errors:  59366]\n",
      "[Epoch  80/100 of autoencoder training] [Loss:   -6733.65] [errors:  58795]\n",
      "[Epoch  81/100 of autoencoder training] [Loss:   -6763.28] [errors:  59494]\n",
      "[Epoch  82/100 of autoencoder training] [Loss:   -6783.78] [errors:  59233]\n",
      "[Epoch  83/100 of autoencoder training] [Loss:   -6773.74] [errors:  58884]\n",
      "[Epoch  84/100 of autoencoder training] [Loss:   -6796.27] [errors:  59137]\n",
      "[Epoch  85/100 of autoencoder training] [Loss:   -6791.00] [errors:  58853]\n",
      "[Epoch  86/100 of autoencoder training] [Loss:   -6793.77] [errors:  58596]\n",
      "[Epoch  87/100 of autoencoder training] [Loss:   -6793.99] [errors:  58630]\n",
      "[Epoch  88/100 of autoencoder training] [Loss:   -6826.75] [errors:  59099]\n",
      "[Epoch  89/100 of autoencoder training] [Loss:   -6835.98] [errors:  58729]\n",
      "[Epoch  90/100 of autoencoder training] [Loss:   -6832.93] [errors:  58917]\n",
      "[Epoch  91/100 of autoencoder training] [Loss:   -6833.73] [errors:  58802]\n",
      "[Epoch  92/100 of autoencoder training] [Loss:   -6835.56] [errors:  58422]\n",
      "[Epoch  93/100 of autoencoder training] [Loss:   -6852.38] [errors:  58729]\n",
      "[Epoch  94/100 of autoencoder training] [Loss:   -6833.99] [errors:  58446]\n",
      "[Epoch  95/100 of autoencoder training] [Loss:   -6864.33] [errors:  58693]\n",
      "[Epoch  96/100 of autoencoder training] [Loss:   -6835.56] [errors:  58185]\n",
      "[Epoch  97/100 of autoencoder training] [Loss:   -6867.17] [errors:  58636]\n",
      "[Epoch  98/100 of autoencoder training] [Loss:   -6871.40] [errors:  58489]\n",
      "[Epoch  99/100 of autoencoder training] [Loss:   -6872.33] [errors:  58542]\n",
      "[Epoch 100/100 of autoencoder training] [Loss:   -6876.11] [errors:  58620]\n"
     ]
    }
   ],
   "source": [
    "criterion = AutoEncoderLoss()\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch_ae):\n",
    "    autoencoder.train()\n",
    "    for batch in training_dataloader:\n",
    "        batch = Variable(batch.type(Tensor))\n",
    "        generated = autoencoder(batch)\n",
    "        loss_A = criterion(generated, batch)\n",
    "        optimizer_A.zero_grad()\n",
    "        loss_A.backward()\n",
    "        optimizer_A.step()\n",
    "\n",
    "    errors = 0\n",
    "    testing_loss = 0\n",
    "    autoencoder.eval()\n",
    "    for batch in testing_dataloader:\n",
    "        batch = Variable(batch.type(Tensor))\n",
    "        generated = autoencoder(batch)\n",
    "        res = generated.round()\n",
    "        diff = torch.abs(res - batch).view(1, 1, -\n",
    "                         1)[0][0].cpu().detach().numpy()\n",
    "        bad_diffs = diff[diff > 0.5]\n",
    "        errors += len(bad_diffs)\n",
    "        testing_loss += criterion(generated, batch)\n",
    "\n",
    "    print(\"[Epoch {:3d}/{:3d} of autoencoder training] [Loss: {:10.2f}] [errors: {:6d}]\".format(\n",
    "        epoch + 1, n_epoch_ae, testing_loss, errors), flush=True)\n",
    "\n",
    "torch.save(autoencoder.state_dict(), os.path.join(result_path, 'autoencoder.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=1358, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1358, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.load_state_dict(torch.load(os.path.join(result_path, 'autoencoder.model')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=1358, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1358, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of bad digits: 58620\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for batch in testing_dataloader:\n",
    "    batch = Variable(batch.type(Tensor))\n",
    "    generated = autoencoder(batch)\n",
    "    res = generated.round()\n",
    "    diff = torch.abs(res - batch).view(1, 1, -1)[0][0].cpu().detach().numpy()\n",
    "    bad_diffs = diff[diff > 0.5]\n",
    "    errors += len(bad_diffs)\n",
    "print(\"total number of bad samples: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\preet\\AppData\\Local\\Temp\\ipykernel_18396\\2098713926.py:80: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\tensor\\python_tensor.cpp:85.)\n",
      "  real = Variable(Tensor(num_of_samples).fill_(1.0), requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 g_loss 10.698472023010254 d_loss 1.2571314573287964 E(D(fake)) 0.4227368235588074 E(D(real)) 0.49597620964050293\n",
      "epoch 1 g_loss 10.639214515686035 d_loss 1.1008896827697754 E(D(fake)) 0.32931649684906006 E(D(real)) 0.4997137188911438\n",
      "epoch 2 g_loss 10.385124206542969 d_loss 1.0596849918365479 E(D(fake)) 0.31453296542167664 E(D(real)) 0.5096796751022339\n",
      "epoch 3 g_loss 10.136439323425293 d_loss 1.0953577756881714 E(D(fake)) 0.3008112609386444 E(D(real)) 0.4875369369983673\n",
      "epoch 4 g_loss 9.768461227416992 d_loss 1.1097683906555176 E(D(fake)) 0.32704854011535645 E(D(real)) 0.49675440788269043\n",
      "epoch 5 g_loss 9.436370849609375 d_loss 1.1314208507537842 E(D(fake)) 0.3468097150325775 E(D(real)) 0.5056874752044678\n",
      "epoch 6 g_loss 9.217110633850098 d_loss 1.1770908832550049 E(D(fake)) 0.33142074942588806 E(D(real)) 0.4750141501426697\n",
      "epoch 7 g_loss 8.94255256652832 d_loss 1.1747868061065674 E(D(fake)) 0.33619430661201477 E(D(real)) 0.48266786336898804\n",
      "epoch 8 g_loss 8.652918815612793 d_loss 1.2084479331970215 E(D(fake)) 0.3495333194732666 E(D(real)) 0.4822764992713928\n",
      "epoch 9 g_loss 8.463268280029297 d_loss 1.223289132118225 E(D(fake)) 0.3323037028312683 E(D(real)) 0.46843892335891724\n",
      "epoch 10 g_loss 8.197409629821777 d_loss 1.2228022813796997 E(D(fake)) 0.3416970670223236 E(D(real)) 0.4783061444759369\n",
      "epoch 11 g_loss 7.906285762786865 d_loss 1.2195892333984375 E(D(fake)) 0.3642237186431885 E(D(real)) 0.49025025963783264\n",
      "epoch 12 g_loss 7.690987586975098 d_loss 1.2234927415847778 E(D(fake)) 0.3626416027545929 E(D(real)) 0.49063608050346375\n",
      "epoch 13 g_loss 7.427148342132568 d_loss 1.2433745861053467 E(D(fake)) 0.38242506980895996 E(D(real)) 0.49818745255470276\n",
      "epoch 14 g_loss 7.1956634521484375 d_loss 1.2605876922607422 E(D(fake)) 0.39441439509391785 E(D(real)) 0.5008658170700073\n",
      "epoch 15 g_loss 6.970917701721191 d_loss 1.3055317401885986 E(D(fake)) 0.40562722086906433 E(D(real)) 0.48807814717292786\n",
      "epoch 16 g_loss 6.7818193435668945 d_loss 1.327221393585205 E(D(fake)) 0.4038269817829132 E(D(real)) 0.4786372780799866\n",
      "epoch 17 g_loss 6.551358699798584 d_loss 1.3359980583190918 E(D(fake)) 0.42155250906944275 E(D(real)) 0.4809633195400238\n",
      "epoch 18 g_loss 6.314089298248291 d_loss 1.345198631286621 E(D(fake)) 0.4464982748031616 E(D(real)) 0.49121910333633423\n",
      "epoch 19 g_loss 6.06990385055542 d_loss 1.3887054920196533 E(D(fake)) 0.4797405004501343 E(D(real)) 0.5025736689567566\n",
      "epoch 20 g_loss 5.8669915199279785 d_loss 1.3885631561279297 E(D(fake)) 0.49671703577041626 E(D(real)) 0.5117466449737549\n",
      "epoch 21 g_loss 5.670642852783203 d_loss 1.3890705108642578 E(D(fake)) 0.5150662064552307 E(D(real)) 0.5273396372795105\n",
      "epoch 22 g_loss 5.474245071411133 d_loss 1.4117038249969482 E(D(fake)) 0.5392385125160217 E(D(real)) 0.5411396622657776\n",
      "epoch 23 g_loss 5.313662528991699 d_loss 1.41062331199646 E(D(fake)) 0.5411273241043091 E(D(real)) 0.5420840382575989\n",
      "epoch 24 g_loss 5.167571067810059 d_loss 1.4053547382354736 E(D(fake)) 0.5394315123558044 E(D(real)) 0.5414465665817261\n",
      "epoch 25 g_loss 5.033247470855713 d_loss 1.408312439918518 E(D(fake)) 0.5361629128456116 E(D(real)) 0.5356751084327698\n",
      "epoch 26 g_loss 4.893754959106445 d_loss 1.4098429679870605 E(D(fake)) 0.5367538332939148 E(D(real)) 0.5348954200744629\n",
      "epoch 27 g_loss 4.744791507720947 d_loss 1.4148368835449219 E(D(fake)) 0.541703462600708 E(D(real)) 0.532622218132019\n",
      "epoch 28 g_loss 4.616339206695557 d_loss 1.4182586669921875 E(D(fake)) 0.5420930981636047 E(D(real)) 0.5338093638420105\n",
      "epoch 29 g_loss 4.501876354217529 d_loss 1.4210835695266724 E(D(fake)) 0.5387814044952393 E(D(real)) 0.5309917330741882\n",
      "epoch 30 g_loss 4.368915557861328 d_loss 1.4176814556121826 E(D(fake)) 0.5405205488204956 E(D(real)) 0.5309045910835266\n",
      "epoch 31 g_loss 4.261264324188232 d_loss 1.4074175357818604 E(D(fake)) 0.5360747575759888 E(D(real)) 0.5304610133171082\n",
      "epoch 32 g_loss 4.142838478088379 d_loss 1.405988335609436 E(D(fake)) 0.5362657904624939 E(D(real)) 0.5299997329711914\n",
      "epoch 33 g_loss 4.0402021408081055 d_loss 1.4025170803070068 E(D(fake)) 0.5331963896751404 E(D(real)) 0.5291823744773865\n",
      "epoch 34 g_loss 3.933610439300537 d_loss 1.3972084522247314 E(D(fake)) 0.532838761806488 E(D(real)) 0.5309619307518005\n",
      "epoch 35 g_loss 3.8336217403411865 d_loss 1.394648551940918 E(D(fake)) 0.5314462184906006 E(D(real)) 0.530604898929596\n",
      "epoch 36 g_loss 3.7386443614959717 d_loss 1.3937749862670898 E(D(fake)) 0.5292657613754272 E(D(real)) 0.5300812125205994\n",
      "epoch 37 g_loss 3.6376209259033203 d_loss 1.3950549364089966 E(D(fake)) 0.529876172542572 E(D(real)) 0.5297268033027649\n",
      "epoch 38 g_loss 3.5415163040161133 d_loss 1.3955066204071045 E(D(fake)) 0.5302680730819702 E(D(real)) 0.5289263129234314\n",
      "epoch 39 g_loss 3.451756477355957 d_loss 1.3932044506072998 E(D(fake)) 0.5297303795814514 E(D(real)) 0.5293399691581726\n",
      "epoch 40 g_loss 3.360976457595825 d_loss 1.3965092897415161 E(D(fake)) 0.5306879281997681 E(D(real)) 0.5283194780349731\n",
      "epoch 41 g_loss 3.279944658279419 d_loss 1.3968756198883057 E(D(fake)) 0.5288915038108826 E(D(real)) 0.5275730490684509\n",
      "epoch 42 g_loss 3.1997854709625244 d_loss 1.3941142559051514 E(D(fake)) 0.5278099775314331 E(D(real)) 0.5277875661849976\n",
      "epoch 43 g_loss 3.1167516708374023 d_loss 1.3936142921447754 E(D(fake)) 0.5288360714912415 E(D(real)) 0.5261855721473694\n",
      "epoch 44 g_loss 3.042043685913086 d_loss 1.392092227935791 E(D(fake)) 0.5275951027870178 E(D(real)) 0.5272970795631409\n",
      "epoch 45 g_loss 2.966470718383789 d_loss 1.3931140899658203 E(D(fake)) 0.5275630950927734 E(D(real)) 0.5261917114257812\n",
      "epoch 46 g_loss 2.89391827583313 d_loss 1.3956780433654785 E(D(fake)) 0.5273179411888123 E(D(real)) 0.5246769189834595\n",
      "epoch 47 g_loss 2.8232038021087646 d_loss 1.3943939208984375 E(D(fake)) 0.5273006558418274 E(D(real)) 0.5251356959342957\n",
      "epoch 48 g_loss 2.7561092376708984 d_loss 1.3943519592285156 E(D(fake)) 0.5267391800880432 E(D(real)) 0.5240499377250671\n",
      "epoch 49 g_loss 2.691350221633911 d_loss 1.3935418128967285 E(D(fake)) 0.5261650681495667 E(D(real)) 0.5237853527069092\n",
      "epoch 50 g_loss 2.628786325454712 d_loss 1.392372727394104 E(D(fake)) 0.5254919528961182 E(D(real)) 0.5237438082695007\n",
      "epoch 51 g_loss 2.568549633026123 d_loss 1.3937127590179443 E(D(fake)) 0.524725615978241 E(D(real)) 0.5226116180419922\n",
      "epoch 52 g_loss 2.509341239929199 d_loss 1.3941521644592285 E(D(fake)) 0.5243569612503052 E(D(real)) 0.5219194293022156\n",
      "epoch 53 g_loss 2.451927661895752 d_loss 1.394061803817749 E(D(fake)) 0.524086594581604 E(D(real)) 0.5215343832969666\n",
      "epoch 54 g_loss 2.3961095809936523 d_loss 1.3935374021530151 E(D(fake)) 0.523918092250824 E(D(real)) 0.5214542746543884\n",
      "epoch 55 g_loss 2.3427088260650635 d_loss 1.3950331211090088 E(D(fake)) 0.5234880447387695 E(D(real)) 0.5202231407165527\n",
      "epoch 56 g_loss 2.2908897399902344 d_loss 1.3929431438446045 E(D(fake)) 0.5230897665023804 E(D(real)) 0.5207944512367249\n",
      "epoch 57 g_loss 2.24076247215271 d_loss 1.3927637338638306 E(D(fake)) 0.5226768851280212 E(D(real)) 0.5204050540924072\n",
      "epoch 58 g_loss 2.1922731399536133 d_loss 1.3926811218261719 E(D(fake)) 0.5222544074058533 E(D(real)) 0.5200958251953125\n",
      "epoch 59 g_loss 2.1451218128204346 d_loss 1.3927854299545288 E(D(fake)) 0.5219674110412598 E(D(real)) 0.5196536183357239\n",
      "epoch 60 g_loss 2.099705934524536 d_loss 1.3924243450164795 E(D(fake)) 0.5215166211128235 E(D(real)) 0.5193597674369812\n",
      "epoch 61 g_loss 2.0558431148529053 d_loss 1.3919754028320312 E(D(fake)) 0.5210539698600769 E(D(real)) 0.5190942287445068\n",
      "epoch 62 g_loss 2.0133097171783447 d_loss 1.3915635347366333 E(D(fake)) 0.5206204652786255 E(D(real)) 0.5188185572624207\n",
      "epoch 63 g_loss 1.9721176624298096 d_loss 1.392175555229187 E(D(fake)) 0.5201976299285889 E(D(real)) 0.518060564994812\n",
      "epoch 64 g_loss 1.9322749376296997 d_loss 1.3913757801055908 E(D(fake)) 0.519805908203125 E(D(real)) 0.5180144309997559\n",
      "epoch 65 g_loss 1.8936318159103394 d_loss 1.391023874282837 E(D(fake)) 0.5194375514984131 E(D(real)) 0.5178083777427673\n",
      "epoch 66 g_loss 1.8561419248580933 d_loss 1.3910470008850098 E(D(fake)) 0.5191054344177246 E(D(real)) 0.5174344182014465\n",
      "epoch 67 g_loss 1.8198319673538208 d_loss 1.3908421993255615 E(D(fake)) 0.5187981724739075 E(D(real)) 0.5172273516654968\n",
      "epoch 68 g_loss 1.78470778465271 d_loss 1.3904945850372314 E(D(fake)) 0.5184680223464966 E(D(real)) 0.5170345902442932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69 g_loss 1.750794768333435 d_loss 1.390334129333496 E(D(fake)) 0.518091082572937 E(D(real)) 0.5167074203491211\n",
      "epoch 70 g_loss 1.7180185317993164 d_loss 1.390707015991211 E(D(fake)) 0.5177038908004761 E(D(real)) 0.5161169767379761\n",
      "epoch 71 g_loss 1.6862425804138184 d_loss 1.390061616897583 E(D(fake)) 0.5173534154891968 E(D(real)) 0.5160425305366516\n",
      "epoch 72 g_loss 1.6553239822387695 d_loss 1.3895219564437866 E(D(fake)) 0.5170745849609375 E(D(real)) 0.5160263776779175\n",
      "epoch 73 g_loss 1.625251293182373 d_loss 1.3902382850646973 E(D(fake)) 0.5168657302856445 E(D(real)) 0.5154598355293274\n",
      "epoch 74 g_loss 1.5960667133331299 d_loss 1.3901344537734985 E(D(fake)) 0.5167121291160583 E(D(real)) 0.5153355002403259\n",
      "epoch 75 g_loss 1.5678025484085083 d_loss 1.3897544145584106 E(D(fake)) 0.5165628790855408 E(D(real)) 0.5153639316558838\n",
      "epoch 76 g_loss 1.5404770374298096 d_loss 1.3892927169799805 E(D(fake)) 0.5163795351982117 E(D(real)) 0.515402615070343\n",
      "epoch 77 g_loss 1.5140929222106934 d_loss 1.3893146514892578 E(D(fake)) 0.5161565542221069 E(D(real)) 0.5151567459106445\n",
      "epoch 78 g_loss 1.4885752201080322 d_loss 1.3893649578094482 E(D(fake)) 0.5159130692481995 E(D(real)) 0.5148752927780151\n",
      "epoch 79 g_loss 1.4639358520507812 d_loss 1.3893243074417114 E(D(fake)) 0.5156699419021606 E(D(real)) 0.5146476626396179\n",
      "epoch 80 g_loss 1.4400403499603271 d_loss 1.3890068531036377 E(D(fake)) 0.5154569149017334 E(D(real)) 0.5145704746246338\n",
      "epoch 81 g_loss 1.416820764541626 d_loss 1.388742208480835 E(D(fake)) 0.5152930617332458 E(D(real)) 0.5145288705825806\n",
      "epoch 82 g_loss 1.3942739963531494 d_loss 1.3886609077453613 E(D(fake)) 0.5151618123054504 E(D(real)) 0.5144301652908325\n",
      "epoch 83 g_loss 1.372438907623291 d_loss 1.3888282775878906 E(D(fake)) 0.5150207877159119 E(D(real)) 0.5142003297805786\n",
      "epoch 84 g_loss 1.3514063358306885 d_loss 1.388791561126709 E(D(fake)) 0.5148412585258484 E(D(real)) 0.5140225291252136\n",
      "epoch 85 g_loss 1.3311713933944702 d_loss 1.388533592224121 E(D(fake)) 0.5146016478538513 E(D(real)) 0.5139023661613464\n",
      "epoch 86 g_loss 1.3116121292114258 d_loss 1.3887550830841064 E(D(fake)) 0.5143318772315979 E(D(real)) 0.5135068893432617\n",
      "epoch 87 g_loss 1.2927184104919434 d_loss 1.3886139392852783 E(D(fake)) 0.5140401124954224 E(D(real)) 0.5132685899734497\n",
      "epoch 88 g_loss 1.274409294128418 d_loss 1.3882609605789185 E(D(fake)) 0.513775110244751 E(D(real)) 0.5131654739379883\n",
      "epoch 89 g_loss 1.2566382884979248 d_loss 1.3888760805130005 E(D(fake)) 0.5135473608970642 E(D(real)) 0.5126188397407532\n",
      "epoch 90 g_loss 1.2393684387207031 d_loss 1.388261079788208 E(D(fake)) 0.5133467316627502 E(D(real)) 0.5127143859863281\n",
      "epoch 91 g_loss 1.222658395767212 d_loss 1.3884254693984985 E(D(fake)) 0.5131493806838989 E(D(real)) 0.5124242305755615\n",
      "epoch 92 g_loss 1.2064975500106812 d_loss 1.3885512351989746 E(D(fake)) 0.5129522681236267 E(D(real)) 0.5121544599533081\n",
      "epoch 93 g_loss 1.1908832788467407 d_loss 1.3883678913116455 E(D(fake)) 0.512742817401886 E(D(real)) 0.512031078338623\n",
      "epoch 94 g_loss 1.1757702827453613 d_loss 1.3883283138275146 E(D(fake)) 0.5125207901000977 E(D(real)) 0.5118211507797241\n",
      "epoch 95 g_loss 1.1611541509628296 d_loss 1.3884135484695435 E(D(fake)) 0.5122969746589661 E(D(real)) 0.5115488171577454\n",
      "epoch 96 g_loss 1.1470246315002441 d_loss 1.3877111673355103 E(D(fake)) 0.512081503868103 E(D(real)) 0.5116576552391052\n",
      "epoch 97 g_loss 1.1333656311035156 d_loss 1.3879765272140503 E(D(fake)) 0.5118613243103027 E(D(real)) 0.5113182067871094\n",
      "epoch 98 g_loss 1.1200604438781738 d_loss 1.3876817226409912 E(D(fake)) 0.5116758346557617 E(D(real)) 0.5112512707710266\n",
      "epoch 99 g_loss 1.1071512699127197 d_loss 1.3877925872802734 E(D(fake)) 0.5114984512329102 E(D(real)) 0.5110188126564026\n",
      "epoch 100 g_loss 1.0946571826934814 d_loss 1.3879820108413696 E(D(fake)) 0.511339545249939 E(D(real)) 0.5107520222663879\n",
      "epoch 101 g_loss 1.0825395584106445 d_loss 1.3879961967468262 E(D(fake)) 0.5111991763114929 E(D(real)) 0.510604739189148\n",
      "epoch 102 g_loss 1.0707465410232544 d_loss 1.3881111145019531 E(D(fake)) 0.5110805034637451 E(D(real)) 0.5104187726974487\n",
      "epoch 103 g_loss 1.0592951774597168 d_loss 1.3876545429229736 E(D(fake)) 0.5109793543815613 E(D(real)) 0.510545015335083\n",
      "epoch 104 g_loss 1.048235535621643 d_loss 1.3876011371612549 E(D(fake)) 0.5108727216720581 E(D(real)) 0.5104513168334961\n",
      "epoch 105 g_loss 1.037569284439087 d_loss 1.3876488208770752 E(D(fake)) 0.5107638239860535 E(D(real)) 0.5103166103363037\n",
      "epoch 106 g_loss 1.027284026145935 d_loss 1.3876969814300537 E(D(fake)) 0.5106306076049805 E(D(real)) 0.5101568102836609\n",
      "epoch 107 g_loss 1.0173594951629639 d_loss 1.3876099586486816 E(D(fake)) 0.5104748606681824 E(D(real)) 0.5100398659706116\n",
      "epoch 108 g_loss 1.0078121423721313 d_loss 1.3873926401138306 E(D(fake)) 0.5102972388267517 E(D(real)) 0.5099616050720215\n",
      "epoch 109 g_loss 0.9986113905906677 d_loss 1.387230396270752 E(D(fake)) 0.5101038217544556 E(D(real)) 0.5098426938056946\n",
      "epoch 110 g_loss 0.9896979331970215 d_loss 1.3875484466552734 E(D(fake)) 0.5099077820777893 E(D(real)) 0.5094879269599915\n",
      "epoch 111 g_loss 0.9810722470283508 d_loss 1.387181043624878 E(D(fake)) 0.5097178816795349 E(D(real)) 0.5094724893569946\n",
      "epoch 112 g_loss 0.9727104902267456 d_loss 1.3871476650238037 E(D(fake)) 0.509544312953949 E(D(real)) 0.5093055367469788\n",
      "epoch 113 g_loss 0.9645646810531616 d_loss 1.3871387243270874 E(D(fake)) 0.5093873143196106 E(D(real)) 0.50914067029953\n",
      "epoch 114 g_loss 0.9566484093666077 d_loss 1.386907935142517 E(D(fake)) 0.5092387199401855 E(D(real)) 0.5091055035591125\n",
      "epoch 115 g_loss 0.9490008354187012 d_loss 1.3869436979293823 E(D(fake)) 0.5091094970703125 E(D(real)) 0.5089586973190308\n",
      "epoch 116 g_loss 0.9415578842163086 d_loss 1.3868169784545898 E(D(fake)) 0.508994996547699 E(D(real)) 0.5088956356048584\n",
      "epoch 117 g_loss 0.9343471527099609 d_loss 1.3868539333343506 E(D(fake)) 0.5088872909545898 E(D(real)) 0.5087681412696838\n",
      "epoch 118 g_loss 0.927348256111145 d_loss 1.3866181373596191 E(D(fake)) 0.5087879300117493 E(D(real)) 0.5087820887565613\n",
      "epoch 119 g_loss 0.9205777645111084 d_loss 1.3870302438735962 E(D(fake)) 0.5086978673934937 E(D(real)) 0.5084901452064514\n",
      "epoch 120 g_loss 0.9139924049377441 d_loss 1.3864887952804565 E(D(fake)) 0.508613109588623 E(D(real)) 0.5086701512336731\n",
      "epoch 121 g_loss 0.9076619744300842 d_loss 1.3863922357559204 E(D(fake)) 0.5085190534591675 E(D(real)) 0.5086269974708557\n",
      "epoch 122 g_loss 0.9015889763832092 d_loss 1.3861562013626099 E(D(fake)) 0.5084042549133301 E(D(real)) 0.508630633354187\n",
      "epoch 123 g_loss 0.8957467675209045 d_loss 1.385878562927246 E(D(fake)) 0.5082657337188721 E(D(real)) 0.5086301565170288\n",
      "epoch 124 g_loss 0.8880386352539062 d_loss 1.387768268585205 E(D(fake)) 0.5091906189918518 E(D(real)) 0.5086328983306885\n",
      "epoch 125 g_loss 0.8805078268051147 d_loss 1.3901042938232422 E(D(fake)) 0.5101428627967834 E(D(real)) 0.5084432363510132\n",
      "epoch 126 g_loss 0.8745501041412354 d_loss 1.391461730003357 E(D(fake)) 0.5103892683982849 E(D(real)) 0.5080103874206543\n",
      "epoch 127 g_loss 0.8694854378700256 d_loss 1.3916821479797363 E(D(fake)) 0.5102688074111938 E(D(real)) 0.5077780485153198\n",
      "epoch 128 g_loss 0.8649590611457825 d_loss 1.3908088207244873 E(D(fake)) 0.5099655389785767 E(D(real)) 0.5078962445259094\n",
      "epoch 129 g_loss 0.8609216809272766 d_loss 1.3894121646881104 E(D(fake)) 0.5094895362854004 E(D(real)) 0.5081093311309814\n",
      "epoch 130 g_loss 0.8570125102996826 d_loss 1.387939214706421 E(D(fake)) 0.5090259313583374 E(D(real)) 0.5083740949630737\n",
      "epoch 131 g_loss 0.8525010347366333 d_loss 1.3875904083251953 E(D(fake)) 0.5089369416236877 E(D(real)) 0.5084760189056396\n",
      "epoch 132 g_loss 0.8466266393661499 d_loss 1.388741135597229 E(D(fake)) 0.509627640247345 E(D(real)) 0.5086087584495544\n",
      "epoch 133 g_loss 0.841776430606842 d_loss 1.3896359205245972 E(D(fake)) 0.5098755359649658 E(D(real)) 0.508417010307312\n",
      "epoch 134 g_loss 0.8381181955337524 d_loss 1.3892779350280762 E(D(fake)) 0.5095886588096619 E(D(real)) 0.5083020925521851\n",
      "epoch 135 g_loss 0.8351671695709229 d_loss 1.3893767595291138 E(D(fake)) 0.5090043544769287 E(D(real)) 0.5076575875282288\n",
      "epoch 136 g_loss 0.8318306803703308 d_loss 1.3893351554870605 E(D(fake)) 0.5086929202079773 E(D(real)) 0.5073573589324951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137 g_loss 0.8290218710899353 d_loss 1.3897690773010254 E(D(fake)) 0.5081712603569031 E(D(real)) 0.5066026449203491\n",
      "epoch 138 g_loss 0.8268590569496155 d_loss 1.388775110244751 E(D(fake)) 0.5073831677436829 E(D(real)) 0.5062816143035889\n",
      "epoch 139 g_loss 0.8250089287757874 d_loss 1.388009786605835 E(D(fake)) 0.5064778923988342 E(D(real)) 0.5057373046875\n",
      "epoch 140 g_loss 0.8232433795928955 d_loss 1.386867880821228 E(D(fake)) 0.5055782794952393 E(D(real)) 0.5053892135620117\n",
      "epoch 141 g_loss 0.8213327527046204 d_loss 1.3855102062225342 E(D(fake)) 0.5047959685325623 E(D(real)) 0.505271852016449\n",
      "epoch 142 g_loss 0.8191914558410645 d_loss 1.383667230606079 E(D(fake)) 0.5041784048080444 E(D(real)) 0.5055640935897827\n",
      "epoch 143 g_loss 0.8167522549629211 d_loss 1.382112741470337 E(D(fake)) 0.5037577152252197 E(D(real)) 0.5059199333190918\n",
      "epoch 144 g_loss 0.8140862584114075 d_loss 1.380455493927002 E(D(fake)) 0.5034926533699036 E(D(real)) 0.5064957737922668\n",
      "epoch 145 g_loss 0.809157133102417 d_loss 1.3816053867340088 E(D(fake)) 0.504414439201355 E(D(real)) 0.506878674030304\n",
      "epoch 146 g_loss 0.8007789850234985 d_loss 1.3868415355682373 E(D(fake)) 0.507178544998169 E(D(real)) 0.5070807337760925\n",
      "epoch 147 g_loss 0.7942116260528564 d_loss 1.3904976844787598 E(D(fake)) 0.5091367959976196 E(D(real)) 0.507250189781189\n",
      "epoch 148 g_loss 0.7902084589004517 d_loss 1.3914425373077393 E(D(fake)) 0.5098464488983154 E(D(real)) 0.5075143575668335\n",
      "epoch 149 g_loss 0.7881903052330017 d_loss 1.3906017541885376 E(D(fake)) 0.509592592716217 E(D(real)) 0.5076790452003479\n",
      "epoch 150 g_loss 0.7869175672531128 d_loss 1.3884732723236084 E(D(fake)) 0.5089807510375977 E(D(real)) 0.5081212520599365\n",
      "epoch 151 g_loss 0.7858968377113342 d_loss 1.385568380355835 E(D(fake)) 0.508277177810669 E(D(real)) 0.5088751912117004\n",
      "epoch 152 g_loss 0.7849288582801819 d_loss 1.381698489189148 E(D(fake)) 0.5075739026069641 E(D(real)) 0.510129988193512\n",
      "epoch 153 g_loss 0.783825159072876 d_loss 1.3783904314041138 E(D(fake)) 0.5069705247879028 E(D(real)) 0.5112087726593018\n",
      "epoch 154 g_loss 0.782545804977417 d_loss 1.3749665021896362 E(D(fake)) 0.5064875483512878 E(D(real)) 0.5124682784080505\n",
      "epoch 155 g_loss 0.7810070514678955 d_loss 1.3700772523880005 E(D(fake)) 0.5061554908752441 E(D(real)) 0.5146734714508057\n",
      "epoch 156 g_loss 0.7791828513145447 d_loss 1.367532730102539 E(D(fake)) 0.5060054659843445 E(D(real)) 0.5158832669258118\n",
      "epoch 157 g_loss 0.769483745098114 d_loss 1.370269775390625 E(D(fake)) 0.5099176168441772 E(D(real)) 0.5186478495597839\n",
      "epoch 158 g_loss 0.7581371068954468 d_loss 1.3773205280303955 E(D(fake)) 0.5148388743400574 E(D(real)) 0.5203189849853516\n",
      "epoch 159 g_loss 0.7508763074874878 d_loss 1.3838868141174316 E(D(fake)) 0.5177826285362244 E(D(real)) 0.5200751423835754\n",
      "epoch 160 g_loss 0.7468324899673462 d_loss 1.3871456384658813 E(D(fake)) 0.5191382765769958 E(D(real)) 0.5198314785957336\n",
      "epoch 161 g_loss 0.745794415473938 d_loss 1.3841872215270996 E(D(fake)) 0.5189729928970337 E(D(real)) 0.521320641040802\n",
      "epoch 162 g_loss 0.7455998659133911 d_loss 1.3826611042022705 E(D(fake)) 0.5183796286582947 E(D(real)) 0.5214549899101257\n",
      "epoch 163 g_loss 0.7437933087348938 d_loss 1.3830735683441162 E(D(fake)) 0.5186507701873779 E(D(real)) 0.5216334462165833\n",
      "epoch 164 g_loss 0.7403696775436401 d_loss 1.3850579261779785 E(D(fake)) 0.5198165774345398 E(D(real)) 0.5218517780303955\n",
      "epoch 165 g_loss 0.7398943305015564 d_loss 1.3829108476638794 E(D(fake)) 0.5194730758666992 E(D(real)) 0.5227893590927124\n",
      "epoch 166 g_loss 0.744663417339325 d_loss 1.3749568462371826 E(D(fake)) 0.5163299441337585 E(D(real)) 0.523508608341217\n",
      "epoch 167 g_loss 0.743623673915863 d_loss 1.3737126588821411 E(D(fake)) 0.5161835551261902 E(D(real)) 0.5240921378135681\n",
      "epoch 168 g_loss 0.7368048429489136 d_loss 1.3829129934310913 E(D(fake)) 0.5190768241882324 E(D(real)) 0.5223133563995361\n",
      "epoch 169 g_loss 0.733328104019165 d_loss 1.3840372562408447 E(D(fake)) 0.5202820301055908 E(D(real)) 0.5230405330657959\n",
      "epoch 170 g_loss 0.7309740781784058 d_loss 1.3874764442443848 E(D(fake)) 0.520939290523529 E(D(real)) 0.5219137072563171\n",
      "epoch 171 g_loss 0.7286641001701355 d_loss 1.3862476348876953 E(D(fake)) 0.5216191411018372 E(D(real)) 0.5233943462371826\n",
      "epoch 172 g_loss 0.7274045944213867 d_loss 1.3877475261688232 E(D(fake)) 0.5217622518539429 E(D(real)) 0.5226484537124634\n",
      "epoch 173 g_loss 0.7280420660972595 d_loss 1.3837075233459473 E(D(fake)) 0.520927906036377 E(D(real)) 0.5239675045013428\n",
      "epoch 174 g_loss 0.7314898371696472 d_loss 1.3816131353378296 E(D(fake)) 0.5186197757720947 E(D(real)) 0.522432267665863\n",
      "epoch 175 g_loss 0.736057698726654 d_loss 1.3722950220108032 E(D(fake)) 0.5156885981559753 E(D(real)) 0.5241410732269287\n",
      "epoch 176 g_loss 0.73875492811203 d_loss 1.3679531812667847 E(D(fake)) 0.5137032866477966 E(D(real)) 0.5243715047836304\n",
      "epoch 177 g_loss 0.740086019039154 d_loss 1.3675262928009033 E(D(fake)) 0.5124214291572571 E(D(real)) 0.5230692625045776\n",
      "epoch 178 g_loss 0.7361975312232971 d_loss 1.366754412651062 E(D(fake)) 0.5138264894485474 E(D(real)) 0.5251591801643372\n",
      "epoch 179 g_loss 0.6839407086372375 d_loss 1.4254392385482788 E(D(fake)) 0.5410231947898865 E(D(real)) 0.524670422077179\n",
      "epoch 180 g_loss 0.6566568613052368 d_loss 1.4632675647735596 E(D(fake)) 0.5559601187705994 E(D(real)) 0.5221632122993469\n",
      "epoch 181 g_loss 0.6539860963821411 d_loss 1.4715155363082886 E(D(fake)) 0.5574793815612793 E(D(real)) 0.5195964574813843\n",
      "epoch 182 g_loss 0.6651840806007385 d_loss 1.4599418640136719 E(D(fake)) 0.5512194037437439 E(D(real)) 0.5183420181274414\n",
      "epoch 183 g_loss 0.6780639290809631 d_loss 1.4469038248062134 E(D(fake)) 0.543998658657074 E(D(real)) 0.5167273283004761\n",
      "epoch 184 g_loss 0.6892781853675842 d_loss 1.4374827146530151 E(D(fake)) 0.537672221660614 E(D(real)) 0.5144079327583313\n",
      "epoch 185 g_loss 0.6984333992004395 d_loss 1.4282751083374023 E(D(fake)) 0.5324371457099915 E(D(real)) 0.5132683515548706\n",
      "epoch 186 g_loss 0.7049144506454468 d_loss 1.4218844175338745 E(D(fake)) 0.5285871028900146 E(D(real)) 0.512322723865509\n",
      "epoch 187 g_loss 0.7074709534645081 d_loss 1.4193949699401855 E(D(fake)) 0.5268048048019409 E(D(real)) 0.5115752816200256\n",
      "epoch 188 g_loss 0.7100938558578491 d_loss 1.416515827178955 E(D(fake)) 0.5249829292297363 E(D(real)) 0.5109808444976807\n",
      "epoch 189 g_loss 0.7121157050132751 d_loss 1.4134786128997803 E(D(fake)) 0.5234907269477844 E(D(real)) 0.5108837485313416\n",
      "epoch 190 g_loss 0.7128046154975891 d_loss 1.4103155136108398 E(D(fake)) 0.5227031111717224 E(D(real)) 0.5116207599639893\n",
      "epoch 191 g_loss 0.7128919363021851 d_loss 1.4094465970993042 E(D(fake)) 0.5222309827804565 E(D(real)) 0.5115212798118591\n",
      "epoch 192 g_loss 0.7133088707923889 d_loss 1.4064736366271973 E(D(fake)) 0.521615743637085 E(D(real)) 0.5123351812362671\n",
      "epoch 193 g_loss 0.7147080302238464 d_loss 1.4020752906799316 E(D(fake)) 0.520512580871582 E(D(real)) 0.5134028196334839\n",
      "epoch 194 g_loss 0.7165290713310242 d_loss 1.3970105648040771 E(D(fake)) 0.5192008018493652 E(D(real)) 0.5145947337150574\n",
      "epoch 195 g_loss 0.7195054292678833 d_loss 1.3906073570251465 E(D(fake)) 0.5172944664955139 E(D(real)) 0.5159663558006287\n",
      "epoch 196 g_loss 0.7180668115615845 d_loss 1.3905155658721924 E(D(fake)) 0.5176817774772644 E(D(real)) 0.5164515376091003\n",
      "epoch 197 g_loss 0.7178515791893005 d_loss 1.3864808082580566 E(D(fake)) 0.5174685716629028 E(D(real)) 0.5183053016662598\n",
      "epoch 198 g_loss 0.7175732254981995 d_loss 1.3843027353286743 E(D(fake)) 0.5172984600067139 E(D(real)) 0.5192919969558716\n",
      "epoch 199 g_loss 0.716498613357544 d_loss 1.3833754062652588 E(D(fake)) 0.5175495147705078 E(D(real)) 0.5200890302658081\n",
      "epoch 200 g_loss 0.7154045701026917 d_loss 1.3819127082824707 E(D(fake)) 0.5178114175796509 E(D(real)) 0.5211915969848633\n",
      "epoch 201 g_loss 0.713665246963501 d_loss 1.3807597160339355 E(D(fake)) 0.5184284448623657 E(D(real)) 0.522523820400238\n",
      "epoch 202 g_loss 0.7120401859283447 d_loss 1.3825949430465698 E(D(fake)) 0.5189985632896423 E(D(real)) 0.5221856236457825\n",
      "epoch 203 g_loss 0.7099820375442505 d_loss 1.3827025890350342 E(D(fake)) 0.5198239088058472 E(D(real)) 0.5230502486228943\n",
      "epoch 204 g_loss 0.7087210416793823 d_loss 1.3834308385849 E(D(fake)) 0.5202623605728149 E(D(real)) 0.5230739116668701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 205 g_loss 0.7069894075393677 d_loss 1.3832964897155762 E(D(fake)) 0.5209541320800781 E(D(real)) 0.5241629481315613\n",
      "epoch 206 g_loss 0.6916112303733826 d_loss 1.4018210172653198 E(D(fake)) 0.5288916230201721 E(D(real)) 0.5231207609176636\n",
      "epoch 207 g_loss 0.6811627149581909 d_loss 1.416473627090454 E(D(fake)) 0.5343993306159973 E(D(real)) 0.5216003656387329\n",
      "epoch 208 g_loss 0.6800603270530701 d_loss 1.4199061393737793 E(D(fake)) 0.5349624752998352 E(D(real)) 0.5204564332962036\n",
      "epoch 209 g_loss 0.6841068863868713 d_loss 1.417550802230835 E(D(fake)) 0.5327423810958862 E(D(real)) 0.519139289855957\n",
      "epoch 210 g_loss 0.6890139579772949 d_loss 1.4171886444091797 E(D(fake)) 0.5300319790840149 E(D(real)) 0.5162543654441833\n",
      "epoch 211 g_loss 0.6907625198364258 d_loss 1.4171152114868164 E(D(fake)) 0.5289874076843262 E(D(real)) 0.5151288509368896\n",
      "epoch 212 g_loss 0.6929490566253662 d_loss 1.418137550354004 E(D(fake)) 0.5277097225189209 E(D(real)) 0.5131789445877075\n",
      "epoch 213 g_loss 0.6966352462768555 d_loss 1.4164215326309204 E(D(fake)) 0.5256314277648926 E(D(real)) 0.5117314457893372\n",
      "epoch 214 g_loss 0.7018454670906067 d_loss 1.4135942459106445 E(D(fake)) 0.5227377414703369 E(D(real)) 0.5100516080856323\n",
      "epoch 215 g_loss 0.7064048647880554 d_loss 1.4105736017227173 E(D(fake)) 0.5201683640480042 E(D(real)) 0.5088090896606445\n",
      "epoch 216 g_loss 0.7116015553474426 d_loss 1.4087358713150024 E(D(fake)) 0.517244279384613 E(D(real)) 0.506685197353363\n",
      "epoch 217 g_loss 0.716181755065918 d_loss 1.404632806777954 E(D(fake)) 0.5146104097366333 E(D(real)) 0.5059340000152588\n",
      "epoch 218 g_loss 0.719814658164978 d_loss 1.4018149375915527 E(D(fake)) 0.5124642252922058 E(D(real)) 0.5051227807998657\n",
      "epoch 219 g_loss 0.7227208018302917 d_loss 1.399207592010498 E(D(fake)) 0.5106782913208008 E(D(real)) 0.5045678019523621\n",
      "epoch 220 g_loss 0.7242476344108582 d_loss 1.3975279331207275 E(D(fake)) 0.5095831751823425 E(D(real)) 0.504264771938324\n",
      "epoch 221 g_loss 0.7253093719482422 d_loss 1.3962838649749756 E(D(fake)) 0.5087288022041321 E(D(real)) 0.5040051937103271\n",
      "epoch 222 g_loss 0.7262433171272278 d_loss 1.3948194980621338 E(D(fake)) 0.5079408884048462 E(D(real)) 0.5039216876029968\n",
      "epoch 223 g_loss 0.725921630859375 d_loss 1.3939720392227173 E(D(fake)) 0.5077821016311646 E(D(real)) 0.5041714906692505\n",
      "epoch 224 g_loss 0.7238414883613586 d_loss 1.3952867984771729 E(D(fake)) 0.5085195302963257 E(D(real)) 0.5042489171028137\n",
      "epoch 225 g_loss 0.7209375500679016 d_loss 1.3968708515167236 E(D(fake)) 0.5097227692604065 E(D(real)) 0.5046559572219849\n",
      "epoch 226 g_loss 0.7190825939178467 d_loss 1.3979605436325073 E(D(fake)) 0.5104284286499023 E(D(real)) 0.5048202872276306\n",
      "epoch 227 g_loss 0.7176121473312378 d_loss 1.399121880531311 E(D(fake)) 0.5109633207321167 E(D(real)) 0.5047740340232849\n",
      "epoch 228 g_loss 0.7175526022911072 d_loss 1.397318720817566 E(D(fake)) 0.5108035206794739 E(D(real)) 0.5055045485496521\n",
      "epoch 229 g_loss 0.7178009748458862 d_loss 1.3966190814971924 E(D(fake)) 0.5104750394821167 E(D(real)) 0.5055186152458191\n",
      "epoch 230 g_loss 0.7181711792945862 d_loss 1.3947041034698486 E(D(fake)) 0.5100845098495483 E(D(real)) 0.5060753226280212\n",
      "epoch 231 g_loss 0.7180755734443665 d_loss 1.3942500352859497 E(D(fake)) 0.5099291205406189 E(D(real)) 0.5061771869659424\n",
      "epoch 232 g_loss 0.7163119912147522 d_loss 1.3959839344024658 E(D(fake)) 0.5106328725814819 E(D(real)) 0.5060154795646667\n",
      "epoch 233 g_loss 0.7143879532814026 d_loss 1.3970592021942139 E(D(fake)) 0.5114680528640747 E(D(real)) 0.5063335299491882\n",
      "epoch 234 g_loss 0.7128404378890991 d_loss 1.3984047174453735 E(D(fake)) 0.5121323466300964 E(D(real)) 0.5063427686691284\n",
      "epoch 235 g_loss 0.7120769023895264 d_loss 1.398820161819458 E(D(fake)) 0.5124059319496155 E(D(real)) 0.5064123868942261\n",
      "epoch 236 g_loss 0.7118123769760132 d_loss 1.3991522789001465 E(D(fake)) 0.5124328136444092 E(D(real)) 0.5062723159790039\n",
      "epoch 237 g_loss 0.7119007110595703 d_loss 1.3993407487869263 E(D(fake)) 0.5122923851013184 E(D(real)) 0.5060579180717468\n",
      "epoch 238 g_loss 0.711978018283844 d_loss 1.3990612030029297 E(D(fake)) 0.5121566653251648 E(D(real)) 0.5060440897941589\n",
      "epoch 239 g_loss 0.711969256401062 d_loss 1.3993903398513794 E(D(fake)) 0.5120809674263 E(D(real)) 0.5058251023292542\n",
      "epoch 240 g_loss 0.7114894390106201 d_loss 1.399925708770752 E(D(fake)) 0.5122705698013306 E(D(real)) 0.50574791431427\n",
      "epoch 241 g_loss 0.7111505270004272 d_loss 1.4014127254486084 E(D(fake)) 0.512397289276123 E(D(real)) 0.5051298141479492\n",
      "epoch 242 g_loss 0.7112147808074951 d_loss 1.402364730834961 E(D(fake)) 0.512320339679718 E(D(real)) 0.5045608282089233\n",
      "epoch 243 g_loss 0.7119384407997131 d_loss 1.4021958112716675 E(D(fake)) 0.5119132995605469 E(D(real)) 0.5042200088500977\n",
      "epoch 244 g_loss 0.7135197520256042 d_loss 1.4018982648849487 E(D(fake)) 0.5110501050949097 E(D(real)) 0.5035029053688049\n",
      "epoch 245 g_loss 0.7146917581558228 d_loss 1.4016616344451904 E(D(fake)) 0.510383129119873 E(D(real)) 0.5029211044311523\n",
      "epoch 246 g_loss 0.7158380746841431 d_loss 1.4015896320343018 E(D(fake)) 0.5097211003303528 E(D(real)) 0.5022706985473633\n",
      "epoch 247 g_loss 0.7173891067504883 d_loss 1.4010287523269653 E(D(fake)) 0.5088313221931458 E(D(real)) 0.5016440153121948\n",
      "epoch 248 g_loss 0.7192934155464172 d_loss 1.3994474411010742 E(D(fake)) 0.5077492594718933 E(D(real)) 0.501323938369751\n",
      "epoch 249 g_loss 0.72104811668396 d_loss 1.3982499837875366 E(D(fake)) 0.5067363977432251 E(D(real)) 0.5008741617202759\n",
      "epoch 250 g_loss 0.7224422693252563 d_loss 1.3967370986938477 E(D(fake)) 0.5058975219726562 E(D(real)) 0.5007767677307129\n",
      "epoch 251 g_loss 0.7239287495613098 d_loss 1.395383596420288 E(D(fake)) 0.5050033926963806 E(D(real)) 0.5005530118942261\n",
      "epoch 252 g_loss 0.7252810001373291 d_loss 1.3940322399139404 E(D(fake)) 0.5041723847389221 E(D(real)) 0.5003947019577026\n",
      "epoch 253 g_loss 0.7261061072349548 d_loss 1.392518162727356 E(D(fake)) 0.5036067366600037 E(D(real)) 0.5005624890327454\n",
      "epoch 254 g_loss 0.7267357110977173 d_loss 1.3912858963012695 E(D(fake)) 0.503146231174469 E(D(real)) 0.500709593296051\n",
      "epoch 255 g_loss 0.7271424531936646 d_loss 1.3902552127838135 E(D(fake)) 0.5027973651885986 E(D(real)) 0.5008673071861267\n",
      "epoch 256 g_loss 0.7271807789802551 d_loss 1.389498233795166 E(D(fake)) 0.5026344060897827 E(D(real)) 0.5010911822319031\n",
      "epoch 257 g_loss 0.7266815304756165 d_loss 1.3891828060150146 E(D(fake)) 0.5027493238449097 E(D(real)) 0.5013572573661804\n",
      "epoch 258 g_loss 0.7259736657142639 d_loss 1.3889102935791016 E(D(fake)) 0.5029682517051697 E(D(real)) 0.5017151832580566\n",
      "epoch 259 g_loss 0.7249358892440796 d_loss 1.38926100730896 E(D(fake)) 0.5033829808235168 E(D(real)) 0.5019615888595581\n",
      "epoch 260 g_loss 0.7238053679466248 d_loss 1.3895699977874756 E(D(fake)) 0.5038540363311768 E(D(real)) 0.5022770166397095\n",
      "epoch 261 g_loss 0.7228713631629944 d_loss 1.389533281326294 E(D(fake)) 0.5042343139648438 E(D(real)) 0.5026830434799194\n",
      "epoch 262 g_loss 0.7223792672157288 d_loss 1.3893704414367676 E(D(fake)) 0.5043985843658447 E(D(real)) 0.5029396414756775\n",
      "epoch 263 g_loss 0.7216101884841919 d_loss 1.3892993927001953 E(D(fake)) 0.5047054886817932 E(D(real)) 0.5032854676246643\n",
      "epoch 264 g_loss 0.7208556532859802 d_loss 1.389876127243042 E(D(fake)) 0.5050132870674133 E(D(real)) 0.5033124089241028\n",
      "epoch 265 g_loss 0.7202115654945374 d_loss 1.3897829055786133 E(D(fake)) 0.5052770376205444 E(D(real)) 0.5036307573318481\n",
      "epoch 266 g_loss 0.7195467352867126 d_loss 1.3900220394134521 E(D(fake)) 0.5055548548698425 E(D(real)) 0.5038041472434998\n",
      "epoch 267 g_loss 0.7175382375717163 d_loss 1.3923202753067017 E(D(fake)) 0.5065327882766724 E(D(real)) 0.5036416053771973\n",
      "epoch 268 g_loss 0.7160590291023254 d_loss 1.3938227891921997 E(D(fake)) 0.5072551369667053 E(D(real)) 0.5036227703094482\n",
      "epoch 269 g_loss 0.7153146862983704 d_loss 1.3950858116149902 E(D(fake)) 0.5076159238815308 E(D(real)) 0.5033577680587769\n",
      "epoch 270 g_loss 0.7152770161628723 d_loss 1.3959851264953613 E(D(fake)) 0.5076206922531128 E(D(real)) 0.5029118657112122\n",
      "epoch 271 g_loss 0.7157703638076782 d_loss 1.3963779211044312 E(D(fake)) 0.5073463320732117 E(D(real)) 0.5024303793907166\n",
      "epoch 272 g_loss 0.7163936495780945 d_loss 1.3964805603027344 E(D(fake)) 0.5070111751556396 E(D(real)) 0.50203537940979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 273 g_loss 0.717243492603302 d_loss 1.3965333700180054 E(D(fake)) 0.5065591931343079 E(D(real)) 0.5015403032302856\n",
      "epoch 274 g_loss 0.7180468440055847 d_loss 1.3964996337890625 E(D(fake)) 0.5061221718788147 E(D(real)) 0.5011101365089417\n",
      "epoch 275 g_loss 0.7188937067985535 d_loss 1.3960773944854736 E(D(fake)) 0.5056608319282532 E(D(real)) 0.500851571559906\n",
      "epoch 276 g_loss 0.7196083068847656 d_loss 1.3957678079605103 E(D(fake)) 0.5052643418312073 E(D(real)) 0.5005986094474792\n",
      "epoch 277 g_loss 0.7202295660972595 d_loss 1.3955702781677246 E(D(fake)) 0.5049128532409668 E(D(real)) 0.5003470778465271\n",
      "epoch 278 g_loss 0.7206553816795349 d_loss 1.3951404094696045 E(D(fake)) 0.5046650767326355 E(D(real)) 0.5003131628036499\n",
      "epoch 279 g_loss 0.720604658126831 d_loss 1.3954534530639648 E(D(fake)) 0.5046579837799072 E(D(real)) 0.5001477003097534\n",
      "epoch 280 g_loss 0.7204632759094238 d_loss 1.3957431316375732 E(D(fake)) 0.5046915411949158 E(D(real)) 0.5000318288803101\n",
      "epoch 281 g_loss 0.7203736305236816 d_loss 1.395552396774292 E(D(fake)) 0.5047056078910828 E(D(real)) 0.5001330375671387\n",
      "epoch 282 g_loss 0.7202897667884827 d_loss 1.3957116603851318 E(D(fake)) 0.5047106742858887 E(D(real)) 0.5000590682029724\n",
      "epoch 283 g_loss 0.7201641201972961 d_loss 1.39543879032135 E(D(fake)) 0.5047449469566345 E(D(real)) 0.5002302527427673\n",
      "epoch 284 g_loss 0.7198916077613831 d_loss 1.3954261541366577 E(D(fake)) 0.504849910736084 E(D(real)) 0.5003362894058228\n",
      "epoch 285 g_loss 0.719582736492157 d_loss 1.3953864574432373 E(D(fake)) 0.5049801468849182 E(D(real)) 0.5004863142967224\n",
      "epoch 286 g_loss 0.7192803621292114 d_loss 1.395695447921753 E(D(fake)) 0.5051109790802002 E(D(real)) 0.5004667043685913\n",
      "epoch 287 g_loss 0.7190214991569519 d_loss 1.395378828048706 E(D(fake)) 0.5052252411842346 E(D(real)) 0.5007364749908447\n",
      "epoch 288 g_loss 0.718837320804596 d_loss 1.3950037956237793 E(D(fake)) 0.5052973031997681 E(D(real)) 0.5009934306144714\n",
      "epoch 289 g_loss 0.7187473773956299 d_loss 1.3947217464447021 E(D(fake)) 0.5053300261497498 E(D(real)) 0.5011686682701111\n",
      "epoch 290 g_loss 0.718746542930603 d_loss 1.393831729888916 E(D(fake)) 0.5053161382675171 E(D(real)) 0.5015988349914551\n",
      "epoch 291 g_loss 0.7188010215759277 d_loss 1.393357515335083 E(D(fake)) 0.5052738189697266 E(D(real)) 0.5017983913421631\n",
      "epoch 292 g_loss 0.7188600301742554 d_loss 1.393004059791565 E(D(fake)) 0.5052295327186584 E(D(real)) 0.5019437670707703\n",
      "epoch 293 g_loss 0.7185097932815552 d_loss 1.393058180809021 E(D(fake)) 0.505402147769928 E(D(real)) 0.5020856857299805\n",
      "epoch 294 g_loss 0.7181925177574158 d_loss 1.3929567337036133 E(D(fake)) 0.505558431148529 E(D(real)) 0.5022953748703003\n",
      "epoch 295 g_loss 0.718097448348999 d_loss 1.3922240734100342 E(D(fake)) 0.5056034922599792 E(D(real)) 0.5027071237564087\n",
      "epoch 296 g_loss 0.7179466485977173 d_loss 1.392966866493225 E(D(fake)) 0.5056779980659485 E(D(real)) 0.5024275183677673\n",
      "epoch 297 g_loss 0.7176302075386047 d_loss 1.3934082984924316 E(D(fake)) 0.5058425664901733 E(D(real)) 0.5023732781410217\n",
      "epoch 298 g_loss 0.7178313732147217 d_loss 1.3940610885620117 E(D(fake)) 0.5057459473609924 E(D(real)) 0.5019547939300537\n",
      "epoch 299 g_loss 0.7186073660850525 d_loss 1.3931713104248047 E(D(fake)) 0.5053442716598511 E(D(real)) 0.5019853711128235\n",
      "epoch 300 g_loss 0.7197771072387695 d_loss 1.3926513195037842 E(D(fake)) 0.5047338604927063 E(D(real)) 0.5016354918479919\n",
      "epoch 301 g_loss 0.7208039164543152 d_loss 1.3918970823287964 E(D(fake)) 0.5041861534118652 E(D(real)) 0.501462996006012\n",
      "epoch 302 g_loss 0.7214500308036804 d_loss 1.3916313648223877 E(D(fake)) 0.5038272142410278 E(D(real)) 0.5012302398681641\n",
      "epoch 303 g_loss 0.7220604419708252 d_loss 1.391300916671753 E(D(fake)) 0.5034770965576172 E(D(real)) 0.5010448694229126\n",
      "epoch 304 g_loss 0.7220063209533691 d_loss 1.3915941715240479 E(D(fake)) 0.5034648776054382 E(D(real)) 0.5008821487426758\n",
      "epoch 305 g_loss 0.7214664220809937 d_loss 1.3922092914581299 E(D(fake)) 0.5036993622779846 E(D(real)) 0.5008038878440857\n",
      "epoch 306 g_loss 0.7208334803581238 d_loss 1.3928968906402588 E(D(fake)) 0.5039966702461243 E(D(real)) 0.5007645487785339\n",
      "epoch 307 g_loss 0.7198666334152222 d_loss 1.393723726272583 E(D(fake)) 0.5044674873352051 E(D(real)) 0.5008329153060913\n",
      "epoch 308 g_loss 0.719201385974884 d_loss 1.3945927619934082 E(D(fake)) 0.5047807097434998 E(D(real)) 0.5007084608078003\n",
      "epoch 309 g_loss 0.7189913392066956 d_loss 1.3945122957229614 E(D(fake)) 0.5048783421516418 E(D(real)) 0.5008454918861389\n",
      "epoch 310 g_loss 0.7191592454910278 d_loss 1.3944497108459473 E(D(fake)) 0.5047883987426758 E(D(real)) 0.5007867813110352\n",
      "epoch 311 g_loss 0.7196007370948792 d_loss 1.3939406871795654 E(D(fake)) 0.5045530796051025 E(D(real)) 0.5008022785186768\n",
      "epoch 312 g_loss 0.7202387452125549 d_loss 1.3933756351470947 E(D(fake)) 0.5042286515235901 E(D(real)) 0.500758171081543\n",
      "epoch 313 g_loss 0.7209904193878174 d_loss 1.3929476737976074 E(D(fake)) 0.5038435459136963 E(D(real)) 0.5005896091461182\n",
      "epoch 314 g_loss 0.7215403914451599 d_loss 1.3925280570983887 E(D(fake)) 0.5035576224327087 E(D(real)) 0.50050288438797\n",
      "epoch 315 g_loss 0.7222362160682678 d_loss 1.3917839527130127 E(D(fake)) 0.5031921863555908 E(D(real)) 0.5005046129226685\n",
      "epoch 316 g_loss 0.7222952842712402 d_loss 1.3920960426330566 E(D(fake)) 0.5031495690345764 E(D(real)) 0.5003207921981812\n",
      "epoch 317 g_loss 0.721886396408081 d_loss 1.3927907943725586 E(D(fake)) 0.5033450126647949 E(D(real)) 0.500170111656189\n",
      "epoch 318 g_loss 0.7216247916221619 d_loss 1.3936712741851807 E(D(fake)) 0.5034705400466919 E(D(real)) 0.49985960125923157\n",
      "epoch 319 g_loss 0.7214685678482056 d_loss 1.3941915035247803 E(D(fake)) 0.5035451054573059 E(D(real)) 0.4996691048145294\n",
      "epoch 320 g_loss 0.7214913368225098 d_loss 1.3941748142242432 E(D(fake)) 0.50352942943573 E(D(real)) 0.4996546804904938\n",
      "epoch 321 g_loss 0.7215524911880493 d_loss 1.3945910930633545 E(D(fake)) 0.5034986734390259 E(D(real)) 0.4994162917137146\n",
      "epoch 322 g_loss 0.7217400670051575 d_loss 1.3942363262176514 E(D(fake)) 0.5034011006355286 E(D(real)) 0.49950098991394043\n",
      "epoch 323 g_loss 0.7212327718734741 d_loss 1.3946495056152344 E(D(fake)) 0.503652036190033 E(D(real)) 0.49954450130462646\n",
      "epoch 324 g_loss 0.7208008766174316 d_loss 1.3948352336883545 E(D(fake)) 0.5038763880729675 E(D(real)) 0.49966922402381897\n",
      "epoch 325 g_loss 0.7204275727272034 d_loss 1.3950304985046387 E(D(fake)) 0.5040661692619324 E(D(real)) 0.49976375699043274\n",
      "epoch 326 g_loss 0.7199241518974304 d_loss 1.3954753875732422 E(D(fake)) 0.5043308734893799 E(D(real)) 0.49980399012565613\n",
      "epoch 327 g_loss 0.7195892333984375 d_loss 1.3951739072799683 E(D(fake)) 0.504513144493103 E(D(real)) 0.5001319050788879\n",
      "epoch 328 g_loss 0.719269871711731 d_loss 1.395444631576538 E(D(fake)) 0.5046910047531128 E(D(real)) 0.5001774430274963\n",
      "epoch 329 g_loss 0.7191436886787415 d_loss 1.3947398662567139 E(D(fake)) 0.5047719478607178 E(D(real)) 0.5006115436553955\n",
      "epoch 330 g_loss 0.719219982624054 d_loss 1.3944568634033203 E(D(fake)) 0.5047594904899597 E(D(real)) 0.5007397532463074\n",
      "epoch 331 g_loss 0.719456672668457 d_loss 1.3935679197311401 E(D(fake)) 0.5046650767326355 E(D(real)) 0.5010859370231628\n",
      "epoch 332 g_loss 0.719849169254303 d_loss 1.3928923606872559 E(D(fake)) 0.5044867992401123 E(D(real)) 0.5012475252151489\n",
      "epoch 333 g_loss 0.7203139066696167 d_loss 1.3917880058288574 E(D(fake)) 0.504269003868103 E(D(real)) 0.5015802383422852\n",
      "epoch 334 g_loss 0.720832884311676 d_loss 1.3918063640594482 E(D(fake)) 0.5040194392204285 E(D(real)) 0.5013223886489868\n",
      "epoch 335 g_loss 0.7214598059654236 d_loss 1.3901965618133545 E(D(fake)) 0.503716766834259 E(D(real)) 0.5018327236175537\n",
      "epoch 336 g_loss 0.7218571305274963 d_loss 1.3895206451416016 E(D(fake)) 0.5035200715065002 E(D(real)) 0.5019704699516296\n",
      "epoch 337 g_loss 0.722338855266571 d_loss 1.3894760608673096 E(D(fake)) 0.5032843947410583 E(D(real)) 0.5017579197883606\n",
      "epoch 338 g_loss 0.7227845191955566 d_loss 1.3888304233551025 E(D(fake)) 0.5030608177185059 E(D(real)) 0.5018612742424011\n",
      "epoch 339 g_loss 0.7228615880012512 d_loss 1.389173984527588 E(D(fake)) 0.5030225515365601 E(D(real)) 0.5016670823097229\n",
      "epoch 340 g_loss 0.7223331928253174 d_loss 1.3901886940002441 E(D(fake)) 0.503292441368103 E(D(real)) 0.5014345049858093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 341 g_loss 0.7216761708259583 d_loss 1.391875982284546 E(D(fake)) 0.5036349892616272 E(D(real)) 0.5009353756904602\n",
      "epoch 342 g_loss 0.7220112681388855 d_loss 1.3928816318511963 E(D(fake)) 0.5034793615341187 E(D(real)) 0.5002807974815369\n",
      "epoch 343 g_loss 0.7233982086181641 d_loss 1.3928163051605225 E(D(fake)) 0.5027785301208496 E(D(real)) 0.4996134340763092\n",
      "epoch 344 g_loss 0.7247170805931091 d_loss 1.3927712440490723 E(D(fake)) 0.5020987391471863 E(D(real)) 0.49894407391548157\n",
      "epoch 345 g_loss 0.7257304191589355 d_loss 1.3924956321716309 E(D(fake)) 0.5015702247619629 E(D(real)) 0.4985562264919281\n",
      "epoch 346 g_loss 0.7259218096733093 d_loss 1.3929369449615479 E(D(fake)) 0.5014389753341675 E(D(real)) 0.49819108843803406\n",
      "epoch 347 g_loss 0.7256107926368713 d_loss 1.3930985927581787 E(D(fake)) 0.5015612840652466 E(D(real)) 0.49821990728378296\n",
      "epoch 348 g_loss 0.7251038551330566 d_loss 1.3933908939361572 E(D(fake)) 0.5017954111099243 E(D(real)) 0.4983043372631073\n",
      "epoch 349 g_loss 0.7245462536811829 d_loss 1.3935714960098267 E(D(fake)) 0.5020583868026733 E(D(real)) 0.49847158789634705\n",
      "epoch 350 g_loss 0.7239640951156616 d_loss 1.3936071395874023 E(D(fake)) 0.5023389458656311 E(D(real)) 0.49873271584510803\n",
      "epoch 351 g_loss 0.7236258387565613 d_loss 1.3932998180389404 E(D(fake)) 0.502505898475647 E(D(real)) 0.4990602433681488\n",
      "epoch 352 g_loss 0.7231250405311584 d_loss 1.3928006887435913 E(D(fake)) 0.5027487874031067 E(D(real)) 0.49954286217689514\n",
      "epoch 353 g_loss 0.7228610515594482 d_loss 1.3923938274383545 E(D(fake)) 0.5028780698776245 E(D(real)) 0.49988558888435364\n",
      "epoch 354 g_loss 0.7227658629417419 d_loss 1.3916676044464111 E(D(fake)) 0.502925455570221 E(D(real)) 0.5003045201301575\n",
      "epoch 355 g_loss 0.7228872776031494 d_loss 1.390355110168457 E(D(fake)) 0.5028564929962158 E(D(real)) 0.5008860230445862\n",
      "epoch 356 g_loss 0.7228941321372986 d_loss 1.389404058456421 E(D(fake)) 0.502846896648407 E(D(real)) 0.5013538599014282\n",
      "epoch 357 g_loss 0.7227572202682495 d_loss 1.3880715370178223 E(D(fake)) 0.502915620803833 E(D(real)) 0.502095639705658\n",
      "epoch 358 g_loss 0.7224762439727783 d_loss 1.3872191905975342 E(D(fake)) 0.5030449628829956 E(D(real)) 0.5026558637619019\n",
      "epoch 359 g_loss 0.7222025394439697 d_loss 1.3864672183990479 E(D(fake)) 0.5031695365905762 E(D(real)) 0.5031595230102539\n",
      "epoch 360 g_loss 0.7219494581222534 d_loss 1.384775161743164 E(D(fake)) 0.5032855868339539 E(D(real)) 0.5041409730911255\n",
      "epoch 361 g_loss 0.7215558290481567 d_loss 1.384204626083374 E(D(fake)) 0.5034719705581665 E(D(real)) 0.5046355128288269\n",
      "epoch 362 g_loss 0.7207695841789246 d_loss 1.3838104009628296 E(D(fake)) 0.5038567781448364 E(D(real)) 0.5052313208580017\n",
      "epoch 363 g_loss 0.7197386622428894 d_loss 1.3842759132385254 E(D(fake)) 0.5043771266937256 E(D(real)) 0.5055415034294128\n",
      "epoch 364 g_loss 0.7180957794189453 d_loss 1.3862255811691284 E(D(fake)) 0.5052146911621094 E(D(real)) 0.505406379699707\n",
      "epoch 365 g_loss 0.7162743210792542 d_loss 1.3884071111679077 E(D(fake)) 0.5061601400375366 E(D(real)) 0.505274772644043\n",
      "epoch 366 g_loss 0.7153521776199341 d_loss 1.3896667957305908 E(D(fake)) 0.5066695809364319 E(D(real)) 0.5051755905151367\n",
      "epoch 367 g_loss 0.7152782678604126 d_loss 1.3916343450546265 E(D(fake)) 0.506753146648407 E(D(real)) 0.504260241985321\n",
      "epoch 368 g_loss 0.7159243822097778 d_loss 1.3930081129074097 E(D(fake)) 0.5064718127250671 E(D(real)) 0.5032724738121033\n",
      "epoch 369 g_loss 0.7172735929489136 d_loss 1.3935003280639648 E(D(fake)) 0.5058406591415405 E(D(real)) 0.5023917555809021\n",
      "epoch 370 g_loss 0.718852698802948 d_loss 1.3929381370544434 E(D(fake)) 0.505081057548523 E(D(real)) 0.5018814206123352\n",
      "epoch 371 g_loss 0.7201327085494995 d_loss 1.3935105800628662 E(D(fake)) 0.5044562220573425 E(D(real)) 0.5009514689445496\n",
      "epoch 372 g_loss 0.7215257883071899 d_loss 1.3936965465545654 E(D(fake)) 0.5037757754325867 E(D(real)) 0.5001649260520935\n",
      "epoch 373 g_loss 0.7229223847389221 d_loss 1.393469214439392 E(D(fake)) 0.5030879378318787 E(D(real)) 0.499580442905426\n",
      "epoch 374 g_loss 0.7240957021713257 d_loss 1.3933659791946411 E(D(fake)) 0.5025033950805664 E(D(real)) 0.499040424823761\n",
      "epoch 375 g_loss 0.7245641350746155 d_loss 1.3935186862945557 E(D(fake)) 0.502262532711029 E(D(real)) 0.49871736764907837\n",
      "epoch 376 g_loss 0.7245180010795593 d_loss 1.3941115140914917 E(D(fake)) 0.5022839307785034 E(D(real)) 0.49843430519104004\n",
      "epoch 377 g_loss 0.7243196964263916 d_loss 1.3945038318634033 E(D(fake)) 0.5023821592330933 E(D(real)) 0.4983345866203308\n",
      "epoch 378 g_loss 0.7241305112838745 d_loss 1.3942866325378418 E(D(fake)) 0.5024900436401367 E(D(real)) 0.49855172634124756\n",
      "epoch 379 g_loss 0.7239637970924377 d_loss 1.3941750526428223 E(D(fake)) 0.5025917887687683 E(D(real)) 0.49871236085891724\n",
      "epoch 380 g_loss 0.7236392498016357 d_loss 1.394386649131775 E(D(fake)) 0.502781093120575 E(D(real)) 0.49880120158195496\n",
      "epoch 381 g_loss 0.7233455777168274 d_loss 1.3946352005004883 E(D(fake)) 0.50295490026474 E(D(real)) 0.49884968996047974\n",
      "epoch 382 g_loss 0.7234325408935547 d_loss 1.3947442770004272 E(D(fake)) 0.5029319524765015 E(D(real)) 0.49877089262008667\n",
      "epoch 383 g_loss 0.7236449122428894 d_loss 1.3943994045257568 E(D(fake)) 0.5028442144393921 E(D(real)) 0.49884894490242004\n",
      "epoch 384 g_loss 0.7239508628845215 d_loss 1.3942759037017822 E(D(fake)) 0.5027055740356445 E(D(real)) 0.49877217411994934\n",
      "epoch 385 g_loss 0.7242779731750488 d_loss 1.393450379371643 E(D(fake)) 0.5025493502616882 E(D(real)) 0.4990234375\n",
      "epoch 386 g_loss 0.7245131731033325 d_loss 1.3931933641433716 E(D(fake)) 0.5024380683898926 E(D(real)) 0.4990476965904236\n",
      "epoch 387 g_loss 0.7242345809936523 d_loss 1.3929593563079834 E(D(fake)) 0.5025937557220459 E(D(real)) 0.499327689409256\n",
      "epoch 388 g_loss 0.723545491695404 d_loss 1.3928883075714111 E(D(fake)) 0.5029639005661011 E(D(real)) 0.4997383654117584\n",
      "epoch 389 g_loss 0.7234140038490295 d_loss 1.3931868076324463 E(D(fake)) 0.5030485391616821 E(D(real)) 0.4996712803840637\n",
      "epoch 390 g_loss 0.7235317230224609 d_loss 1.3932737112045288 E(D(fake)) 0.5029972791671753 E(D(real)) 0.49957942962646484\n",
      "epoch 391 g_loss 0.7237522602081299 d_loss 1.393303394317627 E(D(fake)) 0.5028977394104004 E(D(real)) 0.49946296215057373\n",
      "epoch 392 g_loss 0.724250853061676 d_loss 1.3927538394927979 E(D(fake)) 0.5026556849479675 E(D(real)) 0.4994966387748718\n",
      "epoch 393 g_loss 0.7245786190032959 d_loss 1.3921256065368652 E(D(fake)) 0.5024932622909546 E(D(real)) 0.49964991211891174\n",
      "epoch 394 g_loss 0.7244717478752136 d_loss 1.3925933837890625 E(D(fake)) 0.5025515556335449 E(D(real)) 0.49947649240493774\n",
      "epoch 395 g_loss 0.7241796851158142 d_loss 1.3924362659454346 E(D(fake)) 0.5026975274085999 E(D(real)) 0.4997035264968872\n",
      "epoch 396 g_loss 0.724132239818573 d_loss 1.3923165798187256 E(D(fake)) 0.5027164220809937 E(D(real)) 0.49978306889533997\n",
      "epoch 397 g_loss 0.7241587042808533 d_loss 1.3916230201721191 E(D(fake)) 0.5026940107345581 E(D(real)) 0.50009685754776\n",
      "epoch 398 g_loss 0.724021852016449 d_loss 1.3913781642913818 E(D(fake)) 0.5027581453323364 E(D(real)) 0.5002884268760681\n",
      "epoch 399 g_loss 0.7239946722984314 d_loss 1.3906769752502441 E(D(fake)) 0.5027567148208618 E(D(real)) 0.5006356239318848\n",
      "epoch 400 g_loss 0.7236810922622681 d_loss 1.3896329402923584 E(D(fake)) 0.5028936266899109 E(D(real)) 0.5012996792793274\n",
      "epoch 401 g_loss 0.7231162786483765 d_loss 1.3897814750671387 E(D(fake)) 0.5031560659408569 E(D(real)) 0.5014803409576416\n",
      "epoch 402 g_loss 0.7223687171936035 d_loss 1.3895108699798584 E(D(fake)) 0.5035213828086853 E(D(real)) 0.5019875764846802\n",
      "epoch 403 g_loss 0.721509575843811 d_loss 1.3891233205795288 E(D(fake)) 0.503948450088501 E(D(real)) 0.5026305317878723\n",
      "epoch 404 g_loss 0.7209789752960205 d_loss 1.388927698135376 E(D(fake)) 0.5042163729667664 E(D(real)) 0.5029975771903992\n",
      "epoch 405 g_loss 0.7206896543502808 d_loss 1.3886117935180664 E(D(fake)) 0.5043665170669556 E(D(real)) 0.5033072829246521\n",
      "epoch 406 g_loss 0.7205688953399658 d_loss 1.3880285024642944 E(D(fake)) 0.5044395327568054 E(D(real)) 0.5036924481391907\n",
      "epoch 407 g_loss 0.7200453877449036 d_loss 1.3879449367523193 E(D(fake)) 0.5047296285629272 E(D(real)) 0.5040437579154968\n",
      "epoch 408 g_loss 0.7195203304290771 d_loss 1.3892459869384766 E(D(fake)) 0.5050129890441895 E(D(real)) 0.5036917328834534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 409 g_loss 0.7195353507995605 d_loss 1.3901352882385254 E(D(fake)) 0.5050246715545654 E(D(real)) 0.503237783908844\n",
      "epoch 410 g_loss 0.7200562953948975 d_loss 1.3910672664642334 E(D(fake)) 0.5047808289527893 E(D(real)) 0.5025389194488525\n",
      "epoch 411 g_loss 0.7207293510437012 d_loss 1.3923981189727783 E(D(fake)) 0.5044553279876709 E(D(real)) 0.5015164017677307\n",
      "epoch 412 g_loss 0.7216809988021851 d_loss 1.39241623878479 E(D(fake)) 0.5039841532707214 E(D(real)) 0.5010248422622681\n",
      "epoch 413 g_loss 0.722724199295044 d_loss 1.3924990892410278 E(D(fake)) 0.503463089466095 E(D(real)) 0.5004493594169617\n",
      "epoch 414 g_loss 0.7235986590385437 d_loss 1.3926823139190674 E(D(fake)) 0.5030169486999512 E(D(real)) 0.49990156292915344\n",
      "epoch 415 g_loss 0.7244849801063538 d_loss 1.3927738666534424 E(D(fake)) 0.5025722980499268 E(D(real)) 0.4993995130062103\n",
      "epoch 416 g_loss 0.7252686023712158 d_loss 1.3931617736816406 E(D(fake)) 0.502184271812439 E(D(real)) 0.4988108277320862\n",
      "epoch 417 g_loss 0.7260288596153259 d_loss 1.3931117057800293 E(D(fake)) 0.5017977356910706 E(D(real)) 0.498444139957428\n",
      "epoch 418 g_loss 0.7267847061157227 d_loss 1.393057942390442 E(D(fake)) 0.5014195442199707 E(D(real)) 0.49809321761131287\n",
      "epoch 419 g_loss 0.7273160219192505 d_loss 1.392878770828247 E(D(fake)) 0.5011378526687622 E(D(real)) 0.49789297580718994\n",
      "epoch 420 g_loss 0.7274671792984009 d_loss 1.3927602767944336 E(D(fake)) 0.5010440945625305 E(D(real)) 0.4978574812412262\n",
      "epoch 421 g_loss 0.727420449256897 d_loss 1.3929365873336792 E(D(fake)) 0.5010573863983154 E(D(real)) 0.49778228998184204\n",
      "epoch 422 g_loss 0.7271856069564819 d_loss 1.3927056789398193 E(D(fake)) 0.5011608004570007 E(D(real)) 0.4979957342147827\n",
      "epoch 423 g_loss 0.7269969582557678 d_loss 1.392804503440857 E(D(fake)) 0.5012469291687012 E(D(real)) 0.49803227186203003\n",
      "epoch 424 g_loss 0.7269420027732849 d_loss 1.3929290771484375 E(D(fake)) 0.5012716054916382 E(D(real)) 0.4979981482028961\n",
      "epoch 425 g_loss 0.7272494435310364 d_loss 1.3925913572311401 E(D(fake)) 0.5011171698570251 E(D(real)) 0.4980151057243347\n",
      "epoch 426 g_loss 0.7276472449302673 d_loss 1.3929429054260254 E(D(fake)) 0.5009148120880127 E(D(real)) 0.4976460337638855\n",
      "epoch 427 g_loss 0.7277565598487854 d_loss 1.3929970264434814 E(D(fake)) 0.500855565071106 E(D(real)) 0.4975622296333313\n",
      "epoch 428 g_loss 0.7277791500091553 d_loss 1.3935129642486572 E(D(fake)) 0.5008479952812195 E(D(real)) 0.4972987771034241\n",
      "epoch 429 g_loss 0.7279059886932373 d_loss 1.394251823425293 E(D(fake)) 0.5007834434509277 E(D(real)) 0.4968651235103607\n",
      "epoch 430 g_loss 0.728138267993927 d_loss 1.3946797847747803 E(D(fake)) 0.5006645321846008 E(D(real)) 0.4965319037437439\n",
      "epoch 431 g_loss 0.7282743453979492 d_loss 1.3951679468154907 E(D(fake)) 0.5005932450294495 E(D(real)) 0.4962208867073059\n",
      "epoch 432 g_loss 0.7285867929458618 d_loss 1.3951542377471924 E(D(fake)) 0.5004248023033142 E(D(real)) 0.49606165289878845\n",
      "epoch 433 g_loss 0.7290010452270508 d_loss 1.3950071334838867 E(D(fake)) 0.5001924633979797 E(D(real)) 0.49589163064956665\n",
      "epoch 434 g_loss 0.729106605052948 d_loss 1.3948040008544922 E(D(fake)) 0.5001184940338135 E(D(real)) 0.4959145188331604\n",
      "epoch 435 g_loss 0.7289516925811768 d_loss 1.3942830562591553 E(D(fake)) 0.5001723766326904 E(D(real)) 0.4962223172187805\n",
      "epoch 436 g_loss 0.7286173701286316 d_loss 1.3938825130462646 E(D(fake)) 0.500312328338623 E(D(real)) 0.49655643105506897\n",
      "epoch 437 g_loss 0.7281631231307983 d_loss 1.3935109376907349 E(D(fake)) 0.500520646572113 E(D(real)) 0.4969438314437866\n",
      "epoch 438 g_loss 0.7276186347007751 d_loss 1.392810344696045 E(D(fake)) 0.5007720589637756 E(D(real)) 0.4975413382053375\n",
      "epoch 439 g_loss 0.727092981338501 d_loss 1.3922665119171143 E(D(fake)) 0.5010243654251099 E(D(real)) 0.4980625808238983\n",
      "epoch 440 g_loss 0.7268832921981812 d_loss 1.3916547298431396 E(D(fake)) 0.5011031627655029 E(D(real)) 0.4984542429447174\n",
      "epoch 441 g_loss 0.7264788746833801 d_loss 1.3905673027038574 E(D(fake)) 0.501290500164032 E(D(real)) 0.49918851256370544\n",
      "epoch 442 g_loss 0.7256637215614319 d_loss 1.390179991722107 E(D(fake)) 0.5016852617263794 E(D(real)) 0.4997956454753876\n",
      "epoch 443 g_loss 0.724590003490448 d_loss 1.3909344673156738 E(D(fake)) 0.5022217631340027 E(D(real)) 0.49995389580726624\n",
      "epoch 444 g_loss 0.7237918972969055 d_loss 1.3916685581207275 E(D(fake)) 0.502632200717926 E(D(real)) 0.5000118613243103\n",
      "epoch 445 g_loss 0.7234577536582947 d_loss 1.3922163248062134 E(D(fake)) 0.5028146505355835 E(D(real)) 0.4999135434627533\n",
      "epoch 446 g_loss 0.7235950231552124 d_loss 1.3927110433578491 E(D(fake)) 0.5027658343315125 E(D(real)) 0.4996183514595032\n",
      "epoch 447 g_loss 0.7242048978805542 d_loss 1.3927277326583862 E(D(fake)) 0.5024777054786682 E(D(real)) 0.49931925535202026\n",
      "epoch 448 g_loss 0.7252219915390015 d_loss 1.3924908638000488 E(D(fake)) 0.5019819140434265 E(D(real)) 0.49893781542778015\n",
      "epoch 449 g_loss 0.7263954281806946 d_loss 1.3926527500152588 E(D(fake)) 0.5014010071754456 E(D(real)) 0.49827778339385986\n",
      "epoch 450 g_loss 0.7277531027793884 d_loss 1.3923814296722412 E(D(fake)) 0.500712513923645 E(D(real)) 0.49772724509239197\n",
      "epoch 451 g_loss 0.7287744879722595 d_loss 1.3917970657348633 E(D(fake)) 0.5001729726791382 E(D(real)) 0.4974724054336548\n",
      "epoch 452 g_loss 0.7294983863830566 d_loss 1.3916336297988892 E(D(fake)) 0.49977096915245056 E(D(real)) 0.4971534013748169\n",
      "epoch 453 g_loss 0.7296074032783508 d_loss 1.3917019367218018 E(D(fake)) 0.49966952204704285 E(D(real)) 0.49700912833213806\n",
      "epoch 454 g_loss 0.7293773889541626 d_loss 1.391274333000183 E(D(fake)) 0.49975845217704773 E(D(real)) 0.49729323387145996\n",
      "epoch 455 g_loss 0.7291134595870972 d_loss 1.3910447359085083 E(D(fake)) 0.4998819828033447 E(D(real)) 0.4975341260433197\n",
      "epoch 456 g_loss 0.7290230989456177 d_loss 1.390718936920166 E(D(fake)) 0.4999137222766876 E(D(real)) 0.4977327287197113\n",
      "epoch 457 g_loss 0.7289332747459412 d_loss 1.3905510902404785 E(D(fake)) 0.4999372065067291 E(D(real)) 0.4978366494178772\n",
      "epoch 458 g_loss 0.7288484573364258 d_loss 1.390303373336792 E(D(fake)) 0.4999642074108124 E(D(real)) 0.49799031019210815\n",
      "epoch 459 g_loss 0.7287204265594482 d_loss 1.3901607990264893 E(D(fake)) 0.5000105500221252 E(D(real)) 0.4981040954589844\n",
      "epoch 460 g_loss 0.7286301255226135 d_loss 1.3899140357971191 E(D(fake)) 0.5000402927398682 E(D(real)) 0.4982571005821228\n",
      "epoch 461 g_loss 0.7285411357879639 d_loss 1.3899295330047607 E(D(fake)) 0.500063955783844 E(D(real)) 0.49827656149864197\n",
      "epoch 462 g_loss 0.7284184694290161 d_loss 1.3898358345031738 E(D(fake)) 0.5001099109649658 E(D(real)) 0.4983697235584259\n",
      "epoch 463 g_loss 0.7283778786659241 d_loss 1.3893487453460693 E(D(fake)) 0.5001204609870911 E(D(real)) 0.4986203610897064\n",
      "epoch 464 g_loss 0.728346586227417 d_loss 1.3893187046051025 E(D(fake)) 0.5001163482666016 E(D(real)) 0.4986295998096466\n",
      "epoch 465 g_loss 0.728278398513794 d_loss 1.388954758644104 E(D(fake)) 0.5001325607299805 E(D(real)) 0.498824805021286\n",
      "epoch 466 g_loss 0.7281774878501892 d_loss 1.389310598373413 E(D(fake)) 0.5001693367958069 E(D(real)) 0.49869078397750854\n",
      "epoch 467 g_loss 0.7281376123428345 d_loss 1.388847827911377 E(D(fake)) 0.5001716017723083 E(D(real)) 0.4989268481731415\n",
      "epoch 468 g_loss 0.7281318306922913 d_loss 1.388636827468872 E(D(fake)) 0.5001610517501831 E(D(real)) 0.49901923537254333\n",
      "epoch 469 g_loss 0.7282142043113708 d_loss 1.3883171081542969 E(D(fake)) 0.5001111626625061 E(D(real)) 0.4991290271282196\n",
      "epoch 470 g_loss 0.7282316088676453 d_loss 1.388394832611084 E(D(fake)) 0.5000872015953064 E(D(real)) 0.49907612800598145\n",
      "epoch 471 g_loss 0.728144109249115 d_loss 1.3885092735290527 E(D(fake)) 0.5001038312911987 E(D(real)) 0.4990275502204895\n",
      "epoch 472 g_loss 0.7280075550079346 d_loss 1.388936996459961 E(D(fake)) 0.5001619458198547 E(D(real)) 0.4988726079463959\n",
      "epoch 473 g_loss 0.7280842661857605 d_loss 1.3890950679779053 E(D(fake)) 0.5000966787338257 E(D(real)) 0.49872493743896484\n",
      "epoch 474 g_loss 0.7281957864761353 d_loss 1.389902114868164 E(D(fake)) 0.5000290870666504 E(D(real)) 0.49826547503471375\n",
      "epoch 475 g_loss 0.7284606099128723 d_loss 1.3898518085479736 E(D(fake)) 0.49988144636154175 E(D(real)) 0.4981369972229004\n",
      "epoch 476 g_loss 0.7287443280220032 d_loss 1.3901023864746094 E(D(fake)) 0.49971845746040344 E(D(real)) 0.497854083776474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 477 g_loss 0.7287042140960693 d_loss 1.3904340267181396 E(D(fake)) 0.49972090125083923 E(D(real)) 0.49768903851509094\n",
      "epoch 478 g_loss 0.7286074161529541 d_loss 1.3908627033233643 E(D(fake)) 0.4997599422931671 E(D(real)) 0.49751216173171997\n",
      "epoch 479 g_loss 0.7285595536231995 d_loss 1.391418695449829 E(D(fake)) 0.4997751712799072 E(D(real)) 0.497252494096756\n",
      "epoch 480 g_loss 0.7286895513534546 d_loss 1.391465187072754 E(D(fake)) 0.4996989667415619 E(D(real)) 0.49716103076934814\n",
      "epoch 481 g_loss 0.7286547422409058 d_loss 1.3914875984191895 E(D(fake)) 0.4996984899044037 E(D(real)) 0.4971442222595215\n",
      "epoch 482 g_loss 0.7283825874328613 d_loss 1.3916410207748413 E(D(fake)) 0.4998159110546112 E(D(real)) 0.4971746504306793\n",
      "epoch 483 g_loss 0.7278952598571777 d_loss 1.3915865421295166 E(D(fake)) 0.5000432729721069 E(D(real)) 0.49742212891578674\n",
      "epoch 484 g_loss 0.727410078048706 d_loss 1.3914281129837036 E(D(fake)) 0.5002764463424683 E(D(real)) 0.49773743748664856\n",
      "epoch 485 g_loss 0.726828396320343 d_loss 1.3914930820465088 E(D(fake)) 0.5005577206611633 E(D(real)) 0.49798068404197693\n",
      "epoch 486 g_loss 0.7262629270553589 d_loss 1.391096591949463 E(D(fake)) 0.5008455514907837 E(D(real)) 0.4984639286994934\n",
      "epoch 487 g_loss 0.7257250547409058 d_loss 1.3909645080566406 E(D(fake)) 0.5011188387870789 E(D(real)) 0.49880748987197876\n",
      "epoch 488 g_loss 0.7254210710525513 d_loss 1.3904380798339844 E(D(fake)) 0.5012738704681396 E(D(real)) 0.49922528862953186\n",
      "epoch 489 g_loss 0.7250694632530212 d_loss 1.389916181564331 E(D(fake)) 0.5014538764953613 E(D(real)) 0.49967244267463684\n",
      "epoch 490 g_loss 0.7247948050498962 d_loss 1.389716625213623 E(D(fake)) 0.5015939474105835 E(D(real)) 0.4999186098575592\n",
      "epoch 491 g_loss 0.7244827747344971 d_loss 1.3895093202590942 E(D(fake)) 0.5017607808113098 E(D(real)) 0.5001881122589111\n",
      "epoch 492 g_loss 0.7242976427078247 d_loss 1.3891265392303467 E(D(fake)) 0.5018635988235474 E(D(real)) 0.5004922151565552\n",
      "epoch 493 g_loss 0.7241361737251282 d_loss 1.3894023895263672 E(D(fake)) 0.501955509185791 E(D(real)) 0.5004420280456543\n",
      "epoch 494 g_loss 0.7241436839103699 d_loss 1.3892194032669067 E(D(fake)) 0.5019703507423401 E(D(real)) 0.5005559325218201\n",
      "epoch 495 g_loss 0.7244169116020203 d_loss 1.390197992324829 E(D(fake)) 0.5018552541732788 E(D(real)) 0.4999682307243347\n",
      "epoch 496 g_loss 0.7248868942260742 d_loss 1.3902411460876465 E(D(fake)) 0.5016400814056396 E(D(real)) 0.49973064661026\n",
      "epoch 497 g_loss 0.725573718547821 d_loss 1.3909971714019775 E(D(fake)) 0.5013164281845093 E(D(real)) 0.49903011322021484\n",
      "epoch 498 g_loss 0.7263178825378418 d_loss 1.3909571170806885 E(D(fake)) 0.5009560585021973 E(D(real)) 0.49868133664131165\n",
      "epoch 499 g_loss 0.727096676826477 d_loss 1.3914647102355957 E(D(fake)) 0.5005773305892944 E(D(real)) 0.4980432987213135\n",
      "epoch 500 g_loss 0.7277055978775024 d_loss 1.3916834592819214 E(D(fake)) 0.5002762675285339 E(D(real)) 0.4976288378238678\n",
      "epoch 501 g_loss 0.7279012203216553 d_loss 1.392284631729126 E(D(fake)) 0.5001803040504456 E(D(real)) 0.49723097681999207\n",
      "epoch 502 g_loss 0.7280276417732239 d_loss 1.3927127122879028 E(D(fake)) 0.5001155138015747 E(D(real)) 0.49695003032684326\n",
      "epoch 503 g_loss 0.7281095385551453 d_loss 1.3930540084838867 E(D(fake)) 0.5000734329223633 E(D(real)) 0.4967404901981354\n",
      "epoch 504 g_loss 0.7280482053756714 d_loss 1.3932394981384277 E(D(fake)) 0.5000981092453003 E(D(real)) 0.49666622281074524\n",
      "epoch 505 g_loss 0.7278253436088562 d_loss 1.3934531211853027 E(D(fake)) 0.5002057552337646 E(D(real)) 0.496662974357605\n",
      "epoch 506 g_loss 0.7274744510650635 d_loss 1.393375039100647 E(D(fake)) 0.500382661819458 E(D(real)) 0.496873676776886\n",
      "epoch 507 g_loss 0.7272260785102844 d_loss 1.3929917812347412 E(D(fake)) 0.5005079507827759 E(D(real)) 0.49719199538230896\n",
      "epoch 508 g_loss 0.72708660364151 d_loss 1.3924217224121094 E(D(fake)) 0.5005756616592407 E(D(real)) 0.49754005670547485\n",
      "epoch 509 g_loss 0.7268507480621338 d_loss 1.3916175365447998 E(D(fake)) 0.5006927847862244 E(D(real)) 0.49805593490600586\n",
      "epoch 510 g_loss 0.7266842722892761 d_loss 1.3903088569641113 E(D(fake)) 0.5007757544517517 E(D(real)) 0.49879568815231323\n",
      "epoch 511 g_loss 0.7265888452529907 d_loss 1.389970302581787 E(D(fake)) 0.5008264183998108 E(D(real)) 0.4990164339542389\n",
      "epoch 512 g_loss 0.7265828847885132 d_loss 1.3894665241241455 E(D(fake)) 0.5008254647254944 E(D(real)) 0.4992750585079193\n",
      "epoch 513 g_loss 0.7266963720321655 d_loss 1.3886553049087524 E(D(fake)) 0.500773549079895 E(D(real)) 0.4996310770511627\n",
      "epoch 514 g_loss 0.7269375920295715 d_loss 1.387784481048584 E(D(fake)) 0.5006499290466309 E(D(real)) 0.49994799494743347\n",
      "epoch 515 g_loss 0.7273234128952026 d_loss 1.3873512744903564 E(D(fake)) 0.5004473924636841 E(D(real)) 0.4999714493751526\n",
      "epoch 516 g_loss 0.7277393341064453 d_loss 1.3872723579406738 E(D(fake)) 0.5002265572547913 E(D(real)) 0.4997807741165161\n",
      "epoch 517 g_loss 0.7279308438301086 d_loss 1.3866422176361084 E(D(fake)) 0.5001195669174194 E(D(real)) 0.49998727440834045\n",
      "epoch 518 g_loss 0.728111207485199 d_loss 1.3873295783996582 E(D(fake)) 0.5000209808349609 E(D(real)) 0.49955111742019653\n",
      "epoch 519 g_loss 0.728320300579071 d_loss 1.3864959478378296 E(D(fake)) 0.499904066324234 E(D(real)) 0.4998478591442108\n",
      "epoch 520 g_loss 0.7287406921386719 d_loss 1.3865225315093994 E(D(fake)) 0.4996829926967621 E(D(real)) 0.49961745738983154\n",
      "epoch 521 g_loss 0.7292267084121704 d_loss 1.3869686126708984 E(D(fake)) 0.49942177534103394 E(D(real)) 0.49913087487220764\n",
      "epoch 522 g_loss 0.7297756671905518 d_loss 1.386995553970337 E(D(fake)) 0.49913015961647034 E(D(real)) 0.4988214373588562\n",
      "epoch 523 g_loss 0.7302173972129822 d_loss 1.3871650695800781 E(D(fake)) 0.4988895356655121 E(D(real)) 0.4984951913356781\n",
      "epoch 524 g_loss 0.7304562330245972 d_loss 1.3873260021209717 E(D(fake)) 0.4987446963787079 E(D(real)) 0.4982726573944092\n",
      "epoch 525 g_loss 0.7304295897483826 d_loss 1.3872871398925781 E(D(fake)) 0.4987321197986603 E(D(real)) 0.49827131628990173\n",
      "epoch 526 g_loss 0.7301741242408752 d_loss 1.387756586074829 E(D(fake)) 0.4988393783569336 E(D(real)) 0.49813854694366455\n",
      "epoch 527 g_loss 0.7296813726425171 d_loss 1.3877646923065186 E(D(fake)) 0.4990680515766144 E(D(real)) 0.4983612895011902\n",
      "epoch 528 g_loss 0.7289985418319702 d_loss 1.388176441192627 E(D(fake)) 0.49939125776290894 E(D(real)) 0.49847641587257385\n",
      "epoch 529 g_loss 0.7281832098960876 d_loss 1.3880807161331177 E(D(fake)) 0.4997878074645996 E(D(real)) 0.49891769886016846\n",
      "epoch 530 g_loss 0.7271907925605774 d_loss 1.388265609741211 E(D(fake)) 0.5002803206443787 E(D(real)) 0.49932199716567993\n",
      "epoch 531 g_loss 0.7260865569114685 d_loss 1.3886053562164307 E(D(fake)) 0.5008336901664734 E(D(real)) 0.49970316886901855\n",
      "epoch 532 g_loss 0.7250528335571289 d_loss 1.388390302658081 E(D(fake)) 0.50136399269104 E(D(real)) 0.5003533959388733\n",
      "epoch 533 g_loss 0.7240739464759827 d_loss 1.3888394832611084 E(D(fake)) 0.5018734931945801 E(D(real)) 0.5006451606750488\n",
      "epoch 534 g_loss 0.7234301567077637 d_loss 1.3892762660980225 E(D(fake)) 0.5022238492965698 E(D(real)) 0.5007872581481934\n",
      "epoch 535 g_loss 0.7231258749961853 d_loss 1.3894771337509155 E(D(fake)) 0.5024095177650452 E(D(real)) 0.5008798241615295\n",
      "epoch 536 g_loss 0.723181962966919 d_loss 1.3899192810058594 E(D(fake)) 0.5024169087409973 E(D(real)) 0.5006721019744873\n",
      "epoch 537 g_loss 0.7236674427986145 d_loss 1.389763355255127 E(D(fake)) 0.5022047758102417 E(D(real)) 0.5005354881286621\n",
      "epoch 538 g_loss 0.7244729399681091 d_loss 1.390185832977295 E(D(fake)) 0.5018302798271179 E(D(real)) 0.4999392032623291\n",
      "epoch 539 g_loss 0.7253534197807312 d_loss 1.3907277584075928 E(D(fake)) 0.5014148950576782 E(D(real)) 0.4992545545101166\n",
      "epoch 540 g_loss 0.7262629270553589 d_loss 1.3905997276306152 E(D(fake)) 0.5009773373603821 E(D(real)) 0.4988767206668854\n",
      "epoch 541 g_loss 0.7270616292953491 d_loss 1.3909802436828613 E(D(fake)) 0.5005859136581421 E(D(real)) 0.49828964471817017\n",
      "epoch 542 g_loss 0.7276933193206787 d_loss 1.3914744853973389 E(D(fake)) 0.5002730488777161 E(D(real)) 0.49772751331329346\n",
      "epoch 543 g_loss 0.7281151413917542 d_loss 1.3913860321044922 E(D(fake)) 0.5000622868537903 E(D(real)) 0.4975561797618866\n",
      "epoch 544 g_loss 0.7282651662826538 d_loss 1.3918075561523438 E(D(fake)) 0.49998775124549866 E(D(real)) 0.4972691237926483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 545 g_loss 0.7281749248504639 d_loss 1.3915438652038574 E(D(fake)) 0.5000314712524414 E(D(real)) 0.4974324107170105\n",
      "epoch 546 g_loss 0.7277683615684509 d_loss 1.3917546272277832 E(D(fake)) 0.5002373456954956 E(D(real)) 0.49753573536872864\n",
      "epoch 547 g_loss 0.7272170782089233 d_loss 1.3919003009796143 E(D(fake)) 0.5005194544792175 E(D(real)) 0.49774497747421265\n",
      "epoch 548 g_loss 0.7266589403152466 d_loss 1.3918063640594482 E(D(fake)) 0.5008159279823303 E(D(real)) 0.49808719754219055\n",
      "epoch 549 g_loss 0.7262903451919556 d_loss 1.3916040658950806 E(D(fake)) 0.5010212063789368 E(D(real)) 0.4983938932418823\n",
      "epoch 550 g_loss 0.7261968851089478 d_loss 1.3918935060501099 E(D(fake)) 0.501089870929718 E(D(real)) 0.4983241856098175\n",
      "epoch 551 g_loss 0.7263216376304626 d_loss 1.3919624090194702 E(D(fake)) 0.5010513663291931 E(D(real)) 0.49825960397720337\n",
      "epoch 552 g_loss 0.7266736626625061 d_loss 1.3920683860778809 E(D(fake)) 0.50089430809021 E(D(real)) 0.4980465769767761\n",
      "epoch 553 g_loss 0.7272597551345825 d_loss 1.3920209407806396 E(D(fake)) 0.5006203651428223 E(D(real)) 0.49779772758483887\n",
      "epoch 554 g_loss 0.7279937267303467 d_loss 1.391620397567749 E(D(fake)) 0.5002666711807251 E(D(real)) 0.49763917922973633\n",
      "epoch 555 g_loss 0.7287389039993286 d_loss 1.3916709423065186 E(D(fake)) 0.4998965561389923 E(D(real)) 0.497246652841568\n",
      "epoch 556 g_loss 0.7294381856918335 d_loss 1.3915232419967651 E(D(fake)) 0.49955126643180847 E(D(real)) 0.4969768524169922\n",
      "epoch 557 g_loss 0.7300330400466919 d_loss 1.3914134502410889 E(D(fake)) 0.49925145506858826 E(D(real)) 0.49672913551330566\n",
      "epoch 558 g_loss 0.7309184074401855 d_loss 1.3906569480895996 E(D(fake)) 0.4988020360469818 E(D(real)) 0.49666833877563477\n",
      "epoch 559 g_loss 0.731361448764801 d_loss 1.390791416168213 E(D(fake)) 0.4985688626766205 E(D(real)) 0.4963725507259369\n",
      "epoch 560 g_loss 0.7316762208938599 d_loss 1.39052152633667 E(D(fake)) 0.49839526414871216 E(D(real)) 0.49631962180137634\n",
      "epoch 561 g_loss 0.7319859862327576 d_loss 1.3904521465301514 E(D(fake)) 0.49822309613227844 E(D(real)) 0.4961777627468109\n",
      "epoch 562 g_loss 0.731948971748352 d_loss 1.390525460243225 E(D(fake)) 0.49821045994758606 E(D(real)) 0.49612995982170105\n",
      "epoch 563 g_loss 0.7316800951957703 d_loss 1.3901560306549072 E(D(fake)) 0.4983222186565399 E(D(real)) 0.49641746282577515\n",
      "epoch 564 g_loss 0.731185257434845 d_loss 1.3900532722473145 E(D(fake)) 0.4985491931438446 E(D(real)) 0.4966908097267151\n",
      "epoch 565 g_loss 0.730563223361969 d_loss 1.3899755477905273 E(D(fake)) 0.4988420605659485 E(D(real)) 0.49701857566833496\n",
      "epoch 566 g_loss 0.7298893332481384 d_loss 1.3892409801483154 E(D(fake)) 0.4991644620895386 E(D(real)) 0.4977053701877594\n",
      "epoch 567 g_loss 0.7292112112045288 d_loss 1.389369249343872 E(D(fake)) 0.49949759244918823 E(D(real)) 0.49797487258911133\n",
      "epoch 568 g_loss 0.7286022901535034 d_loss 1.3888486623764038 E(D(fake)) 0.4997999370098114 E(D(real)) 0.49854040145874023\n",
      "epoch 569 g_loss 0.7280729413032532 d_loss 1.38888418674469 E(D(fake)) 0.5000743269920349 E(D(real)) 0.49879974126815796\n",
      "epoch 570 g_loss 0.72763592004776 d_loss 1.3885540962219238 E(D(fake)) 0.5003050565719604 E(D(real)) 0.49920424818992615\n",
      "epoch 571 g_loss 0.7273728847503662 d_loss 1.3888428211212158 E(D(fake)) 0.5004466772079468 E(D(real)) 0.4992021918296814\n",
      "epoch 572 g_loss 0.7274649143218994 d_loss 1.3889753818511963 E(D(fake)) 0.5004168748855591 E(D(real)) 0.49911218881607056\n",
      "epoch 573 g_loss 0.7279596924781799 d_loss 1.3886914253234863 E(D(fake)) 0.5001828670501709 E(D(real)) 0.49902287125587463\n",
      "epoch 574 g_loss 0.7287541627883911 d_loss 1.388868808746338 E(D(fake)) 0.49979305267333984 E(D(real)) 0.498549222946167\n",
      "epoch 575 g_loss 0.7298426628112793 d_loss 1.3882371187210083 E(D(fake)) 0.4992462992668152 E(D(real)) 0.4983128309249878\n",
      "epoch 576 g_loss 0.7309868335723877 d_loss 1.3882325887680054 E(D(fake)) 0.49866682291030884 E(D(real)) 0.4977375864982605\n",
      "epoch 577 g_loss 0.7320536375045776 d_loss 1.3882088661193848 E(D(fake)) 0.4981168508529663 E(D(real)) 0.49720340967178345\n",
      "epoch 578 g_loss 0.7329341769218445 d_loss 1.388227939605713 E(D(fake)) 0.49765297770500183 E(D(real)) 0.49672961235046387\n",
      "epoch 579 g_loss 0.7335095405578613 d_loss 1.3880822658538818 E(D(fake)) 0.497329443693161 E(D(real)) 0.49647828936576843\n",
      "epoch 580 g_loss 0.7337605357170105 d_loss 1.3879108428955078 E(D(fake)) 0.49716922640800476 E(D(real)) 0.4963979125022888\n",
      "epoch 581 g_loss 0.7336376309394836 d_loss 1.3879661560058594 E(D(fake)) 0.4971921741962433 E(D(real)) 0.49638739228248596\n",
      "epoch 582 g_loss 0.7331655025482178 d_loss 1.3880658149719238 E(D(fake)) 0.49739310145378113 E(D(real)) 0.4965326189994812\n",
      "epoch 583 g_loss 0.7323976159095764 d_loss 1.3878374099731445 E(D(fake)) 0.49774283170700073 E(D(real)) 0.4969891905784607\n",
      "epoch 584 g_loss 0.7314668893814087 d_loss 1.3877006769180298 E(D(fake)) 0.4981738030910492 E(D(real)) 0.4974822998046875\n",
      "epoch 585 g_loss 0.7304858565330505 d_loss 1.3877570629119873 E(D(fake)) 0.49864527583122253 E(D(real)) 0.4979253113269806\n",
      "epoch 586 g_loss 0.7295339107513428 d_loss 1.3873512744903564 E(D(fake)) 0.49911221861839294 E(D(real)) 0.498595267534256\n",
      "epoch 587 g_loss 0.7286449074745178 d_loss 1.3871541023254395 E(D(fake)) 0.4995518922805786 E(D(real)) 0.4991358518600464\n",
      "epoch 588 g_loss 0.7279068231582642 d_loss 1.3869059085845947 E(D(fake)) 0.49992361664772034 E(D(real)) 0.49963411688804626\n",
      "epoch 589 g_loss 0.727285623550415 d_loss 1.3874857425689697 E(D(fake)) 0.5002458691596985 E(D(real)) 0.4996747076511383\n",
      "epoch 590 g_loss 0.7268973588943481 d_loss 1.387604832649231 E(D(fake)) 0.5004468560218811 E(D(real)) 0.49982118606567383\n",
      "epoch 591 g_loss 0.7269006967544556 d_loss 1.3875211477279663 E(D(fake)) 0.5004655718803406 E(D(real)) 0.49989548325538635\n",
      "epoch 592 g_loss 0.727350652217865 d_loss 1.3875641822814941 E(D(fake)) 0.5002602934837341 E(D(real)) 0.4996706247329712\n",
      "epoch 593 g_loss 0.7282727360725403 d_loss 1.3879797458648682 E(D(fake)) 0.4998106062412262 E(D(real)) 0.4990134835243225\n",
      "epoch 594 g_loss 0.7295628190040588 d_loss 1.387795090675354 E(D(fake)) 0.4991675615310669 E(D(real)) 0.4984610378742218\n",
      "epoch 595 g_loss 0.7310059070587158 d_loss 1.3875055313110352 E(D(fake)) 0.498441606760025 E(D(real)) 0.497883141040802\n",
      "epoch 596 g_loss 0.7323693037033081 d_loss 1.3875130414962769 E(D(fake)) 0.49775123596191406 E(D(real)) 0.497188001871109\n",
      "epoch 597 g_loss 0.7333924174308777 d_loss 1.387549877166748 E(D(fake)) 0.49721473455429077 E(D(real)) 0.49663588404655457\n",
      "epoch 598 g_loss 0.7339576482772827 d_loss 1.3876535892486572 E(D(fake)) 0.4969005286693573 E(D(real)) 0.4962683916091919\n",
      "epoch 599 g_loss 0.7340583801269531 d_loss 1.3876104354858398 E(D(fake)) 0.4968169033527374 E(D(real)) 0.49619564414024353\n",
      "epoch 600 g_loss 0.7336695194244385 d_loss 1.3876856565475464 E(D(fake)) 0.4969715178012848 E(D(real)) 0.4963094890117645\n",
      "epoch 601 g_loss 0.7329599857330322 d_loss 1.387730598449707 E(D(fake)) 0.4972965121269226 E(D(real)) 0.49660205841064453\n",
      "epoch 602 g_loss 0.7320097088813782 d_loss 1.3873133659362793 E(D(fake)) 0.49774405360221863 E(D(real)) 0.49724769592285156\n",
      "epoch 603 g_loss 0.7309353351593018 d_loss 1.3873553276062012 E(D(fake)) 0.49826160073280334 E(D(real)) 0.4977414309978485\n",
      "epoch 604 g_loss 0.7298532128334045 d_loss 1.3870811462402344 E(D(fake)) 0.49878692626953125 E(D(real)) 0.4984007775783539\n",
      "epoch 605 g_loss 0.7288225889205933 d_loss 1.3867785930633545 E(D(fake)) 0.49929895997047424 E(D(real)) 0.49907082319259644\n",
      "epoch 606 g_loss 0.7279156446456909 d_loss 1.3863682746887207 E(D(fake)) 0.4997570812702179 E(D(real)) 0.499737024307251\n",
      "epoch 607 g_loss 0.7271750569343567 d_loss 1.3861380815505981 E(D(fake)) 0.5001387596130371 E(D(real)) 0.5002336502075195\n",
      "epoch 608 g_loss 0.7266457676887512 d_loss 1.3862452507019043 E(D(fake)) 0.5004182457923889 E(D(real)) 0.5004777312278748\n",
      "epoch 609 g_loss 0.7263792753219604 d_loss 1.3861010074615479 E(D(fake)) 0.500575065612793 E(D(real)) 0.500706672668457\n",
      "epoch 610 g_loss 0.726536214351654 d_loss 1.3863581418991089 E(D(fake)) 0.5005127787590027 E(D(real)) 0.5005215406417847\n",
      "epoch 611 g_loss 0.7271468043327332 d_loss 1.386333703994751 E(D(fake)) 0.5002197027206421 E(D(real)) 0.5002434849739075\n",
      "epoch 612 g_loss 0.7280578017234802 d_loss 1.3869805335998535 E(D(fake)) 0.49977436661720276 E(D(real)) 0.4994758069515228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 613 g_loss 0.7292415499687195 d_loss 1.3862783908843994 E(D(fake)) 0.49917787313461304 E(D(real)) 0.4992286264896393\n",
      "epoch 614 g_loss 0.7304964661598206 d_loss 1.3861256837844849 E(D(fake)) 0.4985419511795044 E(D(real)) 0.49866220355033875\n",
      "epoch 615 g_loss 0.7315810918807983 d_loss 1.386292815208435 E(D(fake)) 0.4979807138442993 E(D(real)) 0.49802565574645996\n",
      "epoch 616 g_loss 0.7323033809661865 d_loss 1.3862831592559814 E(D(fake)) 0.4975917339324951 E(D(real)) 0.49763503670692444\n",
      "epoch 617 g_loss 0.7325938940048218 d_loss 1.3865097761154175 E(D(fake)) 0.49741506576538086 E(D(real)) 0.4973408579826355\n",
      "epoch 618 g_loss 0.7324305176734924 d_loss 1.3869794607162476 E(D(fake)) 0.49746719002723694 E(D(real)) 0.4971523582935333\n",
      "epoch 619 g_loss 0.7318883538246155 d_loss 1.3874894380569458 E(D(fake)) 0.49770745635032654 E(D(real)) 0.49713295698165894\n",
      "epoch 620 g_loss 0.7310605049133301 d_loss 1.3877838850021362 E(D(fake)) 0.498097687959671 E(D(real)) 0.4973663091659546\n",
      "epoch 621 g_loss 0.7300202250480652 d_loss 1.3880248069763184 E(D(fake)) 0.4985940754413605 E(D(real)) 0.49773934483528137\n",
      "epoch 622 g_loss 0.7289122939109802 d_loss 1.3881676197052002 E(D(fake)) 0.4991356432437897 E(D(real)) 0.4982030689716339\n",
      "epoch 623 g_loss 0.7278152108192444 d_loss 1.3885445594787598 E(D(fake)) 0.49968409538269043 E(D(real)) 0.49856603145599365\n",
      "epoch 624 g_loss 0.7267916202545166 d_loss 1.3879092931747437 E(D(fake)) 0.5002023577690125 E(D(real)) 0.49940598011016846\n",
      "epoch 625 g_loss 0.7258854508399963 d_loss 1.388004183769226 E(D(fake)) 0.5006736516952515 E(D(real)) 0.49983012676239014\n",
      "epoch 626 g_loss 0.7251259684562683 d_loss 1.3882226943969727 E(D(fake)) 0.5010741949081421 E(D(real)) 0.5001292824745178\n",
      "epoch 627 g_loss 0.7245882749557495 d_loss 1.387803554534912 E(D(fake)) 0.5013741254806519 E(D(real)) 0.500643253326416\n",
      "epoch 628 g_loss 0.7242994904518127 d_loss 1.3879261016845703 E(D(fake)) 0.5015460848808289 E(D(real)) 0.5007626414299011\n",
      "epoch 629 g_loss 0.72434002161026 d_loss 1.3878273963928223 E(D(fake)) 0.5015581250190735 E(D(real)) 0.5008261799812317\n",
      "epoch 630 g_loss 0.7246989011764526 d_loss 1.3881285190582275 E(D(fake)) 0.5014050006866455 E(D(real)) 0.5005257725715637\n",
      "epoch 631 g_loss 0.7253946661949158 d_loss 1.3879776000976562 E(D(fake)) 0.50107741355896 E(D(real)) 0.5002756714820862\n",
      "epoch 632 g_loss 0.7263438105583191 d_loss 1.3873279094696045 E(D(fake)) 0.5006188750267029 E(D(real)) 0.5001430511474609\n",
      "epoch 633 g_loss 0.7275068759918213 d_loss 1.3870913982391357 E(D(fake)) 0.5000450015068054 E(D(real)) 0.49969160556793213\n",
      "epoch 634 g_loss 0.7287653684616089 d_loss 1.3874019384384155 E(D(fake)) 0.49941733479499817 E(D(real)) 0.4989025592803955\n",
      "epoch 635 g_loss 0.7300299406051636 d_loss 1.386436939239502 E(D(fake)) 0.49877864122390747 E(D(real)) 0.49874216318130493\n",
      "epoch 636 g_loss 0.7311023473739624 d_loss 1.3865127563476562 E(D(fake)) 0.49822738766670227 E(D(real)) 0.4981549382209778\n",
      "epoch 637 g_loss 0.7319019436836243 d_loss 1.3860785961151123 E(D(fake)) 0.4978024661540985 E(D(real)) 0.4979417622089386\n",
      "epoch 638 g_loss 0.7323593497276306 d_loss 1.3862147331237793 E(D(fake)) 0.4975415766239166 E(D(real)) 0.4976123869419098\n",
      "epoch 639 g_loss 0.7325400114059448 d_loss 1.3861825466156006 E(D(fake)) 0.49742260575294495 E(D(real)) 0.4975077211856842\n",
      "epoch 640 g_loss 0.7324241399765015 d_loss 1.3863883018493652 E(D(fake)) 0.4974496066570282 E(D(real)) 0.4974251091480255\n",
      "epoch 641 g_loss 0.7320417761802673 d_loss 1.3863203525543213 E(D(fake)) 0.4976106286048889 E(D(real)) 0.49761882424354553\n",
      "epoch 642 g_loss 0.7314865589141846 d_loss 1.3860443830490112 E(D(fake)) 0.49786195158958435 E(D(real)) 0.498005211353302\n",
      "epoch 643 g_loss 0.7307590246200562 d_loss 1.3865156173706055 E(D(fake)) 0.4982048571109772 E(D(real)) 0.49810975790023804\n",
      "epoch 644 g_loss 0.7299908995628357 d_loss 1.3861764669418335 E(D(fake)) 0.4985714256763458 E(D(real)) 0.49864476919174194\n",
      "epoch 645 g_loss 0.7292331457138062 d_loss 1.3864412307739258 E(D(fake)) 0.4989399015903473 E(D(real)) 0.4988786280155182\n",
      "epoch 646 g_loss 0.7285152077674866 d_loss 1.3864210844039917 E(D(fake)) 0.49929627776145935 E(D(real)) 0.49925267696380615\n",
      "epoch 647 g_loss 0.7278878688812256 d_loss 1.3861408233642578 E(D(fake)) 0.4996173083782196 E(D(real)) 0.49971383810043335\n",
      "epoch 648 g_loss 0.7274221181869507 d_loss 1.3861467838287354 E(D(fake)) 0.499858558177948 E(D(real)) 0.49995142221450806\n",
      "epoch 649 g_loss 0.7271915078163147 d_loss 1.3861802816390991 E(D(fake)) 0.49998512864112854 E(D(real)) 0.5000821948051453\n",
      "epoch 650 g_loss 0.7272491455078125 d_loss 1.3865280151367188 E(D(fake)) 0.49996861815452576 E(D(real)) 0.4998825192451477\n",
      "epoch 651 g_loss 0.7274932861328125 d_loss 1.3863036632537842 E(D(fake)) 0.49985840916633606 E(D(real)) 0.4998857080936432\n",
      "epoch 652 g_loss 0.7276046276092529 d_loss 1.3873703479766846 E(D(fake)) 0.49981850385665894 E(D(real)) 0.499325692653656\n",
      "epoch 653 g_loss 0.7280750870704651 d_loss 1.3875244855880737 E(D(fake)) 0.49960097670555115 E(D(real)) 0.4990259110927582\n",
      "epoch 654 g_loss 0.7288309931755066 d_loss 1.3879201412200928 E(D(fake)) 0.4992339611053467 E(D(real)) 0.49846151471138\n",
      "epoch 655 g_loss 0.7297092080116272 d_loss 1.3879259824752808 E(D(fake)) 0.49880561232566833 E(D(real)) 0.498026579618454\n",
      "epoch 656 g_loss 0.7305651903152466 d_loss 1.3884971141815186 E(D(fake)) 0.4983767867088318 E(D(real)) 0.49731671810150146\n",
      "epoch 657 g_loss 0.7312490344047546 d_loss 1.3885045051574707 E(D(fake)) 0.4980252981185913 E(D(real)) 0.49695777893066406\n",
      "epoch 658 g_loss 0.7316119074821472 d_loss 1.388653039932251 E(D(fake)) 0.4978261888027191 E(D(real)) 0.496683806180954\n",
      "epoch 659 g_loss 0.7316301465034485 d_loss 1.388662338256836 E(D(fake)) 0.4977964162826538 E(D(real)) 0.49664047360420227\n",
      "epoch 660 g_loss 0.7313187122344971 d_loss 1.3885297775268555 E(D(fake)) 0.4979351758956909 E(D(real)) 0.49684229493141174\n",
      "epoch 661 g_loss 0.7307374477386475 d_loss 1.388597846031189 E(D(fake)) 0.4982081949710846 E(D(real)) 0.4970751106739044\n",
      "epoch 662 g_loss 0.7299855947494507 d_loss 1.3884197473526 E(D(fake)) 0.4985703229904175 E(D(real)) 0.4975195527076721\n",
      "epoch 663 g_loss 0.7291069030761719 d_loss 1.3883819580078125 E(D(fake)) 0.49900558590888977 E(D(real)) 0.49797144532203674\n",
      "epoch 664 g_loss 0.7282046675682068 d_loss 1.387852430343628 E(D(fake)) 0.49944934248924255 E(D(real)) 0.4986761510372162\n",
      "epoch 665 g_loss 0.7273425459861755 d_loss 1.3876943588256836 E(D(fake)) 0.49988892674446106 E(D(real)) 0.4991980493068695\n",
      "epoch 666 g_loss 0.7265468239784241 d_loss 1.3870946168899536 E(D(fake)) 0.5003026723861694 E(D(real)) 0.4999178647994995\n",
      "epoch 667 g_loss 0.7258986234664917 d_loss 1.3868274688720703 E(D(fake)) 0.5006450414657593 E(D(real)) 0.5003988146781921\n",
      "epoch 668 g_loss 0.7254524827003479 d_loss 1.3868114948272705 E(D(fake)) 0.5008955597877502 E(D(real)) 0.5006624460220337\n",
      "epoch 669 g_loss 0.7252327799797058 d_loss 1.3864598274230957 E(D(fake)) 0.501029372215271 E(D(real)) 0.5009777545928955\n",
      "epoch 670 g_loss 0.7252376675605774 d_loss 1.3866713047027588 E(D(fake)) 0.5010499358177185 E(D(real)) 0.5008930563926697\n",
      "epoch 671 g_loss 0.7254860997200012 d_loss 1.3867125511169434 E(D(fake)) 0.5009458661079407 E(D(real)) 0.5007761120796204\n",
      "epoch 672 g_loss 0.726026713848114 d_loss 1.3864874839782715 E(D(fake)) 0.5006927251815796 E(D(real)) 0.5006394982337952\n",
      "epoch 673 g_loss 0.7268732786178589 d_loss 1.3871493339538574 E(D(fake)) 0.5002759099006653 E(D(real)) 0.4998859167098999\n",
      "epoch 674 g_loss 0.7279304265975952 d_loss 1.3867100477218628 E(D(fake)) 0.4997519552707672 E(D(real)) 0.49957549571990967\n",
      "epoch 675 g_loss 0.7289690375328064 d_loss 1.3868935108184814 E(D(fake)) 0.4992259740829468 E(D(real)) 0.4989601969718933\n",
      "epoch 676 g_loss 0.7298842668533325 d_loss 1.3868768215179443 E(D(fake)) 0.4987565577030182 E(D(real)) 0.49849915504455566\n",
      "epoch 677 g_loss 0.7305576801300049 d_loss 1.3869681358337402 E(D(fake)) 0.49840036034584045 E(D(real)) 0.49808943271636963\n",
      "epoch 678 g_loss 0.7309340238571167 d_loss 1.3869149684906006 E(D(fake)) 0.49819251894950867 E(D(real)) 0.4979075491428375\n",
      "epoch 679 g_loss 0.7309669852256775 d_loss 1.3872002363204956 E(D(fake)) 0.4981487989425659 E(D(real)) 0.49771827459335327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 680 g_loss 0.7306692004203796 d_loss 1.3872891664505005 E(D(fake)) 0.49827489256858826 E(D(real)) 0.49779409170150757\n",
      "epoch 681 g_loss 0.7301167845726013 d_loss 1.387413740158081 E(D(fake)) 0.4985303282737732 E(D(real)) 0.4979822039604187\n",
      "epoch 682 g_loss 0.7293972969055176 d_loss 1.3870937824249268 E(D(fake)) 0.4988696873188019 E(D(real)) 0.4984775483608246\n",
      "epoch 683 g_loss 0.7285966873168945 d_loss 1.387001633644104 E(D(fake)) 0.4992564916610718 E(D(real)) 0.49890896677970886\n",
      "epoch 684 g_loss 0.7278070449829102 d_loss 1.3868695497512817 E(D(fake)) 0.49964550137519836 E(D(real)) 0.49936580657958984\n",
      "epoch 685 g_loss 0.7270050644874573 d_loss 1.3869513273239136 E(D(fake)) 0.5000491142272949 E(D(real)) 0.49973341822624207\n",
      "epoch 686 g_loss 0.72626793384552 d_loss 1.3866944313049316 E(D(fake)) 0.5004270076751709 E(D(real)) 0.5002442002296448\n",
      "epoch 687 g_loss 0.7256820797920227 d_loss 1.386488437652588 E(D(fake)) 0.5007326602935791 E(D(real)) 0.5006580948829651\n",
      "epoch 688 g_loss 0.7253014445304871 d_loss 1.3863213062286377 E(D(fake)) 0.5009430050849915 E(D(real)) 0.5009551644325256\n",
      "epoch 689 g_loss 0.7251421809196472 d_loss 1.3863013982772827 E(D(fake)) 0.5010423064231873 E(D(real)) 0.501068115234375\n",
      "epoch 690 g_loss 0.7252272963523865 d_loss 1.3866519927978516 E(D(fake)) 0.5010190010070801 E(D(real)) 0.50087571144104\n",
      "epoch 691 g_loss 0.7255274057388306 d_loss 1.3864428997039795 E(D(fake)) 0.5008888244628906 E(D(real)) 0.5008544921875\n",
      "epoch 692 g_loss 0.7260098457336426 d_loss 1.3869788646697998 E(D(fake)) 0.5006662011146545 E(D(real)) 0.5003638863563538\n",
      "epoch 693 g_loss 0.7267833352088928 d_loss 1.3867132663726807 E(D(fake)) 0.5002981424331665 E(D(real)) 0.5001312494277954\n",
      "epoch 694 g_loss 0.7277684807777405 d_loss 1.3874046802520752 E(D(fake)) 0.4998113512992859 E(D(real)) 0.4992945194244385\n",
      "epoch 695 g_loss 0.7288430333137512 d_loss 1.3870596885681152 E(D(fake)) 0.4992760121822357 E(D(real)) 0.4989302456378937\n",
      "epoch 696 g_loss 0.7298312187194824 d_loss 1.3868763446807861 E(D(fake)) 0.498775839805603 E(D(real)) 0.49852070212364197\n",
      "epoch 697 g_loss 0.7306094765663147 d_loss 1.3870630264282227 E(D(fake)) 0.49837520718574524 E(D(real)) 0.49802377820014954\n",
      "epoch 698 g_loss 0.7311720252037048 d_loss 1.3870149850845337 E(D(fake)) 0.49807557463645935 E(D(real)) 0.4977456033229828\n",
      "epoch 699 g_loss 0.7314770221710205 d_loss 1.3869976997375488 E(D(fake)) 0.497907429933548 E(D(real)) 0.4975816309452057\n",
      "epoch 700 g_loss 0.7314644455909729 d_loss 1.3870679140090942 E(D(fake)) 0.49789515137672424 E(D(real)) 0.4975312054157257\n",
      "epoch 701 g_loss 0.7311674356460571 d_loss 1.387324571609497 E(D(fake)) 0.4980214536190033 E(D(real)) 0.4975265860557556\n",
      "epoch 702 g_loss 0.7306278347969055 d_loss 1.3870176076889038 E(D(fake)) 0.4982636868953705 E(D(real)) 0.49791595339775085\n",
      "epoch 703 g_loss 0.7299070358276367 d_loss 1.387232780456543 E(D(fake)) 0.49860841035842896 E(D(real)) 0.498149573802948\n",
      "epoch 704 g_loss 0.7291216850280762 d_loss 1.3868240118026733 E(D(fake)) 0.4989891052246094 E(D(real)) 0.4987301826477051\n",
      "epoch 705 g_loss 0.7283167243003845 d_loss 1.3867965936660767 E(D(fake)) 0.4993864893913269 E(D(real)) 0.4991457760334015\n",
      "epoch 706 g_loss 0.7275835275650024 d_loss 1.3869390487670898 E(D(fake)) 0.49975618720054626 E(D(real)) 0.4994440972805023\n",
      "epoch 707 g_loss 0.7268633842468262 d_loss 1.3862311840057373 E(D(fake)) 0.5001246929168701 E(D(real)) 0.5001753568649292\n",
      "epoch 708 g_loss 0.7262298464775085 d_loss 1.386763334274292 E(D(fake)) 0.5004538893699646 E(D(real)) 0.5002343654632568\n",
      "epoch 709 g_loss 0.7258076667785645 d_loss 1.3865993022918701 E(D(fake)) 0.5006821751594543 E(D(real)) 0.5005601644515991\n",
      "epoch 710 g_loss 0.7256416082382202 d_loss 1.3871839046478271 E(D(fake)) 0.5007897019386292 E(D(real)) 0.5003791451454163\n",
      "epoch 711 g_loss 0.7257370352745056 d_loss 1.387077808380127 E(D(fake)) 0.5007658004760742 E(D(real)) 0.5004057884216309\n",
      "epoch 712 g_loss 0.725975513458252 d_loss 1.3877995014190674 E(D(fake)) 0.5006706118583679 E(D(real)) 0.4999532103538513\n",
      "epoch 713 g_loss 0.7264813780784607 d_loss 1.3878111839294434 E(D(fake)) 0.5004360675811768 E(D(real)) 0.499716192483902\n",
      "epoch 714 g_loss 0.7273584008216858 d_loss 1.3874669075012207 E(D(fake)) 0.5000050067901611 E(D(real)) 0.4994640052318573\n",
      "epoch 715 g_loss 0.7284521460533142 d_loss 1.387799620628357 E(D(fake)) 0.499467134475708 E(D(real)) 0.4987519383430481\n",
      "epoch 716 g_loss 0.7295538187026978 d_loss 1.3880887031555176 E(D(fake)) 0.498912513256073 E(D(real)) 0.49805396795272827\n",
      "epoch 717 g_loss 0.7305047512054443 d_loss 1.3878793716430664 E(D(fake)) 0.4984278678894043 E(D(real)) 0.4976717233657837\n",
      "epoch 718 g_loss 0.7311177849769592 d_loss 1.3876254558563232 E(D(fake)) 0.498106449842453 E(D(real)) 0.4974738359451294\n",
      "epoch 719 g_loss 0.7313811779022217 d_loss 1.3878648281097412 E(D(fake)) 0.49795645475387573 E(D(real)) 0.49720609188079834\n",
      "epoch 720 g_loss 0.731467068195343 d_loss 1.3877938985824585 E(D(fake)) 0.4978894293308258 E(D(real)) 0.4971669018268585\n",
      "epoch 721 g_loss 0.7310635447502136 d_loss 1.3879680633544922 E(D(fake)) 0.49806442856788635 E(D(real)) 0.4972474277019501\n",
      "epoch 722 g_loss 0.7303266525268555 d_loss 1.3881990909576416 E(D(fake)) 0.4984113276004791 E(D(real)) 0.4974754750728607\n",
      "epoch 723 g_loss 0.729356050491333 d_loss 1.3881385326385498 E(D(fake)) 0.4988810122013092 E(D(real)) 0.497970312833786\n",
      "epoch 724 g_loss 0.7282261252403259 d_loss 1.3879740238189697 E(D(fake)) 0.49943679571151733 E(D(real)) 0.4986098110675812\n",
      "epoch 725 g_loss 0.7270944714546204 d_loss 1.3876705169677734 E(D(fake)) 0.5000032782554626 E(D(real)) 0.49933040142059326\n",
      "epoch 726 g_loss 0.7260545492172241 d_loss 1.3876688480377197 E(D(fake)) 0.5005286931991577 E(D(real)) 0.49985402822494507\n",
      "epoch 727 g_loss 0.7252259850502014 d_loss 1.3879989385604858 E(D(fake)) 0.5009623169898987 E(D(real)) 0.5001306533813477\n",
      "epoch 728 g_loss 0.7247610688209534 d_loss 1.3879053592681885 E(D(fake)) 0.5012288689613342 E(D(real)) 0.5004582405090332\n",
      "epoch 729 g_loss 0.724504292011261 d_loss 1.3881711959838867 E(D(fake)) 0.5013918280601501 E(D(real)) 0.5005034804344177\n",
      "epoch 730 g_loss 0.7246943116188049 d_loss 1.388806939125061 E(D(fake)) 0.5013327598571777 E(D(real)) 0.5001211762428284\n",
      "epoch 731 g_loss 0.7253824472427368 d_loss 1.3885061740875244 E(D(fake)) 0.5010140538215637 E(D(real)) 0.49995601177215576\n",
      "epoch 732 g_loss 0.7262694835662842 d_loss 1.3886728286743164 E(D(fake)) 0.5005868673324585 E(D(real)) 0.4994471073150635\n",
      "epoch 733 g_loss 0.7272793054580688 d_loss 1.388598918914795 E(D(fake)) 0.5000929832458496 E(D(real)) 0.49897921085357666\n",
      "epoch 734 g_loss 0.7282072901725769 d_loss 1.3888099193572998 E(D(fake)) 0.4996355175971985 E(D(real)) 0.49841421842575073\n",
      "epoch 735 g_loss 0.7289825677871704 d_loss 1.3888087272644043 E(D(fake)) 0.499249666929245 E(D(real)) 0.4980243742465973\n",
      "epoch 736 g_loss 0.7295007705688477 d_loss 1.3887284994125366 E(D(fake)) 0.49897846579551697 E(D(real)) 0.4977901875972748\n",
      "epoch 737 g_loss 0.7297700643539429 d_loss 1.3886098861694336 E(D(fake)) 0.4988377094268799 E(D(real)) 0.4977042078971863\n",
      "epoch 738 g_loss 0.729824960231781 d_loss 1.3882933855056763 E(D(fake)) 0.49880000948905945 E(D(real)) 0.497822642326355\n",
      "epoch 739 g_loss 0.729690432548523 d_loss 1.3882780075073242 E(D(fake)) 0.4988584816455841 E(D(real)) 0.4978819787502289\n",
      "epoch 740 g_loss 0.7293899655342102 d_loss 1.38798189163208 E(D(fake)) 0.4990030527114868 E(D(real)) 0.4981752336025238\n",
      "epoch 741 g_loss 0.7289496660232544 d_loss 1.3879139423370361 E(D(fake)) 0.4992114007472992 E(D(real)) 0.4984157383441925\n",
      "epoch 742 g_loss 0.7284417748451233 d_loss 1.387629747390747 E(D(fake)) 0.49946096539497375 E(D(real)) 0.4988052248954773\n",
      "epoch 743 g_loss 0.7278881669044495 d_loss 1.3874866962432861 E(D(fake)) 0.49973633885383606 E(D(real)) 0.4991527199745178\n",
      "epoch 744 g_loss 0.7273635268211365 d_loss 1.3875617980957031 E(D(fake)) 0.5000027418136597 E(D(real)) 0.4993848204612732\n",
      "epoch 745 g_loss 0.7269675731658936 d_loss 1.386649250984192 E(D(fake)) 0.5002043843269348 E(D(real)) 0.5000551342964172\n",
      "epoch 746 g_loss 0.7266215085983276 d_loss 1.3868529796600342 E(D(fake)) 0.5003891587257385 E(D(real)) 0.5001296401023865\n",
      "epoch 747 g_loss 0.7263413667678833 d_loss 1.3870279788970947 E(D(fake)) 0.5005444288253784 E(D(real)) 0.5002049207687378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 748 g_loss 0.726153552532196 d_loss 1.3864760398864746 E(D(fake)) 0.5006442070007324 E(D(real)) 0.5005807280540466\n",
      "epoch 749 g_loss 0.7261162400245667 d_loss 1.3860077857971191 E(D(fake)) 0.5006799101829529 E(D(real)) 0.5008524656295776\n",
      "epoch 750 g_loss 0.726233720779419 d_loss 1.3868753910064697 E(D(fake)) 0.5006282925605774 E(D(real)) 0.5003688931465149\n",
      "epoch 751 g_loss 0.7265669107437134 d_loss 1.3860037326812744 E(D(fake)) 0.5004751086235046 E(D(real)) 0.500654935836792\n",
      "epoch 752 g_loss 0.7269761562347412 d_loss 1.386040449142456 E(D(fake)) 0.5002772212028503 E(D(real)) 0.5004395842552185\n",
      "epoch 753 g_loss 0.7274782657623291 d_loss 1.3862340450286865 E(D(fake)) 0.5000311732292175 E(D(real)) 0.5000937581062317\n",
      "epoch 754 g_loss 0.7280347347259521 d_loss 1.3857896327972412 E(D(fake)) 0.49975231289863586 E(D(real)) 0.5000391006469727\n",
      "epoch 755 g_loss 0.7285947799682617 d_loss 1.3847784996032715 E(D(fake)) 0.4994746446609497 E(D(real)) 0.5002761483192444\n",
      "epoch 756 g_loss 0.7290414571762085 d_loss 1.3860323429107666 E(D(fake)) 0.4992452561855316 E(D(real)) 0.499409943819046\n",
      "epoch 757 g_loss 0.7295182943344116 d_loss 1.3856191635131836 E(D(fake)) 0.4989987313747406 E(D(real)) 0.4993671476840973\n",
      "epoch 758 g_loss 0.7298411130905151 d_loss 1.3855199813842773 E(D(fake)) 0.49883154034614563 E(D(real)) 0.4992421567440033\n",
      "epoch 759 g_loss 0.7299482226371765 d_loss 1.3853682279586792 E(D(fake)) 0.49876248836517334 E(D(real)) 0.49924781918525696\n",
      "epoch 760 g_loss 0.7298349738121033 d_loss 1.3855712413787842 E(D(fake)) 0.4988008737564087 E(D(real)) 0.49917903542518616\n",
      "epoch 761 g_loss 0.7295280694961548 d_loss 1.385231375694275 E(D(fake)) 0.49894019961357117 E(D(real)) 0.4994880259037018\n",
      "epoch 762 g_loss 0.7290550470352173 d_loss 1.385215401649475 E(D(fake)) 0.4991626739501953 E(D(real)) 0.4997211992740631\n",
      "epoch 763 g_loss 0.7285065054893494 d_loss 1.3853710889816284 E(D(fake)) 0.4994308054447174 E(D(real)) 0.4999065101146698\n",
      "epoch 764 g_loss 0.7279181480407715 d_loss 1.3848204612731934 E(D(fake)) 0.4997214674949646 E(D(real)) 0.500476598739624\n",
      "epoch 765 g_loss 0.7272931933403015 d_loss 1.3850287199020386 E(D(fake)) 0.5000302791595459 E(D(real)) 0.5006800889968872\n",
      "epoch 766 g_loss 0.7266785502433777 d_loss 1.3848440647125244 E(D(fake)) 0.500345766544342 E(D(real)) 0.501101016998291\n",
      "epoch 767 g_loss 0.726137101650238 d_loss 1.3853213787078857 E(D(fake)) 0.5006316900253296 E(D(real)) 0.5011512637138367\n",
      "epoch 768 g_loss 0.7258485555648804 d_loss 1.3853731155395508 E(D(fake)) 0.500795841217041 E(D(real)) 0.5012937784194946\n",
      "epoch 769 g_loss 0.7257634401321411 d_loss 1.3857653141021729 E(D(fake)) 0.5008559226989746 E(D(real)) 0.501173198223114\n",
      "epoch 770 g_loss 0.7259051203727722 d_loss 1.3865103721618652 E(D(fake)) 0.5008066296577454 E(D(real)) 0.5007503032684326\n",
      "epoch 771 g_loss 0.7264102697372437 d_loss 1.386911153793335 E(D(fake)) 0.5005680322647095 E(D(real)) 0.5003028512001038\n",
      "epoch 772 g_loss 0.7271647453308105 d_loss 1.3873205184936523 E(D(fake)) 0.5002009868621826 E(D(real)) 0.49973201751708984\n",
      "epoch 773 g_loss 0.7280299067497253 d_loss 1.3878238201141357 E(D(fake)) 0.49978017807006836 E(D(real)) 0.49905675649642944\n",
      "epoch 774 g_loss 0.72883141040802 d_loss 1.387657642364502 E(D(fake)) 0.49938055872917175 E(D(real)) 0.4987359642982483\n",
      "epoch 775 g_loss 0.7294724583625793 d_loss 1.3878676891326904 E(D(fake)) 0.49905291199684143 E(D(real)) 0.498300701379776\n",
      "epoch 776 g_loss 0.7299487590789795 d_loss 1.3879520893096924 E(D(fake)) 0.4988076984882355 E(D(real)) 0.49800845980644226\n",
      "epoch 777 g_loss 0.7301724553108215 d_loss 1.388110876083374 E(D(fake)) 0.4986870288848877 E(D(real)) 0.4978060722351074\n",
      "epoch 778 g_loss 0.7301294207572937 d_loss 1.388267993927002 E(D(fake)) 0.4986996054649353 E(D(real)) 0.4977336525917053\n",
      "epoch 779 g_loss 0.729823648929596 d_loss 1.388383388519287 E(D(fake)) 0.49884268641471863 E(D(real)) 0.497814804315567\n",
      "epoch 780 g_loss 0.7293030023574829 d_loss 1.3886200189590454 E(D(fake)) 0.4990973174571991 E(D(real)) 0.4979495406150818\n",
      "epoch 781 g_loss 0.7286636829376221 d_loss 1.3883776664733887 E(D(fake)) 0.49941286444664 E(D(real)) 0.4983785152435303\n",
      "epoch 782 g_loss 0.7279212474822998 d_loss 1.3884236812591553 E(D(fake)) 0.499781996011734 E(D(real)) 0.4987264573574066\n",
      "epoch 783 g_loss 0.7271804809570312 d_loss 1.3879566192626953 E(D(fake)) 0.50015789270401 E(D(real)) 0.49934419989585876\n",
      "epoch 784 g_loss 0.7264382839202881 d_loss 1.3875150680541992 E(D(fake)) 0.5005409717559814 E(D(real)) 0.49994826316833496\n",
      "epoch 785 g_loss 0.7257170081138611 d_loss 1.388229489326477 E(D(fake)) 0.5009180307388306 E(D(real)) 0.4999658167362213\n",
      "epoch 786 g_loss 0.7250934839248657 d_loss 1.3880445957183838 E(D(fake)) 0.501250147819519 E(D(real)) 0.5003969669342041\n",
      "epoch 787 g_loss 0.7246755957603455 d_loss 1.3879706859588623 E(D(fake)) 0.5014846324920654 E(D(real)) 0.5006747841835022\n",
      "epoch 788 g_loss 0.7245059013366699 d_loss 1.3884713649749756 E(D(fake)) 0.5015965700149536 E(D(real)) 0.5005397796630859\n",
      "epoch 789 g_loss 0.7244857549667358 d_loss 1.388155460357666 E(D(fake)) 0.5016412734985352 E(D(real)) 0.5007457733154297\n",
      "epoch 790 g_loss 0.724822998046875 d_loss 1.3886706829071045 E(D(fake)) 0.5014992356300354 E(D(real)) 0.5003554224967957\n",
      "epoch 791 g_loss 0.7256189584732056 d_loss 1.388474702835083 E(D(fake)) 0.5011311769485474 E(D(real)) 0.5000876784324646\n",
      "epoch 792 g_loss 0.7266524434089661 d_loss 1.3889117240905762 E(D(fake)) 0.5006315112113953 E(D(real)) 0.4993647336959839\n",
      "epoch 793 g_loss 0.727843165397644 d_loss 1.3885053396224976 E(D(fake)) 0.5000521540641785 E(D(real)) 0.4989881217479706\n",
      "epoch 794 g_loss 0.7289857268333435 d_loss 1.3888163566589355 E(D(fake)) 0.49948355555534363 E(D(real)) 0.4982593059539795\n",
      "epoch 795 g_loss 0.7299614548683167 d_loss 1.3887948989868164 E(D(fake)) 0.49899521470069885 E(D(real)) 0.49778303503990173\n",
      "epoch 796 g_loss 0.7305334210395813 d_loss 1.3885092735290527 E(D(fake)) 0.49869996309280396 E(D(real)) 0.4976205825805664\n",
      "epoch 797 g_loss 0.7306476831436157 d_loss 1.3889446258544922 E(D(fake)) 0.4986216127872467 E(D(real)) 0.4973234534263611\n",
      "epoch 798 g_loss 0.7304952144622803 d_loss 1.3891774415969849 E(D(fake)) 0.49868136644363403 E(D(real)) 0.4972630739212036\n",
      "epoch 799 g_loss 0.730182409286499 d_loss 1.389082670211792 E(D(fake)) 0.4988230764865875 E(D(real)) 0.4974459111690521\n",
      "epoch 800 g_loss 0.7297708988189697 d_loss 1.388985514640808 E(D(fake)) 0.4990144371986389 E(D(real)) 0.4976824223995209\n",
      "epoch 801 g_loss 0.7292600870132446 d_loss 1.389067530632019 E(D(fake)) 0.49926045536994934 E(D(real)) 0.497890830039978\n",
      "epoch 802 g_loss 0.7287417054176331 d_loss 1.3890223503112793 E(D(fake)) 0.49951350688934326 E(D(real)) 0.4981635808944702\n",
      "epoch 803 g_loss 0.7282444834709167 d_loss 1.389146089553833 E(D(fake)) 0.4997626841068268 E(D(real)) 0.4983533024787903\n",
      "epoch 804 g_loss 0.727830171585083 d_loss 1.3892039060592651 E(D(fake)) 0.49997058510780334 E(D(real)) 0.49853014945983887\n",
      "epoch 805 g_loss 0.7275620698928833 d_loss 1.389294147491455 E(D(fake)) 0.5001087784767151 E(D(real)) 0.49862587451934814\n",
      "epoch 806 g_loss 0.7274730205535889 d_loss 1.3891921043395996 E(D(fake)) 0.5001563429832458 E(D(real)) 0.4987279772758484\n",
      "epoch 807 g_loss 0.7275180816650391 d_loss 1.3892850875854492 E(D(fake)) 0.500142514705658 E(D(real)) 0.49866628646850586\n",
      "epoch 808 g_loss 0.7276535034179688 d_loss 1.3894168138504028 E(D(fake)) 0.5000821352005005 E(D(real)) 0.4985426068305969\n",
      "epoch 809 g_loss 0.7277576327323914 d_loss 1.3893578052520752 E(D(fake)) 0.5000297427177429 E(D(real)) 0.498519629240036\n",
      "epoch 810 g_loss 0.7279484272003174 d_loss 1.38905930519104 E(D(fake)) 0.49993079900741577 E(D(real)) 0.4985698461532593\n",
      "epoch 811 g_loss 0.7280014753341675 d_loss 1.3889129161834717 E(D(fake)) 0.49990516901016235 E(D(real)) 0.4986155033111572\n",
      "epoch 812 g_loss 0.7277932167053223 d_loss 1.3887786865234375 E(D(fake)) 0.5000036954879761 E(D(real)) 0.49877262115478516\n",
      "epoch 813 g_loss 0.7275498509407043 d_loss 1.3885352611541748 E(D(fake)) 0.5001240372657776 E(D(real)) 0.4990185797214508\n",
      "epoch 814 g_loss 0.7275163531303406 d_loss 1.3888955116271973 E(D(fake)) 0.5001405477523804 E(D(real)) 0.49885866045951843\n",
      "epoch 815 g_loss 0.7274344563484192 d_loss 1.3883942365646362 E(D(fake)) 0.5001813769340515 E(D(real)) 0.4991488456726074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 816 g_loss 0.7273269891738892 d_loss 1.3882148265838623 E(D(fake)) 0.5002338290214539 E(D(real)) 0.4992889165878296\n",
      "epoch 817 g_loss 0.7272886037826538 d_loss 1.38798987865448 E(D(fake)) 0.5002561807632446 E(D(real)) 0.4994237422943115\n",
      "epoch 818 g_loss 0.7271880507469177 d_loss 1.388063907623291 E(D(fake)) 0.5003035664558411 E(D(real)) 0.49943795800209045\n",
      "epoch 819 g_loss 0.7272054553031921 d_loss 1.3875353336334229 E(D(fake)) 0.5003025531768799 E(D(real)) 0.4997091293334961\n",
      "epoch 820 g_loss 0.7271929383277893 d_loss 1.3879644870758057 E(D(fake)) 0.5003141164779663 E(D(real)) 0.4995008111000061\n",
      "epoch 821 g_loss 0.7270785570144653 d_loss 1.38761305809021 E(D(fake)) 0.5003777146339417 E(D(real)) 0.49974340200424194\n",
      "epoch 822 g_loss 0.7270908951759338 d_loss 1.387498140335083 E(D(fake)) 0.500377893447876 E(D(real)) 0.49980270862579346\n",
      "epoch 823 g_loss 0.7271352410316467 d_loss 1.3882858753204346 E(D(fake)) 0.5003618001937866 E(D(real)) 0.49939602613449097\n",
      "epoch 824 g_loss 0.7274328470230103 d_loss 1.3874187469482422 E(D(fake)) 0.50021892786026 E(D(real)) 0.4996846616268158\n",
      "epoch 825 g_loss 0.7276806831359863 d_loss 1.3881011009216309 E(D(fake)) 0.5000985860824585 E(D(real)) 0.499221533536911\n",
      "epoch 826 g_loss 0.7280916571617126 d_loss 1.3880174160003662 E(D(fake)) 0.499892920255661 E(D(real)) 0.4990709722042084\n",
      "epoch 827 g_loss 0.7283948063850403 d_loss 1.3878717422485352 E(D(fake)) 0.49973398447036743 E(D(real)) 0.49897676706314087\n",
      "epoch 828 g_loss 0.7288129329681396 d_loss 1.387913703918457 E(D(fake)) 0.4995232820510864 E(D(real)) 0.49873897433280945\n",
      "epoch 829 g_loss 0.7291090488433838 d_loss 1.3877012729644775 E(D(fake)) 0.4993704557418823 E(D(real)) 0.4986966848373413\n",
      "epoch 830 g_loss 0.7293024063110352 d_loss 1.3874770402908325 E(D(fake)) 0.4992634654045105 E(D(real)) 0.4986933171749115\n",
      "epoch 831 g_loss 0.7292993664741516 d_loss 1.387420415878296 E(D(fake)) 0.4992579519748688 E(D(real)) 0.4987149238586426\n",
      "epoch 832 g_loss 0.7291780710220337 d_loss 1.3870017528533936 E(D(fake)) 0.49931037425994873 E(D(real)) 0.49897822737693787\n",
      "epoch 833 g_loss 0.728995680809021 d_loss 1.38685941696167 E(D(fake)) 0.4993900954723358 E(D(real)) 0.49913185834884644\n",
      "epoch 834 g_loss 0.7286787629127502 d_loss 1.3863908052444458 E(D(fake)) 0.49953940510749817 E(D(real)) 0.4995052218437195\n",
      "epoch 835 g_loss 0.7283124327659607 d_loss 1.3865420818328857 E(D(fake)) 0.49971693754196167 E(D(real)) 0.4996212124824524\n",
      "epoch 836 g_loss 0.727914571762085 d_loss 1.386396050453186 E(D(fake)) 0.49990931153297424 E(D(real)) 0.49987998604774475\n",
      "epoch 837 g_loss 0.7275612950325012 d_loss 1.3862216472625732 E(D(fake)) 0.5000857710838318 E(D(real)) 0.5001454949378967\n",
      "epoch 838 g_loss 0.727203369140625 d_loss 1.3857412338256836 E(D(fake)) 0.5002719163894653 E(D(real)) 0.5005777478218079\n",
      "epoch 839 g_loss 0.7269636988639832 d_loss 1.385554313659668 E(D(fake)) 0.5003955960273743 E(D(real)) 0.500802755355835\n",
      "epoch 840 g_loss 0.7268399596214294 d_loss 1.3850691318511963 E(D(fake)) 0.5004655122756958 E(D(real)) 0.5011241436004639\n",
      "epoch 841 g_loss 0.7267391681671143 d_loss 1.3850395679473877 E(D(fake)) 0.5005257725715637 E(D(real)) 0.5011914968490601\n",
      "epoch 842 g_loss 0.7267969250679016 d_loss 1.3848035335540771 E(D(fake)) 0.5005078911781311 E(D(real)) 0.5013098120689392\n",
      "epoch 843 g_loss 0.7269552946090698 d_loss 1.3837692737579346 E(D(fake)) 0.5004322528839111 E(D(real)) 0.5017686486244202\n",
      "epoch 844 g_loss 0.7271943688392639 d_loss 1.384967565536499 E(D(fake)) 0.5003263354301453 E(D(real)) 0.5010465383529663\n",
      "epoch 845 g_loss 0.727712094783783 d_loss 1.3846564292907715 E(D(fake)) 0.500080943107605 E(D(real)) 0.5009608864784241\n",
      "epoch 846 g_loss 0.728398323059082 d_loss 1.3859496116638184 E(D(fake)) 0.4997440278530121 E(D(real)) 0.4999719262123108\n",
      "epoch 847 g_loss 0.7292507290840149 d_loss 1.385738492012024 E(D(fake)) 0.49932003021240234 E(D(real)) 0.499657541513443\n",
      "epoch 848 g_loss 0.7304046154022217 d_loss 1.3861799240112305 E(D(fake)) 0.4987475574016571 E(D(real)) 0.49885985255241394\n",
      "epoch 849 g_loss 0.7316035032272339 d_loss 1.386588215827942 E(D(fake)) 0.49814465641975403 E(D(real)) 0.4980572760105133\n",
      "epoch 850 g_loss 0.732627809047699 d_loss 1.3867413997650146 E(D(fake)) 0.49761679768562317 E(D(real)) 0.4974380135536194\n",
      "epoch 851 g_loss 0.733350932598114 d_loss 1.387211799621582 E(D(fake)) 0.49723300337791443 E(D(real)) 0.49682196974754333\n",
      "epoch 852 g_loss 0.7336900234222412 d_loss 1.3872807025909424 E(D(fake)) 0.4970301687717438 E(D(real)) 0.49657636880874634\n",
      "epoch 853 g_loss 0.7335950136184692 d_loss 1.3876999616622925 E(D(fake)) 0.4970382750034332 E(D(real)) 0.4963741600513458\n",
      "epoch 854 g_loss 0.733112096786499 d_loss 1.3881856203079224 E(D(fake)) 0.49724045395851135 E(D(real)) 0.49632593989372253\n",
      "epoch 855 g_loss 0.7323187589645386 d_loss 1.3884854316711426 E(D(fake)) 0.4976074993610382 E(D(real)) 0.4965357482433319\n",
      "epoch 856 g_loss 0.7313868999481201 d_loss 1.388505220413208 E(D(fake)) 0.4980490207672119 E(D(real)) 0.4969574809074402\n",
      "epoch 857 g_loss 0.730462372303009 d_loss 1.3885393142700195 E(D(fake)) 0.49849262833595276 E(D(real)) 0.4973824620246887\n",
      "epoch 858 g_loss 0.7295401096343994 d_loss 1.388201117515564 E(D(fake)) 0.4989403486251831 E(D(real)) 0.4979957938194275\n",
      "epoch 859 g_loss 0.7286524176597595 d_loss 1.3880882263183594 E(D(fake)) 0.49938148260116577 E(D(real)) 0.4984927773475647\n",
      "epoch 860 g_loss 0.7278309464454651 d_loss 1.3881807327270508 E(D(fake)) 0.4997883439064026 E(D(real)) 0.4988546073436737\n",
      "epoch 861 g_loss 0.7271380424499512 d_loss 1.387969970703125 E(D(fake)) 0.5001408457756042 E(D(real)) 0.49931222200393677\n",
      "epoch 862 g_loss 0.7265611290931702 d_loss 1.3875482082366943 E(D(fake)) 0.5004407167434692 E(D(real)) 0.49983200430870056\n",
      "epoch 863 g_loss 0.7261467576026917 d_loss 1.3875653743743896 E(D(fake)) 0.5006670355796814 E(D(real)) 0.5000513792037964\n",
      "epoch 864 g_loss 0.7259247899055481 d_loss 1.3875012397766113 E(D(fake)) 0.5007923245429993 E(D(real)) 0.5002074837684631\n",
      "epoch 865 g_loss 0.7258756160736084 d_loss 1.3876521587371826 E(D(fake)) 0.5008326768875122 E(D(real)) 0.5001797676086426\n",
      "epoch 866 g_loss 0.7260056138038635 d_loss 1.387117862701416 E(D(fake)) 0.5007874369621277 E(D(real)) 0.5004161596298218\n",
      "epoch 867 g_loss 0.7262659668922424 d_loss 1.387946367263794 E(D(fake)) 0.5006759166717529 E(D(real)) 0.49988535046577454\n",
      "epoch 868 g_loss 0.7266871333122253 d_loss 1.3876852989196777 E(D(fake)) 0.5004801750183105 E(D(real)) 0.4998258948326111\n",
      "epoch 869 g_loss 0.7272005081176758 d_loss 1.3882830142974854 E(D(fake)) 0.5002372860908508 E(D(real)) 0.4992741346359253\n",
      "epoch 870 g_loss 0.7278130054473877 d_loss 1.388250470161438 E(D(fake)) 0.49994054436683655 E(D(real)) 0.4989956319332123\n",
      "epoch 871 g_loss 0.728457510471344 d_loss 1.3882198333740234 E(D(fake)) 0.49962568283081055 E(D(real)) 0.4986940324306488\n",
      "epoch 872 g_loss 0.7290182113647461 d_loss 1.3883581161499023 E(D(fake)) 0.49934670329093933 E(D(real)) 0.49834632873535156\n",
      "epoch 873 g_loss 0.7294678092002869 d_loss 1.3882383108139038 E(D(fake)) 0.4991196393966675 E(D(real)) 0.4981731176376343\n",
      "epoch 874 g_loss 0.7296964526176453 d_loss 1.388535976409912 E(D(fake)) 0.49899813532829285 E(D(real)) 0.49790072441101074\n",
      "epoch 875 g_loss 0.7296904921531677 d_loss 1.3884161710739136 E(D(fake)) 0.4989895820617676 E(D(real)) 0.4979476034641266\n",
      "epoch 876 g_loss 0.7294669151306152 d_loss 1.3886940479278564 E(D(fake)) 0.4990898072719574 E(D(real)) 0.4979058504104614\n",
      "epoch 877 g_loss 0.7290601134300232 d_loss 1.3887614011764526 E(D(fake)) 0.499288409948349 E(D(real)) 0.49806809425354004\n",
      "epoch 878 g_loss 0.7285275459289551 d_loss 1.3886611461639404 E(D(fake)) 0.4995492100715637 E(D(real)) 0.4983745515346527\n",
      "epoch 879 g_loss 0.7279230356216431 d_loss 1.3885903358459473 E(D(fake)) 0.49985092878341675 E(D(real)) 0.498710960149765\n",
      "epoch 880 g_loss 0.7273003458976746 d_loss 1.388326644897461 E(D(fake)) 0.5001667737960815 E(D(real)) 0.49915698170661926\n",
      "epoch 881 g_loss 0.7266607880592346 d_loss 1.3881378173828125 E(D(fake)) 0.5004937052726746 E(D(real)) 0.49958106875419617\n",
      "epoch 882 g_loss 0.7260293364524841 d_loss 1.387755274772644 E(D(fake)) 0.500819206237793 E(D(real)) 0.5001024603843689\n",
      "epoch 883 g_loss 0.7256230115890503 d_loss 1.3876343965530396 E(D(fake)) 0.5010332465171814 E(D(real)) 0.5003865957260132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 884 g_loss 0.7252109050750732 d_loss 1.3874149322509766 E(D(fake)) 0.5012478232383728 E(D(real)) 0.5007132291793823\n",
      "epoch 885 g_loss 0.7248386144638062 d_loss 1.3870409727096558 E(D(fake)) 0.501443088054657 E(D(real)) 0.5010966062545776\n",
      "epoch 886 g_loss 0.7245932817459106 d_loss 1.386987328529358 E(D(fake)) 0.5015951991081238 E(D(real)) 0.5012754201889038\n",
      "epoch 887 g_loss 0.7245073914527893 d_loss 1.3872514963150024 E(D(fake)) 0.5016600489616394 E(D(real)) 0.5012155771255493\n",
      "epoch 888 g_loss 0.7244290113449097 d_loss 1.3873913288116455 E(D(fake)) 0.5017210245132446 E(D(real)) 0.5012102127075195\n",
      "epoch 889 g_loss 0.724480152130127 d_loss 1.387507677078247 E(D(fake)) 0.5017163157463074 E(D(real)) 0.5011470317840576\n",
      "epoch 890 g_loss 0.7248011231422424 d_loss 1.3878982067108154 E(D(fake)) 0.5015755891799927 E(D(real)) 0.500813364982605\n",
      "epoch 891 g_loss 0.7252581119537354 d_loss 1.3877692222595215 E(D(fake)) 0.5013691782951355 E(D(real)) 0.5006682872772217\n",
      "epoch 892 g_loss 0.7258942723274231 d_loss 1.3879377841949463 E(D(fake)) 0.5010650157928467 E(D(real)) 0.5002806782722473\n",
      "epoch 893 g_loss 0.7266255021095276 d_loss 1.3874262571334839 E(D(fake)) 0.5007092952728271 E(D(real)) 0.5001735091209412\n",
      "epoch 894 g_loss 0.7273499965667725 d_loss 1.3881359100341797 E(D(fake)) 0.5003524422645569 E(D(real)) 0.499459445476532\n",
      "epoch 895 g_loss 0.7280300855636597 d_loss 1.3877708911895752 E(D(fake)) 0.5000045299530029 E(D(real)) 0.49929073452949524\n",
      "epoch 896 g_loss 0.7286294102668762 d_loss 1.387861728668213 E(D(fake)) 0.49970123171806335 E(D(real)) 0.4989399015903473\n",
      "epoch 897 g_loss 0.7290909290313721 d_loss 1.3874564170837402 E(D(fake)) 0.4994618892669678 E(D(real)) 0.49889877438545227\n",
      "epoch 898 g_loss 0.7293237447738647 d_loss 1.3877828121185303 E(D(fake)) 0.49933314323425293 E(D(real)) 0.4986081123352051\n",
      "epoch 899 g_loss 0.7293486595153809 d_loss 1.387831687927246 E(D(fake)) 0.49930447340011597 E(D(real)) 0.49855127930641174\n",
      "epoch 900 g_loss 0.729181706905365 d_loss 1.3878381252288818 E(D(fake)) 0.4993729293346405 E(D(real)) 0.49861377477645874\n",
      "epoch 901 g_loss 0.7288690805435181 d_loss 1.387905240058899 E(D(fake)) 0.49951624870300293 E(D(real)) 0.49872326850891113\n",
      "epoch 902 g_loss 0.7284590005874634 d_loss 1.3877540826797485 E(D(fake)) 0.4997123181819916 E(D(real)) 0.4989931881427765\n",
      "epoch 903 g_loss 0.7279818058013916 d_loss 1.387694001197815 E(D(fake)) 0.49994325637817383 E(D(real)) 0.49925199151039124\n",
      "epoch 904 g_loss 0.727415919303894 d_loss 1.3877933025360107 E(D(fake)) 0.5002223253250122 E(D(real)) 0.49948257207870483\n",
      "epoch 905 g_loss 0.7268323302268982 d_loss 1.387756586074829 E(D(fake)) 0.5005137920379639 E(D(real)) 0.4997940957546234\n",
      "epoch 906 g_loss 0.7263039946556091 d_loss 1.3872096538543701 E(D(fake)) 0.5007876753807068 E(D(real)) 0.5003483295440674\n",
      "epoch 907 g_loss 0.7258439064025879 d_loss 1.386841058731079 E(D(fake)) 0.501027524471283 E(D(real)) 0.5007743835449219\n",
      "epoch 908 g_loss 0.7255007028579712 d_loss 1.38747239112854 E(D(fake)) 0.5012192130088806 E(D(real)) 0.5006489753723145\n",
      "epoch 909 g_loss 0.7252849340438843 d_loss 1.3870315551757812 E(D(fake)) 0.5013434290885925 E(D(real)) 0.5010000467300415\n",
      "epoch 910 g_loss 0.7251954674720764 d_loss 1.3871815204620361 E(D(fake)) 0.5014030337333679 E(D(real)) 0.5009936094284058\n",
      "epoch 911 g_loss 0.7253158688545227 d_loss 1.3873100280761719 E(D(fake)) 0.5013623237609863 E(D(real)) 0.5008870959281921\n",
      "epoch 912 g_loss 0.7256683707237244 d_loss 1.3864727020263672 E(D(fake)) 0.5012059211730957 E(D(real)) 0.5011530518531799\n",
      "epoch 913 g_loss 0.7262019515037537 d_loss 1.3874945640563965 E(D(fake)) 0.5009527802467346 E(D(real)) 0.5003852844238281\n",
      "epoch 914 g_loss 0.7269101738929749 d_loss 1.3875463008880615 E(D(fake)) 0.5006112456321716 E(D(real)) 0.5000160336494446\n",
      "epoch 915 g_loss 0.7277231812477112 d_loss 1.3868602514266968 E(D(fake)) 0.5002052783966064 E(D(real)) 0.4999553859233856\n",
      "epoch 916 g_loss 0.7285575270652771 d_loss 1.3870521783828735 E(D(fake)) 0.49978482723236084 E(D(real)) 0.4994356334209442\n",
      "epoch 917 g_loss 0.7293735146522522 d_loss 1.3868803977966309 E(D(fake)) 0.4993695914745331 E(D(real)) 0.49910250306129456\n",
      "epoch 918 g_loss 0.7300873398780823 d_loss 1.3864352703094482 E(D(fake)) 0.4989968240261078 E(D(real)) 0.4989548623561859\n",
      "epoch 919 g_loss 0.7306174635887146 d_loss 1.386127233505249 E(D(fake)) 0.4987156391143799 E(D(real)) 0.49882468581199646\n",
      "epoch 920 g_loss 0.7309756278991699 d_loss 1.3858033418655396 E(D(fake)) 0.49851667881011963 E(D(real)) 0.4987827241420746\n",
      "epoch 921 g_loss 0.7311530113220215 d_loss 1.386308193206787 E(D(fake)) 0.49840807914733887 E(D(real)) 0.4984210431575775\n",
      "epoch 922 g_loss 0.7311182022094727 d_loss 1.3860447406768799 E(D(fake)) 0.4984014928340912 E(D(real)) 0.4985421597957611\n",
      "epoch 923 g_loss 0.7308889031410217 d_loss 1.3862130641937256 E(D(fake)) 0.498489648103714 E(D(real)) 0.49854475259780884\n",
      "epoch 924 g_loss 0.730536699295044 d_loss 1.3859926462173462 E(D(fake)) 0.4986414313316345 E(D(real)) 0.49880704283714294\n",
      "epoch 925 g_loss 0.7300884127616882 d_loss 1.3861130475997925 E(D(fake)) 0.49884626269340515 E(D(real)) 0.4989478290081024\n",
      "epoch 926 g_loss 0.729614794254303 d_loss 1.3857731819152832 E(D(fake)) 0.49906936287879944 E(D(real)) 0.49933910369873047\n",
      "epoch 927 g_loss 0.7290850877761841 d_loss 1.3859347105026245 E(D(fake)) 0.4993159770965576 E(D(real)) 0.49950531125068665\n",
      "epoch 928 g_loss 0.728577196598053 d_loss 1.3860280513763428 E(D(fake)) 0.49956101179122925 E(D(real)) 0.4997081458568573\n",
      "epoch 929 g_loss 0.7280909419059753 d_loss 1.3859151601791382 E(D(fake)) 0.49980148673057556 E(D(real)) 0.5000075101852417\n",
      "epoch 930 g_loss 0.7276058793067932 d_loss 1.3861773014068604 E(D(fake)) 0.500042200088501 E(D(real)) 0.5001224875450134\n",
      "epoch 931 g_loss 0.7271993160247803 d_loss 1.3863716125488281 E(D(fake)) 0.500250518321991 E(D(real)) 0.5002345442771912\n",
      "epoch 932 g_loss 0.7269162535667419 d_loss 1.3859670162200928 E(D(fake)) 0.5003985166549683 E(D(real)) 0.500591516494751\n",
      "epoch 933 g_loss 0.7267403602600098 d_loss 1.3867250680923462 E(D(fake)) 0.5004980564117432 E(D(real)) 0.5003102421760559\n",
      "epoch 934 g_loss 0.726872980594635 d_loss 1.387270212173462 E(D(fake)) 0.5004400610923767 E(D(real)) 0.49998536705970764\n",
      "epoch 935 g_loss 0.7273530960083008 d_loss 1.3870198726654053 E(D(fake)) 0.5002105236053467 E(D(real)) 0.49989327788352966\n",
      "epoch 936 g_loss 0.7280682921409607 d_loss 1.387282133102417 E(D(fake)) 0.4998606741428375 E(D(real)) 0.49940234422683716\n",
      "epoch 937 g_loss 0.72891765832901 d_loss 1.3874869346618652 E(D(fake)) 0.4994353950023651 E(D(real)) 0.49887603521347046\n",
      "epoch 938 g_loss 0.7297932505607605 d_loss 1.3873214721679688 E(D(fake)) 0.4989908039569855 E(D(real)) 0.49851199984550476\n",
      "epoch 939 g_loss 0.7305666208267212 d_loss 1.3874797821044922 E(D(fake)) 0.4985943138599396 E(D(real)) 0.498031884431839\n",
      "epoch 940 g_loss 0.7311074137687683 d_loss 1.3876079320907593 E(D(fake)) 0.49830374121665955 E(D(real)) 0.4976756274700165\n",
      "epoch 941 g_loss 0.7314237952232361 d_loss 1.387399435043335 E(D(fake)) 0.4981226325035095 E(D(real)) 0.497596800327301\n",
      "epoch 942 g_loss 0.7315083146095276 d_loss 1.387251377105713 E(D(fake)) 0.49805185198783875 E(D(real)) 0.4975925385951996\n",
      "epoch 943 g_loss 0.7314097881317139 d_loss 1.387335181236267 E(D(fake)) 0.49807247519493103 E(D(real)) 0.497567355632782\n",
      "epoch 944 g_loss 0.7311408519744873 d_loss 1.3869928121566772 E(D(fake)) 0.49817872047424316 E(D(real)) 0.49784472584724426\n",
      "epoch 945 g_loss 0.730758547782898 d_loss 1.387073040008545 E(D(fake)) 0.4983426630496979 E(D(real)) 0.49796655774116516\n",
      "epoch 946 g_loss 0.7302791476249695 d_loss 1.387134075164795 E(D(fake)) 0.4985586702823639 E(D(real)) 0.498149573802948\n",
      "epoch 947 g_loss 0.7297155261039734 d_loss 1.3870372772216797 E(D(fake)) 0.498821496963501 E(D(real)) 0.4984593391418457\n",
      "epoch 948 g_loss 0.7291539907455444 d_loss 1.387218713760376 E(D(fake)) 0.4990892708301544 E(D(real)) 0.4986342787742615\n",
      "epoch 949 g_loss 0.7286372184753418 d_loss 1.387094497680664 E(D(fake)) 0.49933961033821106 E(D(real)) 0.49894633889198303\n",
      "epoch 950 g_loss 0.7281701564788818 d_loss 1.3872296810150146 E(D(fake)) 0.4995669722557068 E(D(real)) 0.4991116225719452\n",
      "epoch 951 g_loss 0.727790117263794 d_loss 1.3868935108184814 E(D(fake)) 0.4997602701187134 E(D(real)) 0.4994763731956482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 952 g_loss 0.7275494337081909 d_loss 1.3874866962432861 E(D(fake)) 0.4998815655708313 E(D(real)) 0.49930715560913086\n",
      "epoch 953 g_loss 0.7275234460830688 d_loss 1.3877099752426147 E(D(fake)) 0.4999048709869385 E(D(real)) 0.49921733140945435\n",
      "epoch 954 g_loss 0.7276358604431152 d_loss 1.3872379064559937 E(D(fake)) 0.4998548924922943 E(D(real)) 0.4994043707847595\n",
      "epoch 955 g_loss 0.727886974811554 d_loss 1.3873600959777832 E(D(fake)) 0.49973469972610474 E(D(real)) 0.49922534823417664\n",
      "epoch 956 g_loss 0.7281976342201233 d_loss 1.3873271942138672 E(D(fake)) 0.49958252906799316 E(D(real)) 0.49909546971321106\n",
      "epoch 957 g_loss 0.7284983396530151 d_loss 1.3876097202301025 E(D(fake)) 0.4994378387928009 E(D(real)) 0.4988064169883728\n",
      "epoch 958 g_loss 0.7286868095397949 d_loss 1.3877601623535156 E(D(fake)) 0.49934104084968567 E(D(real)) 0.49862661957740784\n",
      "epoch 959 g_loss 0.7289155125617981 d_loss 1.3875908851623535 E(D(fake)) 0.4992203116416931 E(D(real)) 0.49859023094177246\n",
      "epoch 960 g_loss 0.7290969491004944 d_loss 1.3872978687286377 E(D(fake)) 0.49912557005882263 E(D(real)) 0.4986400604248047\n",
      "epoch 961 g_loss 0.7291264533996582 d_loss 1.3875634670257568 E(D(fake)) 0.4991036355495453 E(D(real)) 0.4984837770462036\n",
      "epoch 962 g_loss 0.7290223240852356 d_loss 1.387492060661316 E(D(fake)) 0.49915266036987305 E(D(real)) 0.49856823682785034\n",
      "epoch 963 g_loss 0.7288873195648193 d_loss 1.3876147270202637 E(D(fake)) 0.4992203116416931 E(D(real)) 0.4985792338848114\n",
      "epoch 964 g_loss 0.7287492156028748 d_loss 1.3879752159118652 E(D(fake)) 0.499286025762558 E(D(real)) 0.49846136569976807\n",
      "epoch 965 g_loss 0.7286483645439148 d_loss 1.388005018234253 E(D(fake)) 0.4993407726287842 E(D(real)) 0.49849802255630493\n",
      "epoch 966 g_loss 0.728649377822876 d_loss 1.3881256580352783 E(D(fake)) 0.49934402108192444 E(D(real)) 0.49844789505004883\n",
      "epoch 967 g_loss 0.7287545204162598 d_loss 1.3883237838745117 E(D(fake)) 0.4992898106575012 E(D(real)) 0.49829378724098206\n",
      "epoch 968 g_loss 0.7289369702339172 d_loss 1.3883157968521118 E(D(fake)) 0.4991944134235382 E(D(real)) 0.4982069432735443\n",
      "epoch 969 g_loss 0.7290655374526978 d_loss 1.3882741928100586 E(D(fake)) 0.49912458658218384 E(D(real)) 0.49815404415130615\n",
      "epoch 970 g_loss 0.7291861176490784 d_loss 1.3882038593292236 E(D(fake)) 0.49906039237976074 E(D(real)) 0.4981226623058319\n",
      "epoch 971 g_loss 0.7292910218238831 d_loss 1.388119101524353 E(D(fake)) 0.4990023374557495 E(D(real)) 0.4981086850166321\n",
      "epoch 972 g_loss 0.7292644381523132 d_loss 1.3878495693206787 E(D(fake)) 0.4990065395832062 E(D(real)) 0.4982419013977051\n",
      "epoch 973 g_loss 0.7291451096534729 d_loss 1.3881340026855469 E(D(fake)) 0.49906039237976074 E(D(real)) 0.49815091490745544\n",
      "epoch 974 g_loss 0.7289479970932007 d_loss 1.388067603111267 E(D(fake)) 0.4991520941257477 E(D(real)) 0.49827730655670166\n",
      "epoch 975 g_loss 0.7286117672920227 d_loss 1.3877720832824707 E(D(fake)) 0.4993152618408203 E(D(real)) 0.49858325719833374\n",
      "epoch 976 g_loss 0.7282269597053528 d_loss 1.3876986503601074 E(D(fake)) 0.4995066821575165 E(D(real)) 0.49881309270858765\n",
      "epoch 977 g_loss 0.7278342843055725 d_loss 1.3877687454223633 E(D(fake)) 0.49970248341560364 E(D(real)) 0.49897098541259766\n",
      "epoch 978 g_loss 0.7274723052978516 d_loss 1.387317419052124 E(D(fake)) 0.499887079000473 E(D(real)) 0.499382883310318\n",
      "epoch 979 g_loss 0.7271488904953003 d_loss 1.3872178792953491 E(D(fake)) 0.5000534057617188 E(D(real)) 0.4995972514152527\n",
      "epoch 980 g_loss 0.7268033623695374 d_loss 1.386965274810791 E(D(fake)) 0.5002378821372986 E(D(real)) 0.4999108910560608\n",
      "epoch 981 g_loss 0.7264865040779114 d_loss 1.3870291709899902 E(D(fake)) 0.5004062652587891 E(D(real)) 0.5000535845756531\n",
      "epoch 982 g_loss 0.726233720779419 d_loss 1.3864095211029053 E(D(fake)) 0.5005401372909546 E(D(real)) 0.5004991888999939\n",
      "epoch 983 g_loss 0.7260697484016418 d_loss 1.3867056369781494 E(D(fake)) 0.5006349086761475 E(D(real)) 0.5004459023475647\n",
      "epoch 984 g_loss 0.7260358333587646 d_loss 1.3868343830108643 E(D(fake)) 0.5006647706031799 E(D(real)) 0.5004124045372009\n",
      "epoch 985 g_loss 0.7261197566986084 d_loss 1.3867504596710205 E(D(fake)) 0.5006325840950012 E(D(real)) 0.500425398349762\n",
      "epoch 986 g_loss 0.726375937461853 d_loss 1.386242151260376 E(D(fake)) 0.5005191564559937 E(D(real)) 0.5005671977996826\n",
      "epoch 987 g_loss 0.726726770401001 d_loss 1.3860551118850708 E(D(fake)) 0.5003547072410583 E(D(real)) 0.5004976987838745\n",
      "epoch 988 g_loss 0.7271497249603271 d_loss 1.3860831260681152 E(D(fake)) 0.5001496076583862 E(D(real)) 0.5002773404121399\n",
      "epoch 989 g_loss 0.7276166677474976 d_loss 1.3856298923492432 E(D(fake)) 0.4999219477176666 E(D(real)) 0.5002730488777161\n",
      "epoch 990 g_loss 0.7280148267745972 d_loss 1.385566234588623 E(D(fake)) 0.4997197389602661 E(D(real)) 0.5001009106636047\n",
      "epoch 991 g_loss 0.7283815741539001 d_loss 1.385548710823059 E(D(fake)) 0.4995327889919281 E(D(real)) 0.4999261200428009\n",
      "epoch 992 g_loss 0.7286710143089294 d_loss 1.3847935199737549 E(D(fake)) 0.49937960505485535 E(D(real)) 0.500146210193634\n",
      "epoch 993 g_loss 0.7287788391113281 d_loss 1.3852801322937012 E(D(fake)) 0.49931544065475464 E(D(real)) 0.4998365640640259\n",
      "epoch 994 g_loss 0.7288249731063843 d_loss 1.3848601579666138 E(D(fake)) 0.49928292632102966 E(D(real)) 0.500013530254364\n",
      "epoch 995 g_loss 0.7287387847900391 d_loss 1.3850178718566895 E(D(fake)) 0.49931249022483826 E(D(real)) 0.4999661445617676\n",
      "epoch 996 g_loss 0.7286150455474854 d_loss 1.3848152160644531 E(D(fake)) 0.49936842918395996 E(D(real)) 0.5001224279403687\n",
      "epoch 997 g_loss 0.7284589409828186 d_loss 1.3843473196029663 E(D(fake)) 0.49944135546684265 E(D(real)) 0.5004240870475769\n",
      "epoch 998 g_loss 0.7282286882400513 d_loss 1.3841652870178223 E(D(fake)) 0.4995507001876831 E(D(real)) 0.5006291270256042\n",
      "epoch 999 g_loss 0.7280111312866211 d_loss 1.384026050567627 E(D(fake)) 0.49964943528175354 E(D(real)) 0.5007959008216858\n"
     ]
    }
   ],
   "source": [
    "N = len(train_data)\n",
    "# n_c=3\n",
    "\n",
    "\n",
    "# x_shape=(3,28,28)\n",
    "# generator = Generator_CNN(latent_dim, x_shape).cuda()\n",
    "# discriminator = Discriminator_CNN().cuda()\n",
    "\n",
    "\n",
    "A = 0.05  # Discriminator learning rate\n",
    "B = 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n = 0\n",
    "for p in generator.parameters():\n",
    "    n = n+1\n",
    "\n",
    "M = [None]*n\n",
    "n = 0\n",
    "for par in generator.parameters():\n",
    "    M[n] = torch.zeros(list(par.size())).cuda()\n",
    "    n = n+1\n",
    "\n",
    "\n",
    "# N = 60000\n",
    "a = 1\n",
    "beta_1 = 0.9\n",
    "n_epochs = 1000\n",
    "tau = 0.001\n",
    "\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "# real = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\n",
    "# fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "Gen_Dis = torch.zeros(int(N/batchSize*n_epochs/100))\n",
    "Real_Dis = torch.zeros(int(N/batchSize*n_epochs/100))\n",
    "js = 0\n",
    "###########################################\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, sample in enumerate(training_dataloader):\n",
    "\n",
    "          # ---------------------\n",
    "          #  Train Discriminator\n",
    "          # ---------------------\n",
    "        lr_d = A*(iteration+B)**(-1)\n",
    "\n",
    "        for param_group in optimizer_D.param_groups:\n",
    "            param_group['lr'] = lr_d\n",
    "\n",
    "        generator.zero_grad()\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        real_sample = Variable(sample.type(Tensor))\n",
    "        \n",
    "        num_of_samples = real_sample.size(dim=0)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Sample random latent variables\n",
    "        # gen_sample = generator(torch.randn((batchSize, latent_dim, 1, 1)).to(device))\n",
    "        gen_sample = generator(torch.randn((num_of_samples, latent_dim)).to(device))\n",
    "        \n",
    "        # PROBABLY PASS gen_imgs THROUGH AUTOENCODER NOW\n",
    "        \n",
    "        if autoencoder_flag:\n",
    "            gen_sample = autoencoder.decoder(gen_sample)  # added\n",
    "        \n",
    "        D_gen = discriminator(gen_sample)\n",
    "        D_real = discriminator(real_sample)\n",
    "        \n",
    "        \n",
    "        real = Variable(Tensor(num_of_samples).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(num_of_samples).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # real = real.unsqueeze(1)\n",
    "        # fake = fake.unsqueeze(1)\n",
    "        # fake = torch.unsqueeze(fake, 1)\n",
    "        fake = fake.view(-1, 1)\n",
    "        # print(\"real.size():\",real.size())\n",
    "        # print(\"D_real.size():\",D_real.size())\n",
    "        # real = torch.unsqueeze(real, 1)\n",
    "        real = real.view(-1, 1)\n",
    "        # print(\"real.size():\",real.size())\n",
    "        \n",
    "        real_loss = bce_loss(D_real, real)\n",
    "        fake_loss = bce_loss(D_gen, fake)\n",
    "        d_loss = (real_loss + fake_loss)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "          # ---------------------\n",
    "          #  Train Generator\n",
    "          # ---------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        # gen_sample = generator(torch.randn((batchSize, latent_dim, 1, 1)).to(device))\n",
    "        gen_sample = generator(torch.randn((num_of_samples, latent_dim)).to(device))\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"gen_sample.size() before decoding:\", gen_sample.size())\n",
    "        # PROBABLY PASS gen_imgs THROUGH AUTOENCODER NOW\n",
    "        \n",
    "        if autoencoder_flag:\n",
    "            gen_sample = autoencoder.decoder(gen_sample)  # added\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"gen_sample.size() after decoding:\", gen_sample.size())\n",
    "\n",
    "        D_gen = discriminator(gen_sample)\n",
    "        v_loss = bce_loss(D_gen, real)\n",
    "\n",
    "        l2 = 0.0\n",
    "        for p in generator.parameters(): \n",
    "            l2 += (p**2).sum()*20\n",
    "        \n",
    "        g_loss = v_loss+l2/N\n",
    "        # g_loss = v_loss +naive_estimator(real_imgs.view((batch,28*28)),gen_imgs.view((batch,28*28)),k=1)/N*100\n",
    "#         print(\"real_sample.size():\", real_sample.size())\n",
    "#         print(\"gen_sample.size():\", gen_sample.size())\n",
    "#         g_loss = v_loss +naive_estimator(real_sample, gen_sample, k=1)/N*100\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        n = 0\n",
    "        for par in generator.parameters(): \n",
    "            par.data.sub_(a*M[n]*lr_g/N)\n",
    "            n = n+1\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for param in generator.parameters(): \n",
    "                param.add_(torch.randn(param.size()).cuda() * np.sqrt(2*tau*lr_g/N))\n",
    "\n",
    "        n = 0\n",
    "        for par in generator.parameters(): \n",
    "            M[n] *= beta_1\n",
    "            M[n] += (1-beta_1)*par.grad*N\n",
    "            n = n+1\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        # Nash equilibrium check\n",
    "        if iteration % 100 == 1:\n",
    "            # Gen_Dis[js] = torch.mean(discriminator(generator(torch.randn(\n",
    "            #     (batch, latent_dim, 1, 1)).cuda()))).detach().cpu().item()\n",
    "#             Gen_Dis[js] = torch.mean(discriminator(autoencoder.decoder(generator(torch.randn(\n",
    "#                 (num_of_samples, latent_dim)).cuda())))).detach().cpu().item()\n",
    "            \n",
    "            if autoencoder_flag:\n",
    "                Gen_Dis[js] = torch.mean(discriminator(autoencoder.decoder(generator(torch.randn(\n",
    "                (num_of_samples, latent_dim)).cuda())))).detach().cpu().item()\n",
    "            else:\n",
    "                Gen_Dis[js] = torch.mean(discriminator(generator(torch.randn(\n",
    "                (num_of_samples, latent_dim)).cuda()))).detach().cpu().item()\n",
    "                \n",
    "            Real_Dis[js] = torch.mean(discriminator(\n",
    "                Variable(sample.type(Tensor)))).detach().cpu().item()\n",
    "            js += 1\n",
    "\n",
    "    print(\"epoch\",epoch,\"g_loss\",g_loss.item(),\"d_loss\",d_loss.item(),\"E(D(fake))\",torch.mean(D_gen).item(),\"E(D(real))\",torch.mean(D_real).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), os.path.join(result_path, 'generator_batch_1000.model'))\n",
    "torch.save(discriminator.state_dict(), os.path.join(result_path, 'discriminator_batch_1000.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fake_batches = test_data_len//batchSize\n",
    "fake_data = torch.zeros((0, feature_size), device='cpu')\n",
    "for _ in range(num_fake_batches):\n",
    "    z = torch.randn(batchSize, latent_dim, device=device)\n",
    "    generated_batch = generator(z)\n",
    "    if autoencoder_flag:\n",
    "        fake_batch = autoencoder.decoder(generator(z))\n",
    "    else:\n",
    "        fake_batch = generator(z)\n",
    "    fake_data = torch.cat((fake_data, fake_batch.round().to('cpu')), 0)\n",
    "    \n",
    "fake_data = fake_data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9300, 1358)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(fake_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9300, 1358)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\preet\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:8380: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  return ks_2samp(xvals, yvals, alternative=alternative, method=method)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696612665684831\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kstest\n",
    "count = 0\n",
    "for i in range(test_data.shape[1]):\n",
    "    stat, p_value = kstest(test_data[:, i], fake_data[:, i])    # dimension-wise ks test\n",
    "    if p_value > 0.05:\n",
    "        count+=1\n",
    "\n",
    "avg = count/test_data.shape[1]\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
